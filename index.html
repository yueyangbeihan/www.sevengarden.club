<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="seven 的精神家园，学习笔记">
<meta name="keywords" content="云计算,大数据，kuberntes">
<meta property="og:type" content="website">
<meta property="og:title" content="岳阳北寒">
<meta property="og:url" content="http://sevengarden.club/index.html">
<meta property="og:site_name" content="岳阳北寒">
<meta property="og:description" content="seven 的精神家园，学习笔记">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="岳阳北寒">
<meta name="twitter:description" content="seven 的精神家园，学习笔记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://sevengarden.club/">





  <title>岳阳北寒</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">岳阳北寒</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">要有最朴素的生活和最遥远的梦想，即使明日天寒地冻，路远马亡.......</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-somrthing">
          <a href="/有料" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            somrthing
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/12/15/Kubernetes网络模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/15/Kubernetes网络模型/" itemprop="url">Kubernetes网络模型</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-15T15:48:39+08:00">
                2019-12-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Kubnernets-基本网络模型"><a href="#Kubnernets-基本网络模型" class="headerlink" title="Kubnernets 基本网络模型"></a>Kubnernets 基本网络模型</h2><h3 id="准入条件"><a href="#准入条件" class="headerlink" title="准入条件"></a>准入条件</h3><ol>
<li>任意两个pod之间其实是可以直接通信的，无需经过显式使用NAT来接收数据和地址转换</li>
<li>node与pod之间是可以直接通信的，无需使用明显的地址转换</li>
<li>pod看自己的IP跟别人看见它所用的IP是一样的，中间不能经过转换<h3 id="为外部提供服务"><a href="#为外部提供服务" class="headerlink" title="为外部提供服务"></a>为外部提供服务</h3></li>
</ol>
<ul>
<li>外部世界和service之间是怎么通信的？</li>
<li>service如何与后端的pod通讯</li>
<li>pod和pod之间调用是怎么做到通信的</li>
<li>pod 内部容器与容器之间通信</li>
</ul>
<blockquote>
<p>容器网络复杂性在于它是寄生在Host网络之上。从这个角度讲，可以把容器网络方案大体分为Underlay和Overlay 两大派别</p>
</blockquote>
<ul>
<li>Underlay的标准是它与Host网络是同层的，从外在可见的一个特征就是它是不是使用了Host网络同样的网段、输入输出基础设备、容器的IP地址是不是需要与Host网络取得协同</li>
<li>Overlay不一样的地方在于它并不需要从Host网络的IPM的管理组件去申请IP，一般来说，它只需要跟Host网络不冲突，这个IP可以自由分配的</li>
</ul>
<p><strong>协议栈层级</strong></p>
<ul>
<li>二层 （桥接，ARP+MAC larning ），广播问题</li>
<li>三层（纯路由转发）：<ul>
<li>一般基于BGP，自主学习机房的路由状况。最大的优点就是IP穿透性，只要基于这个IP网络，那此网络就可以穿越。</li>
<li>规模优势，具有良好的扩展性</li>
<li>实际部署中，企业的网络受控，BGP不能随便使用的</li>
</ul>
</li>
<li>二层+三层（节点内部二层转发，跨节点三层转发）<ul>
<li>解决纯二层规模问题，又能解决三层各种限制问题，特别是云化场景下VPC的三层转发能力</li>
<li>比较适合Kubernetes对于Pod网络假设，Pod会漂移，IP会改变，不变的是service和ingress</li>
<li>运维角度讲，节点内部就是一个子网，大家习惯利用传统的云化场景，每一个独立可见的应用有一个独立的IP，且不会改变，那么二层加三层就无法做到</li>
</ul>
</li>
</ul>
<p><strong>穿越形态</strong></p>
<ul>
<li>Overlay （隧道穿越底层基础设施）<ul>
<li>云化场景常见,受控VPC网络</li>
</ul>
</li>
<li>Underlay (直接穿越底层基础设施)<ul>
<li>适合可控的网络场景，无论是裸机还是虚拟机，整个网络比啊可以直接穿越过去</li>
</ul>
</li>
</ul>
<p><strong>隔离方式</strong></p>
<ul>
<li>FLAT：扁平网络，无隔离</li>
<li>VLAN：机房内使用，租户数量受限</li>
<li>VXLAN/GRE：基于IP穿越方式，租户规模足够大</li>
</ul>
<h3 id="Calico"><a href="#Calico" class="headerlink" title="Calico"></a>Calico</h3><p>  基于BGP的三层Underlay。它的IP 隧道是当网络受控时的一种妥协的三层Overlay且支持network policy </p>
<blockquote>
<p>calico 可以创建并管理一个3层平面网络，为每个工作负载分配一个完全可路由的IP地址。工作负载可以在没有IP封装或网络地址转换的情况下进行通信，以实现裸机性能，简化故障排除和提供更好的互操作性。在需要使用overlay网络的环境中，提供IP-in-ip隧道技术，或者其他overlay 网络配合使用</p>
</blockquote>
<ul>
<li>BGP（三层underlay）</li>
<li>ipip（三层Overlay）</li>
<li>Network Policy<ul>
<li>IPIP是一种将各node的路由之间做一个tunnel，再把两个网络连接起来的模式。启用IPIP模式时，calico将在各node上创建一个名为“tunl0”的虚拟网络接口<br><img src="https://i.loli.net/2019/12/11/7PZkIVqs36cRJjt.png" alt="image.png"></li>
<li>BGP模式则直接使用物理机作为虚拟路由器（vRouter），不再创建额外的tunnel </li>
</ul>
</li>
</ul>
<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><ul>
<li>Calico创建和管理一个扁平的三层网络（不需要overlay），每个容器会分配一个可路由的IP。由于通信时不需要解包和封包，网络性能损耗小，易于排查，易于水平扩展。</li>
<li>小规模部署可以通过BGP client直接互联，大规模下可以通过指定的BGP Route Reflector来完成，这样保证所有的数据流量都是通过IP路由的方式完成互联</li>
<li>Calico基于iptables还提供了丰富而灵活的网络policy ，保证通过各个节点上的ACL提供给哦你workload的多租户隔离、安全组以及其他可达性限制功能</li>
</ul>
<h4 id="Calico架构"><a href="#Calico架构" class="headerlink" title="Calico架构"></a>Calico架构</h4><p><img src="https://i.loli.net/2019/12/11/X7fZLcSKyiYzOQq.png" alt="image.png"></p>
<p>calico 利用linux内核原声的路由和iptables防火墙功能。进出各个容器、虚拟机和物理主机的所有流量都会在路由到目标之前便利这些内核规则</p>
<ul>
<li>Felix：主要的Calico代理agent,运行每台计算机上管理endpoints资源</li>
<li>calicoctl:允许从命令行界面配置实现高级策略和网络</li>
<li>orchestrator plugins:提供与各种流行的云计算编排工具的紧密集成和同步支持</li>
<li>key/calue store:存储calico的策略配置和网络状态信息，目前主要使用etcd 或k8s api</li>
<li>calico/node:在每个主机上运行，从key/value 存储中读取相关的策略和网络配置信息，并在linux 内核中实现它</li>
<li>dikastes/envoy :可选的kubernetes sidecars,可通过相互TLS身份认证保护工作负载间通信，并增加应用层控制策略</li>
</ul>
<h4 id="基本模式"><a href="#基本模式" class="headerlink" title="基本模式"></a>基本模式</h4><ul>
<li>calico 本质上利用了网卡的代理ARP功能</li>
<li>calico通过一个巧妙的方法将worknode的所有流量引导一个特殊的网关169.254.1.1，从而引流到主机calixxx网络设备上，最终将二三层流量全部转换成三层流量来转发</li>
<li>在主机上通过开启代理ARP功能来实现ARP应答，使得ARP广播被抑制在主机上，抑制了广播风暴，也不会有ARP表膨胀的问题</li>
</ul>
<h3 id="Contic"><a href="#Contic" class="headerlink" title="Contic"></a>Contic</h3><p>  功能非常齐全，二层桥接，基于VLAN网络；三层路由，基于BGP网络；同时支持Overlay，通过Vxaln应对一些受控网络环境，提供ACI支持网络策略</p>
<ul>
<li>L2 Bridged（二层Underlay，基于VLAN）</li>
<li>L3 Routed（三层Underlay，基于BGP）</li>
<li>Overlay（二层Overlay/三层Overlay，基于VXLAN）</li>
<li>ACI（网络策略）</li>
</ul>
<h3 id="Flannel"><a href="#Flannel" class="headerlink" title="Flannel"></a>Flannel</h3><p>   <em>host-gw模式，节点内部子网，节点之间通过路由指过去。但是这种方式存在限制，当它直接指引过去，要求所有节点在同一个二层里，不能穿越不同子网。当不能穿越子网时，通过VxLAN方式解决，帮助报文在二层网络上穿越。比如VPC router，Flannel完成与不同公有云厂商的VPC router对接。</em><br>   <em>在安装node节点的时候，节点上的进程按照flannel-&gt;docker-&gt;kubelet-&gt;kube-proxy的顺序启动的</em></p>
<ul>
<li><p>host gw（二层+三层Underlay）</p>
</li>
<li><p>VXLAN（二层+三层Overlay）</p>
</li>
<li><p>Alicloud VPCvRouter/AWSVPCrouter （二层+三层Underlay）</p>
<p><em>Flannel 通过给每天宿主机分配一个子网的方式为容器提供虚拟网络，其基于linux TUN/TAP，使用UDP封装的IP包创建Overlay网络，并借助etcd维护网络的分配情况</em></p>
</li>
</ul>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p> 控制平面上host本地的flannel负责从远端的ETCD集群同步本地和其他host上的subnet信息，并为POD分配IP地址。数据平面Flannel通过Flannel通过Backend（比如UDP封装）来实现L3 OverLay，即可以选择一般的TUN设备又可以选择VxLAN设备<br> <img src="https://i.loli.net/2019/12/10/NU1WGE7tzxrb2SM.png" alt="image.png"></p>
<p> 除了UDP，Flannel还支持其他很多Backend</p>
<ul>
<li>udp:使用用户态udp封装，性能有较大损失</li>
<li>vxlan:vxlan封装，需要配置VNI，port和GBP</li>
<li>host-gw：直接路由的方式，将容器网络的路由信息直接更新到主机的路由表中，仅适用于二层直接可达的网络</li>
<li>aws-vpc：使用 Amazon VPC route table 创建路由，适用于AWS上运行的容器</li>
<li>gce：使用Google Compute Engine Network创建路由，所有instance需要开启IP forwarding，适用于GCE上运行的容器</li>
<li>ali-vpc：使用阿里云VPC route table 创建路由，适用于阿里云上运行的容器</li>
</ul>
<p>Flannel通过在每一个节点上启动一个叫Flanneld的进程，负责每一个节点上的子网划分，并将相关的配置信息如各个节点的子网网段、外部IP等保存在etcd中，而具体的网络包转发给具体的Backend来实现</p>
<p>目前比较成熟的Backend有VxLAN、host-gw 以及UDP三种方式。Vxlan是目前官方推荐的一种backend实现方式，host-gw一般用于对网络性能要求高的场景，但需要基础架构本身的支持，UDP则一般用于Debug和一些比较老的不支持Vxlan的linux内核</p>
<h4 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h4><ul>
<li><p>当采用UDP模式时，flanneld进程在启动时会通过/dev/net/tun的方式生成一个TUN设备，TUN设备可以简单理解为linux当中提供的一种内核网络与用户空间（应用程序）通信的一种机制，即应用可以通过直接读写tun设备的方式手法RAW IP包。<br><img src="https://i.loli.net/2019/12/11/kpTQSUbo7vxFh2z.png" alt="image.png"></p>
</li>
<li><p>flanneld在整个过程中主要负责两个工作</p>
<ul>
<li>UDP封包解包</li>
<li>节点上的路由表动态更新</li>
</ul>
</li>
<li><p>从上面虚线部分就可以看到container A和container B虽然在物理网络上并没有直接相连，但在逻辑上就好像是处于同一个三层网络当中，这种基于底下的物理网络设备通过Flannel等软件定义网络技术实现的网络我们称之为Overlay网络</p>
</li>
<li><p>网络数据包先是通过tun设备从内核当中复制到用户态的应用，然后再有用户态的应用复制到内核，仅一次的网络传输就进行了两次用户态和内核态的切换，效率是不高的。</p>
</li>
<li><p>当flanneld启动时将创建VTEP设备（默认为flannel.1，若已经创建则跳过），并将VTEP设备的相关信息上报到etcd当中，而当在Flannel网络中有新的节点发现时，各个节点上的flanneld将依次执行以下流程</p>
<ol>
<li>在节点当中创建一条该节点所属网段的路由表，主要是能让Pod当中的流量路由到flannel.1接口。</li>
<li>在节点当中添加一条该节点的IP以及VTEP设备的静态ARP缓存。</li>
<li>在节点当中添加一条该节点的转发表</li>
</ol>
</li>
</ul>
<p><img src="https://i.loli.net/2019/12/11/DszrXUA2ejoP3kC.png" alt="image.png"></p>
<p>此时容器跨节点网络通信实现流程为：</p>
<ol>
<li>同UDP Backend模式，容器A当中的IP包通过容器A内的路由表被发送到cni0</li>
<li>到达cni0当中的IP包通过匹配host A当中的路由表发现通往10.244.2.194的IP包应该交给flannel.1接口</li>
<li>flannel.1作为一个VTEP设备，收到报文后将按照VTEP的配置进行封包，首先通过etcd得知10.244.2.194属于节点B，并得到节点B的IP，通过节点A当中的转发表得到节点B对应的VTEP的MAC，根据flannel.1设备创建时的设置的参数（VNI、local IP、Port）进行VXLAN封包</li>
<li>通过host A跟host B之间的网络连接，VXLAN包到达host B的eth1接口</li>
<li>通过端口8472，VXLAN包被转发给VTEP设备flannel.1进行解包</li>
<li>解封装后的IP包匹配host B当中的路由表（10.244.2.0），内核将IP包转发给cni0</li>
<li>cni0将IP包转发给连接在cni0上的容器B</li>
</ol>
<h4 id="host-gw"><a href="#host-gw" class="headerlink" title="host-gw"></a>host-gw</h4><p><img src="https://i.loli.net/2019/12/11/Z2Dl63Je1bfkYFp.png" alt="image.png"></p>
<ol>
<li>UDP、VXLAN模式一致，通过容器A的路由表IP包到达cni0</li>
<li>到达cni0的IP包匹配到host A当中的路由规则（10.244.2.0），并且网关为172.16.130.164，即host B，所以内核将IP包发送给host B（172.16.130.164）</li>
<li>IP包通过物理网络到达host B的eth1</li>
<li>到达host B eth1的IP包匹配到host B当中的路由表（10.244.2.0），IP包被转发给cni0</li>
<li>cni0将IP包转发给连接在cni0上的容器B</li>
</ol>
<ul>
<li>host-gw模式其中一个局限性就是，由于是通过节点上的路由表来实现各个节点之间的跨节点网络通信，那么就得保证两个节点是可以直接路由过去的。按照内核当中的路由规则，网关必须在跟主机当中至少一个IP处于同一网段，故造成的结果就是采用host-gw这种Backend方式时则集群中所有的节点必须处于同一个网络当中，这对于集群规模比较大时需要对节点进行网段划分的话会存在一定的局限性。另外一个则是随着集群当中节点规模的增大，flanneld需要维护主机上成千上万条路由表的动态更新也是一个不小的压力</li>
</ul>
<h4 id="VXLAN"><a href="#VXLAN" class="headerlink" title="VXLAN"></a>VXLAN</h4><ul>
<li>当采用Vxlan模式是，flanneld在启动时会通过Netlink机制与linux 内核通信，建立一个VTEP设备flannel.1(命名规则为flannel.[]VNI),VNI默认为1，类似于交换机种当中的一个网口</li>
</ul>
<h3 id="Openshift-SDN"><a href="#Openshift-SDN" class="headerlink" title="Openshift SDN"></a>Openshift SDN</h3><p>   基于VXLAN的二层+三层Overlay方案，同时支持network policy,数据平面基于OVS流表实现</p>
<ul>
<li>OVS-subnet(二层+三层Overlay，基于Vxlan)</li>
<li>ovs-multitenant (二层+三层Overlay，基于Vxlan)</li>
<li>ovs-networkpolicy</li>
</ul>
<h3 id="Kubnet-VPC自定义路由"><a href="#Kubnet-VPC自定义路由" class="headerlink" title="Kubnet + VPC自定义路由"></a>Kubnet + VPC自定义路由</h3><p>它会利用公有云平台本身自带的 VPC vRouter，配合 Kubernetes 自带的节点子网方式，用路由方式去完成整个容器网络的转发</p>
<ul>
<li>AWS VPC/Azure VPC/GCE VPC（二层+三层Underlay），需关闭源IP，目的IP检测</li>
</ul>
<h4 id="云化VPC场景存在的问题"><a href="#云化VPC场景存在的问题" class="headerlink" title="云化VPC场景存在的问题"></a>云化VPC场景存在的问题</h4><ol>
<li>需要两套网络策略，一套是VPC层的安全组等；另一套是kubernetes的network policy。管理成本较高</li>
<li>在BGP场景下，BGP Underlay即使能使用但无法跨越多AZ。跨越AZ一般意味着跨子网，跨子网意味着跨路由，但是VPC的vRouter一般不支持BGP。BGP underlay可以用，但也仅限于单AZ</li>
</ol>
<h4 id="VPC自定义路由的场景下的问题"><a href="#VPC自定义路由的场景下的问题" class="headerlink" title="VPC自定义路由的场景下的问题"></a>VPC自定义路由的场景下的问题</h4><ol>
<li>节点规模受限于路由表数量，一般厂商都会在100一下，AWS是50，阿里默认48</li>
<li>多次网络跳转，性能略有下降，节点层跳一次，在VPC里也要跳一次，使之性能有所影响</li>
</ol>
<h4 id="Overlay场景存在的问题"><a href="#Overlay场景存在的问题" class="headerlink" title="Overlay场景存在的问题"></a>Overlay场景存在的问题</h4><ol>
<li>两层Overlay开销问题</li>
<li>对于PPS敏感性业务，受影响较大</li>
</ol>
<h3 id="基于VPC深度集成的容器网络"><a href="#基于VPC深度集成的容器网络" class="headerlink" title="基于VPC深度集成的容器网络"></a>基于VPC深度集成的容器网络</h3><p> 基于VPC这种深度集成的容器网络，把VPC的能力上移到容器网络这一层，用VPC的能力去做转发和控制。如AWS EKS的VPC CNI插件，Azure AKS的VNET CNI插件。</p>
<ul>
<li>Kubernetes设计了Pod-Deployment-Service 经典三层服务访问机制</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/11/22/Flink/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/22/Flink/" itemprop="url">Flink</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-22T18:20:22+08:00">
                2019-11-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>人们对某件事的正确理解往往来自基于有效论据的结论。要获得这样的结论，最有效的方法就是沿着事件发生的轨迹进行分析。</p>
</blockquote>
<p><em>Apache Flink 是为分布式、高性能、随时可用以及准确的流处理应用程序打造的开源流处理框架。”Flink 不仅能提供同时支持高吞吐和 exactly-once 语义的实时计算，还能提供批量数据处理，这让许多人感到吃惊。鱼与熊掌并非不可兼得，Flink 用同一种技术实现了两种功能.</em><br><img src="https://i.loli.net/2019/11/06/uf9aliDmhCwSMVx.png" alt="image.png"></p>
<p><img src="https://i.loli.net/2019/11/06/R3OTbLF8BEnHZNl.png" alt="image.png"><br>Flink 技术栈的核心组成部分</p>
<ul>
<li>Flink 分别提供了面向流处理的接口（DataStream API）和面向批处理的接口（DataSet API）。因此，Flink 既可以完成流处理，也可以完成批处理。Flink 支持的拓展库涉及机器学习（FlinkML）、复杂事件处理（CEP），以及图计算（Gelly），还有分别针对流处理和批处理的 Table<br>Flink 将批处理（即处理有限的静态数据）视作一种特殊的流处理<br>流处理技术三大核心关键技术点：</li>
<li>低延迟</li>
<li>高吞吐</li>
<li>Exactly once </li>
</ul>
<h3 id="Flink-Application"><a href="#Flink-Application" class="headerlink" title="Flink Application"></a>Flink Application</h3><ul>
<li><strong>Streams</strong>: 流，分为有限数据流与无限数据流，unbounded stream是有始无终的数据流，即无线数据流；而bounded stream是限定大小的有始有终的数据集合，即有限数据流，二者的区别在于无限数据流的数据会随时间的推演而持续增加，计算持续进行而不存在结束状态，相对的有限数据流数据大小固定，计算最终会完成并处于结束的状态。</li>
<li><strong>State</strong>：状态时计算过程中的数据信息，在容错恢复和Checkpoint中有重要的作用，流计算在本质上是Incremental Processing，因此需要不断查询保持状态；另外，为了确保Exactly-once语义，需要数据能够写入到状态中；而持久化存储，能够保证在整个分布式系统运行失败或挂掉的情况下做到Exactly-once，这是状态的另外一个价值。</li>
<li><strong>Time</strong>： 分为Event time、Ingestion time、Processing time，Flink的无限数据流是一个持续的过程，时间是我们判断业务状态是否滞后，数据处理是否及时的重要依据。</li>
<li><strong>API</strong>：API通常分为三层，有上而下可分为SQL/Table API、DataStream API、ProcessFunction三层，API的表达能力以及业务抽象能力都非常强大，但越接近SQL层，表达能力会逐步减弱，抽象能力增强，反之，ProcessFunction层API的表达能力非常强，可以进行多种灵活方便的操作，但抽象能力也相对越小</li>
</ul>
<p><img src="https://i.loli.net/2019/11/06/qOtyN3vPW6GcXhV.png" alt="image.png"></p>
<h4 id="无界流和有界流"><a href="#无界流和有界流" class="headerlink" title="无界流和有界流"></a>无界流和有界流</h4><ol>
<li>无界流有一个开始但没有定义的结束。它不会在生成时终止并提供数据。必须持续处理无界流，即必须在摄取事件后立即处理事件。无法等待所有输入数据到达，因为输入时无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序（例如事件发生的顺序）摄取事件，以便能够推官结果完整性。</li>
<li>有界流具有定义的开始和技术。可以在执行任何计算之前通过摄取所有数据来处理有界流。处理有界流不需要有序摄取，因为可以始终对有界数据集进行排序。有界流的处理也称为批处理。<br><img src="https://i.loli.net/2019/11/07/Mdiyv4XONjcF8IW.png" alt="bounded-unbounded.png"></li>
</ol>
<blockquote>
<p>Flink擅长处理无界和有界数据集。精确控制时间和状态使Flink的运行时能够在无界流上运行任何类型的应用程序。有界流由算法和数据结构内部处理，这些算法和数据结构专门针对固定大小的数据集而设计，从而产生出色的性能。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算</p>
</blockquote>
<h4 id="利用内存中的性能"><a href="#利用内存中的性能" class="headerlink" title="利用内存中的性能"></a>利用内存中的性能</h4><ul>
<li>有状态Flink应用程序针对本地状态访问进行优化。任务状态始终保留在内存中，或者，如果状态大小超过可用内存，则保存在访问高效的磁盘数据结构中。因此任务通过本地（通常是内存中）状态来执行所有计算，从而产生非常低的处理延迟。Flink通过定期和异步检查本地状态到持久存储来保证在出现故障时的状态一致性。</li>
</ul>
<p><img src="https://i.loli.net/2019/11/07/OAZviY8JMDkdjcR.png" alt="local-state.png"></p>
<h4 id="Flink的架构"><a href="#Flink的架构" class="headerlink" title="Flink的架构"></a>Flink的架构</h4><p><img src="https://i.loli.net/2019/11/07/3cSyqhnsDiRlOXw.png" alt="1385722-20180510153610561-553418073.png"><br>Flink 可以支持本地的快速迭代，以及一些环形的迭代任务。并且Flink可以定制化内存管理。相比Spark来讲，Flink并没有将内存完全交给应用层，减少出现OOM。</p>
<h4 id="Flink工作原理"><a href="#Flink工作原理" class="headerlink" title="Flink工作原理"></a>Flink工作原理</h4><p><img src="https://i.loli.net/2019/11/07/snbjqkEWU7LOKHe.png" alt="15934580-5f02fc45c0dad61f.png"></p>
<ul>
<li><p>JobClient:</p>
<ul>
<li>负责接收程序，解析和优化程序的执行计划，然后执行计划到JobManager。这里执行的程序优化是将相邻的Operator融合，形成OperationChain，Operator的融合可以减少task的数量，提高TaskManager的资源利用率。</li>
</ul>
</li>
<li><p>JobManager:</p>
<ul>
<li>负责申请资源，协调以及控制整个job的执行过程，具体包括，调度任务、处理checkpoint、容错等等</li>
</ul>
</li>
<li><p>TaskManager:</p>
<ul>
<li>TaskManager运行在不同节点上的JVM进程（process），负责接收并执行JobManager发送的task，并且与JobManager通信，反馈任务状态信息，如果说JobManager是Master的话，那么TaskManager就是Worker用于执行任务。每个TaskManager像是一个容器，包含一个或多个Slot </li>
</ul>
</li>
<li><p>Slot：</p>
<ul>
<li>lot是TaskManager资源粒度的划分，每个Slot都有自己独立的内存。所有Slot平均分配TaskManager的内存，值得注意的是，Slot仅划分内存，不涉及cpu的划分。每个Slot可以运行多个task。Slot的个数就代表了一个程序的最高并行度</li>
</ul>
</li>
<li><p>Task:</p>
<ul>
<li></li>
</ul>
</li>
</ul>
<h4 id="Flink生态圈"><a href="#Flink生态圈" class="headerlink" title="Flink生态圈"></a>Flink生态圈</h4><h4 id="抽象层API"><a href="#抽象层API" class="headerlink" title="抽象层API"></a>抽象层API</h4><p><img src="https://i.loli.net/2019/11/07/mBKpq1tnx3IahNc.png" alt="image.png"></p>
<ol>
<li>DataSet API：对静态数据进行批处理操作，将静态数据抽象成分布式的数据集，用户可以方便地使用Flink提供的各种操作符对数据集进行处理，支持Java、Scala和Python</li>
<li>DataStream API：对数据流进行流处理操作，将流式的数据抽象成分布式的数据流，用户可以方便地对分布式数据流进行各种操作，支持Java和Scala</li>
<li>Table API：对结构化数据进行查询操作，将结构化数据抽象成关系表，并通过类SQL的DSL对关系表进行各种查询操作，支持Java和Scala</li>
<li>Flink ML：Flink的机器学习库，提供了机器学习Pipelines API并实现了多种机器学习算法</li>
<li>Gelly：Flink的图计算库，提供了图计算的相关API及多种图计算算法实现</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/11/22/Flume/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/22/Flume/" itemprop="url">Flume</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-22T18:17:50+08:00">
                2019-11-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote>
<p>Flume 是一种分布式，可靠且可用的服务，用于有效地收集，聚合和移动大量日志数据。具有基于流数据的简单灵活的架构、可靠的可靠性机制和许多故障转移和恢复机制，以及强大的容错性。使用简单的可扩展数据模型，允许在线分析数据。很多大数据分析都通过flume来获取数据的输入。</p>
</blockquote>
<h1 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h1><ul>
<li><strong>Event</strong>：消息的基本单位，有header和body组成</li>
<li><strong>Agent</strong>：一个独立JVM进程，负责将一段外部来源产生的消息转发到另一端外部的目的地。在分布式部署中，每个节点部署一个Agent。多个Agent就组成了Flume的分布式系统</li>
</ul>
<h2 id="Agent（代理）"><a href="#Agent（代理）" class="headerlink" title="Agent（代理）"></a>Agent（代理）</h2><p>Flume运行的核心就是Agent。Fume以Agent为最小的独立运行单位。一个agent就是一个JVM。它是一个完整的数据收集工具，含有三个核心部件，分别是source、channel、sink。通过这些组件，Event可以从一个地方流到另一个地方，如下图所示：<br><img src="https://i.loli.net/2019/11/21/RtDiFsyTKCPUwjY.png" alt="image.png"></p>
<p>一个Agent中source、channel、sink数量可以有多个，他们可相互组合使用，比如一个source对应多个channel，一个channel对应多个sink。</p>
<h2 id="Source（源）"><a href="#Source（源）" class="headerlink" title="Source（源）"></a>Source（源）</h2><p>Source是数据的手机端，负责将数据捕获后进行特殊格式化，将数据封装到事件（event）里，然后将事件推入Channel中。Flume提供了很多内置的Source，支持Avro，log4j，syslog和http post(body为json格式)，可以让应用程序同已有的source直接打交道，如AvroSource，SyslogTcpSource。如果内置的Source无法满足需要，Flume还支持自定义Source</p>
<h2 id="Channel（通道）"><a href="#Channel（通道）" class="headerlink" title="Channel（通道）"></a>Channel（通道）</h2><p>channel是连接source和sink的组件，大家可以将它看作是一个数据的缓冲区（数据队列），它可以将事件暂存在内存中也可以持久化到本地磁盘上，直到sink处理完该事件。</p>
<p>Flume提供了多种内置channel类型，如memorychannel和Filechannel，也支持用户自定义Channel</p>
<h2 id="Sink（接收器）"><a href="#Sink（接收器）" class="headerlink" title="Sink（接收器）"></a>Sink（接收器）</h2><p>Sink从channel中提取出事件，然后将数据发到别处，可以向文件系统、数据库、hadoop存数据，也可以是其他Flume agent的source。</p>
<h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><ol>
<li>多个agent顺序连接</li>
</ol>
<p><img src="https://i.loli.net/2019/11/21/yf8lXGi23PeFROH.png" alt="image.png"></p>
<p>可以将多个agent顺序连接起来，将最初的数据源经过收集，存储在最终的存储系统中。这是最简单的情况，一般情况下，应该控制这种顺序连接的agent的数量，因为数据流经过的路径变长了，出现故障将影响整个Flow上的agent收集服务</p>
<ol start="2">
<li>多个agent的数据汇聚到同一个agent</li>
</ol>
<p><img src="https://i.loli.net/2019/11/21/QJCsHYxNXc8FRT1.png" alt="image.png"></p>
<p>这种情况应用的场景比较多，比如要收集web网站的用户行为日志，web网站为了可用性使用的负载集群模式，每个节点都产生用户行为日志，可以为每个节点都配置一个Agent来单独收集日志数据，然后多个Agent将数据最终汇聚到一个用来存储数据存储系统上，如HDFS</p>
<ol start="3">
<li>多级流</li>
</ol>
<p><img src="https://i.loli.net/2019/11/21/5A8yVi42QEfNLtv.png" alt="image.png"></p>
<p>结合在云开发中的应用来举个例子，当syslog， java， nginx、 tomcat等混合在一起的日志流开始流入一个agent后，可以agent中将混杂的日志流分开，然后给每种日志建立一个自己的传输通道。</p>
<ol start="4">
<li>load balance 功能</li>
</ol>
<p><img src="https://i.loli.net/2019/11/21/UOa9vZtuGgoHWDb.png" alt="image.png"><br> Agent1是一个路由节点，负责将channel暂存在event均衡到对应的多个sink组件上，而每个sink组件分别连接到一个独立的agent上，这样祈祷负荷分担的效果。</p>
<h1 id="Flume拦截器、数据流以及可靠性"><a href="#Flume拦截器、数据流以及可靠性" class="headerlink" title="Flume拦截器、数据流以及可靠性"></a>Flume拦截器、数据流以及可靠性</h1><h2 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h2><p>   当我们需要对数据进行过滤时，除了在source、channel和sink进行代码修改之外，Flume为我们提供了拦截器，拦截器也是chain形式的。</p>
<p>   拦截器的位置在source和channel之间，当我们为source指定拦截器之后，我们在拦截器中会得到event，根据需求可以对event进行保留还是抛弃，抛弃的数据不会进入channel中</p>
<p><img src="https://i.loli.net/2019/11/21/8HOFTYIvzj3Xxkg.png" alt="image.png"></p>
<h2 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h2><ol>
<li><p>flume的核心是把数据收集过来，再送到目的地。为了保证输送一定成功，在送到目的地之前，会先缓存数据，待数据真正到达目的地后，删除自己缓存的数据</p>
</li>
<li><p>flume传输的数据的基本单位是event，如果是文本文件，通常是一行记录，这也是事务的基本单位。Event从Source，流向channel，再到sink；本身为一个byte数组，并可携带header信息。event代表着一个数据流的最小完整单元。</p>
<h2 id="Flume可靠性"><a href="#Flume可靠性" class="headerlink" title="Flume可靠性"></a>Flume可靠性</h2><p>Flume 使用事务性的方式保证传送Event整个过程的可靠性。Sink必须在event被存入channel后，或者，已经被传达到下一站agent里，又或者，已经被存入外部数据目的地之后，才能把event从channel中remove 掉。这样数据流里的event无论是在一个agent还是多个agent之间流转，都能保证可靠，因为在以上的事务保证了event会被成功存储起来。比如 Flume支持在本地保存一份文件 channel 作为备份，而memory channel 将 event存在内存 queue 里，速度快，但丢失的话无法恢复。</p>
</li>
</ol>
<h1 id="Flume与kafka对比"><a href="#Flume与kafka对比" class="headerlink" title="Flume与kafka对比"></a>Flume与kafka对比</h1><ol>
<li>Kafka是分布式消息中间件，自带存储，提供push和pull存取数据功能。Flume分为agent（数据采集器），collector（数据简单处理和写入），storage（存储器）三部分，每一部分都是可以定制的。比如agent采用RPC（Thrift-RPC）、text（文件）等，storage指定用hdfs做。</li>
<li>Kafka做日志缓存应该是更合适的，但是flume的数据采集部分做的很好，可以定制很多数据源，减少开发量。比较六次那个flume+kfka模式，如果为了利用flume写hdfs的能力，也可以采用kfaka+flume方式</li>
</ol>
<p>采集层主要可以使用Flume，Kafka两种技术。</p>
<p>Flume：Flume是管道流方式，提供了很多默认实现，让用户通过参数部署，及扩展API</p>
<ul>
<li>Kafka是一个非常通用的系统。可以有许多生产者和消费者共享多个主题topic。相比之下，flume是一个专用工具被设计旨在往HDFS，HBase发送数据。它对HDFS有特殊的优化，并且集成了Hadoop的安全特性。所以，如果数据被多个系统消费的话，使用kfaka；数据设计给HadooP使用，使用Flume</li>
<li>Flume可以使用拦截器实时处理数据，这些对数据屏蔽或者过滤是很有用的。Kafka需要外部的流处理系统才能做到。</li>
<li>Kafka和Flume都是可靠的系统，通过适当的配置能保证零数据丢失。然而，Flume不支持副本事件。于是，如果Flume代理的节点崩溃，即使使用了可靠的文件管道方式，也将丢失这些事件知道回复这些磁盘。如果需要高可靠的管道，使用Kafka。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/11/15/DynamoDB-DeepDive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/15/DynamoDB-DeepDive/" itemprop="url">DynamoDB DeepDive</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-15T16:58:42+08:00">
                2019-11-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS/" itemprop="url" rel="index">
                    <span itemprop="name">AWS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="table"><a href="#table" class="headerlink" title="table"></a>table</h3><p><img src="https://i.loli.net/2019/11/14/vrweiudKH1UpBXO.png" alt="ScreenShot_20191114105742.png"></p>
<ul>
<li>Item attributes 条目 属性</li>
<li>分区键（Range key）：必须指定，键值访问方式，决定数据如何分布</li>
<li>排序键(Sort key):可选，用于1：N的关系，提供很多查询优化的能力</li>
</ul>
<h3 id="分区键"><a href="#分区键" class="headerlink" title="分区键"></a>分区键</h3><ul>
<li>分区键唯一的标识一条记录</li>
<li>分区键用来构建一个非排序的散列索引（对比关系型数据库采用二叉树索引）</li>
<li>使得表可以进行分区，从而满足扩展性的需求<br><img src="https://i.loli.net/2019/11/14/82bFoRPshZlHyiY.png" alt="ScreenShot_20191114110301.png"></li>
</ul>
<h3 id="分区键：排序键"><a href="#分区键：排序键" class="headerlink" title="分区键：排序键"></a>分区键：排序键</h3><ul>
<li>分区键和排序键共同唯一的标识一条记录</li>
<li>在一个分区键决定的散列索引里，数据按照排序键进行排列</li>
<li>每个排序键所对应的数据行数没有上限<ul>
<li>除非有本地二级索引（local seconday indexs）<br><img src="https://i.loli.net/2019/11/14/HZh1liAeurkKqtF.png" alt="ScreenShot_20191114110313.png"></li>
</ul>
</li>
</ul>
<h3 id="本地二级索引-Local-Secondary-Index（LSI）"><a href="#本地二级索引-Local-Secondary-Index（LSI）" class="headerlink" title="本地二级索引-Local Secondary Index（LSI）"></a>本地二级索引-Local Secondary Index（LSI）</h3><ul>
<li>可以选择与表不同的排序键</li>
<li>每个表分区对应一个索引分区</li>
<li>每个分区键可以存储最多10Gb的数据，包括表分区和索引分区的数据量</li>
<li>使用的是表上定义的RCU和WCU</li>
<li>强一致性<br><img src="https://i.loli.net/2019/11/14/DlZjWkFiLyhTsmU.png" alt="ScreenShot_20191114110453.png"></li>
<li>keys_only 存在回表的可行性</li>
<li>include 或all 存在空间的浪费</li>
</ul>
<h3 id="全局二级索引-Glocal-Secondary-Index（GSI）"><a href="#全局二级索引-Glocal-Secondary-Index（GSI）" class="headerlink" title="全局二级索引-Glocal Secondary Index（GSI）"></a>全局二级索引-Glocal Secondary Index（GSI）</h3><ul>
<li>可以选择与表不同的分区键以及排序键</li>
<li>每个索引分区会对应所有的表分区</li>
<li>GSI的RCUs和WCUs 是独立于表的容量而单独计算的</li>
<li>索引的尺寸没有上限</li>
<li>只支持最终一致性</li>
<li>GSI的更新是由dynamoDB自行维护（异步方式，由client发起更新操作）<br><img src="https://i.loli.net/2019/11/14/7kwnE8AxBcSJtPC.png" alt="ScreenShot_20191114110817.png"></li>
</ul>
<h3 id="预置容量"><a href="#预置容量" class="headerlink" title="预置容量"></a>预置容量</h3><p>在表级别或者GSI级别设置读写容量</p>
<ul>
<li>写容量单位（write capacity  units：WCUs）按照每秒1KB进行计算</li>
<li>读容量单位（read capacity  units：WCUs）按照每秒4KB进行计算<ul>
<li>RCUs按照强一致性读进行计算</li>
<li>如果是最终一致性，则RCU double（8KB）</li>
</ul>
</li>
<li>读写吞吐量是独立计算的</li>
</ul>
<h3 id="分区计算公式"><a href="#分区计算公式" class="headerlink" title="分区计算公式"></a>分区计算公式</h3><p>| <strong>分区个数</strong>                                   |   |   |<br>|——–|————————————-|—|—|<br>| 按照容量计算 | (Total RCU/3000）+（Total WCU/1000） |   |   |<br>| 按照尺寸计算 | Total Size /10GB                    |   |   |<br>| 分区数量   | CEILING(MAX(Capacity,Size))     |   |   |<br>|        |                                     |   |   |</p>
<h4 id="sample"><a href="#sample" class="headerlink" title="sample"></a>sample</h4><p><img src="https://i.loli.net/2019/11/14/pXUQinZr8OH4KcF.png" alt="ScreenShot_20191114111818.png"></p>
<h3 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h3><p> 如果吞吐量持续的超过分区上预置的吞吐量，则发生限流。限流的主要原因包括：</p>
<ul>
<li><p>不平均的工作负载</p>
</li>
<li><p>存在热键或者热分区</p>
</li>
<li><p>存在非常大的记录<br><img src="https://i.loli.net/2019/11/14/kKdMEavUGDIVXfx.png" alt="ScreenShot_20191114112029.png"></p>
<h3 id="计算表或索引的容量"><a href="#计算表或索引的容量" class="headerlink" title="计算表或索引的容量"></a>计算表或索引的容量</h3></li>
</ul>
<ol>
<li>计算RCU和WCU</li>
<li>计算每秒发出的读或写的记录数量</li>
<li>计算每条记录上的读写活动的数量</li>
<li>每秒读写的记录数乘以每条记录上读写活动的数量</li>
<li>对于读来说，如果是最终一致性则实际需要的RCU可以减半</li>
<li>sample<br><img src="https://i.loli.net/2019/11/14/b7nD63k9sZourBJ.png" alt="ScreenShot_20191114112336.png"></li>
</ol>
<ul>
<li><p><strong>注意：不要忘记LSI以及需要独立计算容量的GSI</strong></p>
<h3 id="DynamoDB-的自动伸缩"><a href="#DynamoDB-的自动伸缩" class="headerlink" title="DynamoDB 的自动伸缩"></a>DynamoDB 的自动伸缩</h3></li>
</ul>
<ul>
<li>DynamoDB能够根据工作负载进行自动伸缩</li>
<li>使用自动伸缩时，需要自定义伸缩策略，包括目标使用率、最小预置容量以及最大预置容量</li>
<li>可以分别为读和谐自定义伸缩策略。也可以为GSI配置与表相同的自动伸缩策略</li>
</ul>
<p><img src="https://i.loli.net/2019/11/14/Pw9iKWgMnqakvSF.png" alt="ScreenShot_20191114112742.png"></p>
<h3 id="最佳模式实践"><a href="#最佳模式实践" class="headerlink" title="最佳模式实践"></a>最佳模式实践</h3><h4 id="最佳实践1：慎重选择Hash-Key以实现无限扩展"><a href="#最佳实践1：慎重选择Hash-Key以实现无限扩展" class="headerlink" title="最佳实践1：慎重选择Hash Key以实现无限扩展"></a>最佳实践1：慎重选择Hash Key以实现无限扩展</h4><p>避免热键</p>
<ul>
<li>好的散列键（hash key）的取值范围很大；不好的散列键只能有有限的值</li>
<li>选择能将负载均衡分布到不同分区的散列键（访问模式）</li>
</ul>
<h4 id="如何存储大项目"><a href="#如何存储大项目" class="headerlink" title="如何存储大项目"></a>如何存储大项目</h4><ul>
<li>把大项目分开存储在另一张表<br><img src="https://i.loli.net/2019/11/14/u5Jfm7gn4Kerdva.png" alt="ScreenShot_20191114113139.png"></li>
<li>把大项目存储在S3 <ul>
<li>基表也做相应修改，大的属性值存在S3<br><img src="https://i.loli.net/2019/11/14/1FmKQrBucMACT3a.png" alt="ScreenShot_20191114113257.png"></li>
</ul>
</li>
</ul>
<ul>
<li>每条记录的大小限制（400KB），但是记录的数目无限制<ul>
<li>讲一个大的属性分开存储在分开的表格中</li>
<li>将大的记录分成多个小的记录</li>
<li>将image/media 等大文件存储在S3</li>
</ul>
</li>
</ul>
<ul>
<li>将查询分散到不同分区，降低对单一分区的读写吞吐量，从而降低对整表的吞吐量要求</li>
</ul>
<h4 id="最佳实践：使用Time-Series表格存储时序型数据"><a href="#最佳实践：使用Time-Series表格存储时序型数据" class="headerlink" title="最佳实践：使用Time-Series表格存储时序型数据"></a>最佳实践：使用Time-Series表格存储时序型数据</h4><ul>
<li><p>适应于类似日志，点击行为，浏览行为，交易记录，操作记录等数据</p>
<ul>
<li>对于应用倾向于访问最近的数据，而老的数据访问很少或者根本不再访问的场景，应该将热数据和冷数据分别存储在不同表格中，这样就可以对热数据表格配置高的吞吐量，冷数据表格配置低的吞吐量</li>
<li>预先创建每天，每周或每月的表格，对当前表格配置需要的吞吐量，新的数据斜土当前表格，降低历史数据表格的吞吐量</li>
</ul>
</li>
<li><p>对每个时间段创建一张表</p>
<h4 id="最佳实践：如何处理多个属性为条件的查询"><a href="#最佳实践：如何处理多个属性为条件的查询" class="headerlink" title="最佳实践：如何处理多个属性为条件的查询"></a>最佳实践：如何处理多个属性为条件的查询</h4><ul>
<li>Query filter<ul>
<li>简化应用代码</li>
<li>简单的类似SQL语句的表达式：AND，OR，NOT，（）</li>
</ul>
</li>
<li>组合键（重新设计表把两个旧表字冠组合为一个新的字段Sortkey，减少RCU）</li>
</ul>
<h3 id="DynamoDB流"><a href="#DynamoDB流" class="headerlink" title="DynamoDB流"></a>DynamoDB流</h3><ul>
<li>针对表里数据变化的顺序记录</li>
<li>在流里，针对表的变化的记录只出现一次</li>
<li>在流里的记录的顺序与表上发生修改操作的顺序是一致的</li>
<li>流里的数据保存24小时，24H后自动删除</li>
<li>可以把表的数据被更新前的值以及更新后值都写在流里</li>
<li>流里的数据通过API进行消费</li>
</ul>
</li>
</ul>
<h4 id="访问DynamoDB流记录"><a href="#访问DynamoDB流记录" class="headerlink" title="访问DynamoDB流记录"></a>访问DynamoDB流记录</h4><ul>
<li>DynamoDB和DynamoDB流记录使用了不同的终端节点</li>
<li>流的终端节点命名规则为streams.dynamodb.<region>.amazonaws.com</region></li>
<li>使用dynamoDB Streans Kenesis Adapter来访问流记录。同时实现了Kinesis Data Streams接口，因此可使用Kinesis KCL消费来自dynamoDB 流的记录</li>
<li>也可以使用DynamoDB 流的low-level API来消费流记录<br><img src="https://i.loli.net/2019/11/14/jo32XTgPyUVReHJ.png" alt="ScreenShot_20191114114637.png"></li>
</ul>
<h4 id="流里记录的数据内容"><a href="#流里记录的数据内容" class="headerlink" title="流里记录的数据内容"></a>流里记录的数据内容</h4><p>四种写入的数据内容</p>
<ul>
<li>keys_only：只有分区键和排序键的数据被写入</li>
<li>new_image:修改前的整条记录都被写入流</li>
<li>old_image:修改后的整条记录都被写入流</li>
<li>new_and_old_iamges:修改前和修改后的整条记录都被写入流</li>
</ul>
<h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><ul>
<li>表之间的数据复制</li>
<li>触发器</li>
<li>容灾和多区域复制</li>
<li>数据汇总</li>
<li>数据安全和通知</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/11/06/Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/06/Kafka/" itemprop="url">Kafka</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-06T19:07:37+08:00">
                2019-11-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>Kafka 是一个分布式、分区的、多副本、多订阅者，基于zoopkeeper协调的分布式他日志系统（也可以当作MQ系统），常见用于web/nginx日志、访问日志、消息服务等等。</em></p>
<blockquote>
<p>主要用于<font color="red"><strong>日志收集系统和消息系统</strong></font></p>
</blockquote>
<h2 id="Kafka设计目标"><a href="#Kafka设计目标" class="headerlink" title="Kafka设计目标"></a>Kafka设计目标</h2><ul>
<li>以时间复杂度为O（1）的方式提供消息持久化能力，即使PB级以上的数据也能保证常数时间的访问性能</li>
<li>高吞吐率。即使在非常廉价的商业机器上也能做到单机支持美妙100K条消息的传输</li>
<li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partion内的<font color="green"><strong>消息顺序传输</strong></font></li>
<li>同时支持离线数据处理和实时数据处理</li>
<li>Scale Out：支持水平扩展</li>
</ul>
<h2 id="消息系统介绍"><a href="#消息系统介绍" class="headerlink" title="消息系统介绍"></a>消息系统介绍</h2><p>一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用之间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。两种主要传递模式：<font color="green"><strong>点对点、发布-订阅。</strong></font></p>
<p>Kafaka 架构图<br><img src="https://i.loli.net/2019/11/05/ALvIx89ZG7n6Ywb.png" alt="image.png"></p>
<blockquote>
<p>Kafaka运行在集群上，集群中包含一个或多个度武器。Kafka把消息存在topic中，每一条消息包含键值（key）,值（value）和时间戳（timestamp）</p>
</blockquote>
<h2 id="Kafak组件"><a href="#Kafak组件" class="headerlink" title="Kafak组件"></a>Kafak组件</h2><ul>
<li>Consumergroup: 各个consumer（consumer线程）可以组成一个组（Consumer Group），Partion中的每个message只能被组（consumer group）中的一个consumer（consumer线程）消费，如果一个message可以被多个consumer（consumer线程）消费的话，那么这些consumer必须在不同的组。</li>
<li>Procuder：复杂发布消息到Kafka broker，push</li>
<li>Consumer： 消息消费者，从kafka broker读取消息的客户端，pull数据，主动去broker拉数据</li>
<li>Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>
<li>partion：主题，由用户定义并配置的kafka服务器，用于建立Producer和Consumer之间的订阅关系。生产者发送消息到指定的Topic下，消费者从这个Topic下消费消息。一个topic可以有多个Partion。每一条消息发送到 broker 时，会根据 partition 的规则选择存储到哪一个 partition。如果 partition 规则设置合理，那么所有的消息会均匀的分布在不同的partition中。</li>
<li>Offset：每一个partion都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partion中。partion中的每个消息都有一个连续的序列号叫做offset，用于partion唯一标识一条消息。只保证分区内顺序，不跨分区。</li>
<li>Message： Kafaka中的最基本数据单元，主要由key和alue构成：真正有效的消息是alue数据，key只做为消息路由分区使用， kafka根据key决定将当前消息存储在那个那个分区</li>
</ul>
<h2 id="消息处理发送与分区存储"><a href="#消息处理发送与分区存储" class="headerlink" title="消息处理发送与分区存储"></a>消息处理发送与分区存储</h2><h3 id="消息发送"><a href="#消息发送" class="headerlink" title="消息发送"></a>消息发送</h3><ul>
<li>异步发送，较细防区后台队列，然后由单独线程去从队列中取出消息然后发出<h3 id="消息分区路由"><a href="#消息分区路由" class="headerlink" title="消息分区路由"></a>消息分区路由</h3></li>
<li>如果在发消息的时候指定了分区，则消息投递到指定的分区</li>
<li>如果没有指定分区，但是消息的key不为空，则基于key的哈希值来选择一个分区</li>
<li>如果既没有指定分区，且消息的key也是空，则用轮询的方式选择一个分区根据key进行哈希取<h3 id="消息存储"><a href="#消息存储" class="headerlink" title="消息存储"></a>消息存储</h3></li>
<li>消息全部持久化到磁盘，其使用日志文件的方式来保存。Partion以文件的形式存储在文件系统中。<h3 id="消息消费"><a href="#消息消费" class="headerlink" title="消息消费"></a>消息消费</h3></li>
<li>同一时刻，一条消息只能被group中的一个消费者实例消费，一个topic下的每个partition只从属于group中的一个消费者，不可能出现group中的两个消费者消费同一个分区。</li>
</ul>
<h3 id="Partion的高可用副本机制"><a href="#Partion的高可用副本机制" class="headerlink" title="Partion的高可用副本机制"></a>Partion的高可用副本机制</h3><p>Kafka通过副本机制来实现冗余备份。每个分区可以有多个副本，并且在副本集合中会存在一个leader的副本，所有读写请求都是由leader副本来进行处理。其他副本为follow副本，follower副本会从leader副本同步消息日志</p>
<h4 id="副本分配算法"><a href="#副本分配算法" class="headerlink" title="副本分配算法"></a>副本分配算法</h4><ul>
<li>leader 副本：响应 clients 端读写请求的副本</li>
<li>follower 副本：被动地备份 leader 副本中的数据，不能响应 clients 端读写请求</li>
<li>ISR 副本：包含了 leader 副本和所有与 leader 副本保持同步的 follower 副本</li>
<li>leader 负责维护和跟踪 ISR(in-Sync replicas ， 副本同步队列)中所有 follower 的状态。当 producer 发送一条消息到 broker 后，leader 写入消息并提交之后才会复制到所有的同步 follower 副本中<h4 id="副本协同机制"><a href="#副本协同机制" class="headerlink" title="副本协同机制"></a>副本协同机制</h4></li>
<li>写请求首先由 Leader 副本处理，之后 follower 副本会从 leader 上拉取写入的消息，这个过程会有一定的延迟，导致 follower 副本中保存的消息略少于 leader 副本，但是只要没有超出阈值都可以容忍。但是如果一个 follower 副本出现异常，比如宕机、网络断开等原因长时间没有同步到消息，那这个时候，leader 就会把它踢出去。<h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h4></li>
<li>kafka 通过 ISR 集合来维护一个分区副本信息。ISR 表示目前“可用且消息量与 leader 相差不多的副本集合，这是整个副本集合的一个子集</li>
</ul>
<h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><h4 id="无状态的Broker"><a href="#无状态的Broker" class="headerlink" title="无状态的Broker"></a>无状态的Broker</h4><ol>
<li>Broker没有副本机制，一旦broker宕机，该broker的消费将都不可用</li>
<li>broker不保存订阅者的状态，由订阅者自己保存</li>
<li>无状态导致消息的删除成为难题（可能删除的消息正在被请阅），kafka采用基于时间的SLA,消息保存一定时间（通常为7天）后会删除</li>
<li>消息订阅者可以rewind back到任意位置重新进行消费，当订阅者故障时，可以选择需ixiaodeoffset进行重新读取消费消息<h4 id="message的交付与生命周期"><a href="#message的交付与生命周期" class="headerlink" title="message的交付与生命周期"></a>message的交付与生命周期</h4></li>
<li>不是严格的JMS，因此kafka对消息的重复、丢失、错误以及顺序行没有严格要求（<font color="red">这是与AMQ最大的区别</font>）</li>
<li>kafka 提供at-least-once delivery，即当consumer宕机后，有些消息可能会被重复delivery</li>
<li>因每个partion知会被consumer group内一个consumer消费，因此kafka保证每个partion内的消息会被顺序订阅</li>
<li>kafka为每条消息计算CRC校验，用于错误检测，crc校验不通过的消息会直接被丢弃掉</li>
</ol>
<blockquote>
<p>Kafka将数据写到磁盘，实际上都会写到OS的page cache里， 而读的时候又用sendfile非常高效的将数据传输到NIC。Kafka的扩展性也非常好，只要增加broker即可。Kafka的逻辑也非常清晰，可以将不同业务逻辑的数据写进不同到topic，而topic又可以切分成若干个partition来并行处理，并且Kafka0.9后，zk只需要被broker所使用，consumer并不再需要使用zk来记录offset，大大降低zk的压力，同时也从侧面降低了scale的压力。Kafka也有比较友好的删除策略。可以直接按照max age或者max size自动删除，也可以按照key进行compact，基本上都能满足需求</p>
</blockquote>
<h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><ul>
<li>日志收集 ：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、HBase、Solr等</li>
<li>消息系统：解耦生产者与消费者、缓存消息</li>
<li>用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘</li>
<li>运营指标：Kafka也经常用来记录运营数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。</li>
<li>流式处理： 比如spark streaming和Flink</li>
</ul>
<h4 id="Kafka缺点"><a href="#Kafka缺点" class="headerlink" title="Kafka缺点"></a>Kafka缺点</h4><ul>
<li>由于是批量发送，数据并非真正的实时；</li>
<li>对于MQTT协议不支持</li>
<li>不支持物联网传感数据直接接入</li>
<li>仅支持同一分区内消息有序，无法实现全局消息有序</li>
<li>监控不完善，需要安装插件</li>
<li>依赖Zookeeper进行元数据管理</li>
</ul>
<h4 id="Kafka幂等性实现原理（Producer）"><a href="#Kafka幂等性实现原理（Producer）" class="headerlink" title="Kafka幂等性实现原理（Producer）"></a>Kafka幂等性实现原理（Producer）</h4><p>实现米等的关键点就是服务端可以区分请求是否重复，过滤掉重复请求。区分请求是否重复有两点：</p>
<ul>
<li>唯一标识：要想区分请求是否重复，请求中就得有唯一标识。例如支付请求中，订单号就是唯一标识</li>
<li>记录下已处理过的请求标识：单有唯一标识还不够，还需要记录下那些请求是已经处理过的，这样当收到新的请求时，用新请求中的标识和处理记录进行比较，如果处理记录中有相同的标识，说明是重复交易，拒绝掉</li>
</ul>
<blockquote>
<p>为了实现Producer的幂等性，kafka引入Producer ID（即PID）和Sequence Number</p>
<ul>
<li>PID：每个新的Producer在初始化的时候会被分配一个唯一的PID，这个PID对用户是不可见的</li>
<li>Sequence Number（对于每个PID，该Producer发送数据的每个&lt;Topic，Partion&gt;都对应一个从0开始单调递增的Sequence Number）</li>
</ul>
</blockquote>
<h4 id="kafka-集群选择合适的Topic-partions-数量"><a href="#kafka-集群选择合适的Topic-partions-数量" class="headerlink" title="kafka 集群选择合适的Topic/partions 数量"></a>kafka 集群选择合适的Topic/partions 数量</h4><ul>
<li>单个Partion的吞吐量通常是在10MB/s</li>
<li>越多的分区需要打开更多的文件句柄，生产集群中，每个broker打开的文件句柄数量超过30，000</li>
<li>越多的分区可以提供更高的吞吐量，更多的分区会导致更高的不可用性</li>
<li>通常情况下，当一个Broker有计划地停止服务时，那么controller会在服务停止之前，将该broker上的所有leader一个一个秦阿姨走。单个leader的移动时间只需要几毫秒；当broker非计划地宕机，所有的partion同时变得不可用，若有1000个partion，则恢复时间将花费5秒（灭个partion5 ms）;若宕机的broker恰好是controller节点时，新的leader节点选举过程同样需要花费时间，从zookeeper中恢复元数据时每个partion大约花费2ms，则controller恢复将会增加20秒不可用窗口</li>
<li>通常情况下，将每个broker的partion 数量限制在2000～4000，kafka集群中partion数量限制在10，000</li>
<li>越多的分区可能增加端到端的延迟：in-sync副本复制所花费时间是kafka端到端延迟的主要部分，端到端的延迟大概是20ms（1000 partion）;对于b个broker节点和复制因子为r的kafka 集群，整个kafka集群的partion数量最好不超过100<em>b</em>r个，即单个partion的leader数量不要超过100</li>
</ul>
<h4 id="Kafka如何实现高吞吐率"><a href="#Kafka如何实现高吞吐率" class="headerlink" title="Kafka如何实现高吞吐率"></a>Kafka如何实现高吞吐率</h4><ul>
<li>顺序读写：kafka的消息是不断追加到文件中的，可以充分利用磁盘的顺序读写性能</li>
<li>零拷贝：linux kernel “zero-copy”系统调用机制，跳过“用户缓冲”的拷贝，建议一个磁盘和内存的直接映射，数据不再复制到“用户态缓冲区”</li>
<li>文件分段：kafka的队列被分为多个分区partion，每个partion又分为多个段segment，一个队列中的消息实际上是保存在N多个片段文件中</li>
<li>批量发送：Kafka允许进行批量发送消息，先将消息缓存在内存中，然后一次请求批量发送出去</li>
<li>数据压缩：Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/09/24/RabbitMQ/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/24/RabbitMQ/" itemprop="url">RabbitMQ</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-24T18:50:49+08:00">
                2019-09-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/消息队列/" itemprop="url" rel="index">
                    <span itemprop="name">消息队列</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="消息中间件功能"><a href="#消息中间件功能" class="headerlink" title="消息中间件功能"></a>消息中间件功能</h2><ul>
<li><strong>解耦</strong>:消息中间件在处理过程中间插入了一个隐含的、基于数据的接口层， 两边的处理过程都要实现这一接口，这允许你独立地扩展或修改两边的处理过程， 只要确保它们遵守同样的接口约束即可</li>
<li><strong>异步</strong>：消息中间件提供了异步处理机制， 允许应用把一些消息放入消息中间件中， 但并不立即处理它， 在之后需要的时候再慢慢处理。</li>
<li><strong>削峰</strong>：使用消息中间件能够使关键组件支撑突发访问压力， 不会因为突发的超负荷请求而完全崩溃<br><img src="https://i.loli.net/2019/09/23/lU6HvuaJkRpNxnW.png" alt="Snipaste_2019-09-23_15-11-53.png"></li>
</ul>
<h3 id="RabbitMQ服务端口"><a href="#RabbitMQ服务端口" class="headerlink" title="RabbitMQ服务端口"></a>RabbitMQ服务端口</h3><blockquote>
<p>RabbitMQ 是一个实现AMQP协议的消息中间件服务，采用Erlang语言进行编写。</p>
<ul>
<li>4369：epmd,负责维护RabbitMQ集群内的节点连接</li>
<li>5672：client端通信端口</li>
<li>15672：RabbitMQmanagement web ui 管理口</li>
<li>25672： RabbitMQ集群内节点通信端口</li>
</ul>
</blockquote>
<h3 id="RabbitMQ基本操作"><a href="#RabbitMQ基本操作" class="headerlink" title="RabbitMQ基本操作"></a>RabbitMQ基本操作</h3><ol>
<li>创建Queue</li>
<li>创建exchange</li>
<li>创建binding</li>
<li>发送msg</li>
<li>接收msg</li>
</ol>
<p><img src="https://i.loli.net/2019/09/23/AJNarVCmTRXhWdP.png" alt="Snipaste_2019-09-23_15-15-55.png"></p>
<h3 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h3><ul>
<li>Exchange： 消息交换机，它指定消息按什么规则，路由到那个队列<ul>
<li>Direct：Bingding key和Routing key必须完全一致，不支持通配符</li>
<li>Topic：同Direct类型，但支持通配符。</li>
<li>Fanout：忽略binding key和routing key，消息会被传送到所有绑定的队列上</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2019/09/23/a4iC5t1eWPOInlT.png" alt="Snipaste_2019-09-23_15-18-30.png"></p>
<ul>
<li>Queue：消息队列载体，每个消息都会被投入到一个或多个队列</li>
<li>Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来</li>
<li>Routing key：路由关键字，exchange根据这个关键字进行消息投递</li>
</ul>
<h4 id="Exchange-Delclare参数"><a href="#Exchange-Delclare参数" class="headerlink" title="Exchange Delclare参数"></a>Exchange Delclare参数</h4><hr>
<p><code>def exchange_declare(self, exchange, type, passive=False, durable=False,
auto_delete=True, nowait=False, arguments=None,
argsig=&#39;BssbbbbbF&#39;)</code></p>
<hr>
<ul>
<li>exchange: 交换器的名称。</li>
<li>type: 交换器的类型，常见的如fanout, direct 和topic</li>
<li>passive: passive设置为true用于检测相应的交换器是否存在。 如果存在则正常返回；否则RabbitMQ抛出异常:404 (not found)。</li>
<li>durable: 设置是否持久化。 durable设置为true 表示持久化。</li>
<li>auto_delete: 设置是否自动删除。 auto_delete 设置为true 则表示自动删除。 自动删除的前提是至少有一个队列或<br>者交换器与这个交换器绑定， 之后所有与这个交换器绑定的队列或者交换器都与此解绑。</li>
<li>nowait: 声明Exchange时，不需要RabbitMQ返回任何信息。在声明完一个交换器之后(实际服务器还并未完成交<br>换器的创建) ， 那么此时客户端紧接着使用这个交换器，必然会发生异常。</li>
<li>argument: 其他一些结构化参数，比如alternate-exchange</li>
</ul>
<h4 id="Queue-Declare参数"><a href="#Queue-Declare参数" class="headerlink" title="Queue Declare参数"></a>Queue Declare参数</h4><hr>
<p><code>def queue_declare(self, queue=&#39;&#39;, passive=False, durable=False,
exclusive=False, auto_delete=True, nowait=False,
arguments=None, argsig=&#39;BsbbbbbF&#39;)</code></p>
<hr>
<ul>
<li>queue: 队列的名称。</li>
<li>passive:同exchange_declare的passive参数含义。</li>
<li>durable: 设置是否持久化。 durable设置为true 表示持久化。</li>
<li>exclusive:设置是否排他。为true 则设置队列为排他的。如果一个队列被声明为排他队列，该队列仅对首次声<br>明它的连接可见，并在连接断开时自动删除。</li>
<li>auto_delete: 设置是否自动删除。为true则设置队列为自动删除。自动删除的前提是:至少有一个消费者连接到<br>这个队列，之后所有与这个队列连接的消费者都断开时，才会自动删除。</li>
<li>nowait: 同exchange_declare的nowait参数含义。</li>
<li>argument: 设置队列的其他一些参数，如x-message-ttl, x-expires, x-dead-letter-exchange, x-dead-letterrouting-key, x-max-priority 等。</li>
</ul>
<h4 id="Bing-参数"><a href="#Bing-参数" class="headerlink" title="Bing 参数"></a>Bing 参数</h4><hr>
<p><code>def queue_bind(self, queue, exchange=&#39;&#39;, routing_key=&#39;&#39;,
nowait=False, arguments=None, argsig=&#39;BsssbF&#39;)</code></p>
<hr>
<ul>
<li>queue: 队列名称。</li>
<li>exchange: 交换器名称。</li>
<li>routing_key: 用来绑定队列和交换器的路由键</li>
</ul>
<hr>
<p><code>def exchange_bind(self, destination, source=&#39;&#39;, routing_key=&#39;&#39;,
nowait=False, arguments=None, argsig=&#39;BsssbF&#39;)</code></p>
<hr>
<ul>
<li>destination: 目的交换器名称。</li>
<li>source: 源交换器名称。</li>
<li>routing_key: 用来绑定源交换器和目的交换器的路由键</li>
</ul>
<h3 id="消息可靠传输"><a href="#消息可靠传输" class="headerlink" title="消息可靠传输"></a>消息可靠传输</h3><ul>
<li><p>生产者确认</p>
<ul>
<li>通过事务机制实现</li>
<li>通过发送方确认机制实现</li>
</ul>
</li>
<li><p>生产者保证——保证消息从Producer传输到Rabbit Broker</p>
<ul>
<li>Mandatory参数</li>
<li>Alternate Exchange（备份交换器）</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2019/09/23/GiHuMJOfmkUev1z.png" alt="Snipaste_2019-09-23_17-29-14.png"></p>
<ul>
<li>设置mandatory参数，在生成者业务侧需增加监听回调函数，增加了生成者的复杂度。如果不想消息丢失，可以使用Alternate Exchange。这样可以将未被路由的消息存储在RabbitMQ中，再在需要的时候去处理这些消息。</li>
<li>Alternate Exchange和mandatory参数同时使用，那么mandatory参数无效。</li>
</ul>
<p><img src="https://i.loli.net/2019/09/23/BgWoebCmMHvYV7U.png" alt="Snipaste_2019-09-23_17-26-57.png"></p>
<p>事务机制和publisher confirm机制确保的是消息能够正确的发送至RabbitMQ的Exchange，如果Exchange没有匹配的Queue，那么消息也会丢失。所以发送方需要配合mandatory参数或者Alternate Exchange一起使用来提高消息传输的可靠性</p>
<ul>
<li><p>Broker保证——保证消息在RabbitMQ Broker不丢失</p>
<ul>
<li>Exchange持久化——声明交换器时将durable参数设置为true</li>
<li>Queue持久化——声明队列将durable参数设置为true</li>
<li>消息持久化——将消息的投递模式（delivery_mode）设置为2来实现消息的持久化<blockquote>
<p>单单只设置队列持久化，重启之后消息会丢失;单单只设置消息的持久化，重启之后队列消失，继而消息也丢失。<br>单单设置消息持久化而不设置队列的持久化显得毫无意义。<br>虽然RabbitMQ的entities持久化可以保证消息的可靠性，但是会影响RabbitMQ的吞吐量。因此在选择是否要将<br>消息持久化时，需要在可靠性和吞吐量之间做一个权衡</p>
</blockquote>
</li>
</ul>
</li>
<li><p>消费者保证——保证消息从RabbitMQ传输到Consumer</p>
<ul>
<li>消费者确认——消费者在订阅队列时，设置no_ack参数<br>——————————<br><code>def basic_consume(self, queue=&#39;&#39;, consumer_tag=&#39;&#39;, no_local=False,no_ack=False, exclusive=False,nowait=False,callback=None, arguments=None, on_cancel=None,argsig=&#39;BssbbbbF&#39;)</code><br>———————————</li>
</ul>
</li>
<li><p>当no_ack为false时， RabbitMQ会等待消费者显式的回复确认信号后才从内存(或者磁盘)中移去消息。</p>
</li>
<li><p>当no_ack为true时， RabbitMQ 会自动把发送出去的消息置为确认，然后从内存(或者磁盘)中删除，而不管消<br>费者是否真正地消费到了这些消息。</p>
</li>
<li><p>采用消息确认机制后，只要设置no_ack参数为false，消费者就有足够的时间处理消息(任务) ，不用担心处理<br>消息过程中消费者进程挂掉后消息丢失的问题， 因为RabbitMQ 会一直等待持有消息直到消费者显式调用<br>Basic.Ack 命令为止。即调用如下函数:<br>————————————<br><code>def basic_ack(self, delivery_tag, multiple=False, argsig=&#39;Lb&#39;)</code><br>——————————</p>
</li>
</ul>
<h2 id="RabbitMQ-传输机制和幂等性"><a href="#RabbitMQ-传输机制和幂等性" class="headerlink" title="RabbitMQ 传输机制和幂等性"></a>RabbitMQ 传输机制和幂等性</h2><h3 id="消息的传输机制"><a href="#消息的传输机制" class="headerlink" title="消息的传输机制"></a>消息的传输机制</h3><ul>
<li>At most once:最多一次。消息可能会丢失，但绝对不会重传</li>
<li>At least once：最少一次。消息绝并不会丢失，但可能重传</li>
<li>Exactly once:恰好一次。每条消息只被传输一次并且只传输一次</li>
<li>RabbitMQ支持其中的“最多一次”和“最少一次”</li>
</ul>
<h3 id="消息的幂等性"><a href="#消息的幂等性" class="headerlink" title="消息的幂等性"></a>消息的幂等性</h3><ul>
<li>用户对同一操作发起的一个或多次请求的结果都是一样的</li>
<li>RabbitMQ并不能保证消息的幂等性。需要业务方通过解决消息的重复问题来保证幂等性操作</li>
</ul>
<h2 id="RabbitMQ过期时间（TTL）"><a href="#RabbitMQ过期时间（TTL）" class="headerlink" title="RabbitMQ过期时间（TTL）"></a>RabbitMQ过期时间（TTL）</h2><h3 id="设置消息的TTL"><a href="#设置消息的TTL" class="headerlink" title="设置消息的TTL"></a>设置消息的TTL</h3><ul>
<li>通过队列属性设置，队列中所有消息都有相同的过期时间。 (x-message-ttl)</li>
<li>对消息本身进行单独设置，每条消息的TTL 可以不同。 (expiration)</li>
<li>如果两种方法一起使用，则消息的TTL 以两者之间较小的那个数值为准</li>
</ul>
<h3 id="设置队列的TTL（x-peries）"><a href="#设置队列的TTL（x-peries）" class="headerlink" title="设置队列的TTL（x-peries）"></a>设置队列的TTL（x-peries）</h3><ul>
<li>队列的TTL表示队列被自动删除前处于未使用状态的时间</li>
</ul>
<h2 id="RabbitMQ-消息顺序性"><a href="#RabbitMQ-消息顺序性" class="headerlink" title="RabbitMQ 消息顺序性"></a>RabbitMQ 消息顺序性</h2><ul>
<li>消息的顺序性是指消费者消费到的消息和发送者发布的消息的顺序是一致的。举个例子，不考虑消息重复的<br>情况，如果生产者发布的消息分别为msgl、 msg2 、 msg3 ，那么消费者必然也是按照msgl 、 msg2 、msg3 的顺序进行消费的</li>
<li>RabbitMQ并不能保证消息的顺序性，除非只有一个生产者和一个消息者的情况</li>
<li>如果要保证消息的顺序性， 需要<strong>业务方</strong>使用RabbitMQ 之后做进一步的处理，比如在消息体内添加全局有序<br>标识(类似SequenceID) 来实现</li>
</ul>
<h3 id="RabbitMQ-消息分发"><a href="#RabbitMQ-消息分发" class="headerlink" title="RabbitMQ 消息分发"></a>RabbitMQ 消息分发</h3><ul>
<li>Round-Robin分发（默认消息分发方式）</li>
<li>Fair分发（调用channel.basic_qos函数进行设置）</li>
</ul>
<h2 id="RabbitMQ使用实例"><a href="#RabbitMQ使用实例" class="headerlink" title="RabbitMQ使用实例"></a>RabbitMQ使用实例</h2><h3 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a>延迟队列</h3><p><img src="https://i.loli.net/2019/09/24/T5dc3xC1qXbaZ2n.png" alt="Snipaste_2019-09-24_09-15-15.png"></p>
<ul>
<li>RabbitMQ的延迟队列/重试队列可以采用设置消息的TTL+DLX(Dead-Letter-Exchange)来实现。</li>
<li>当消息在一个队列中变成死信后， 它能被重新被发送到另一个交换器中， 这个交换器就是DLX，绑定DLX的<br>队列就称之为死信队列</li>
</ul>
<h3 id="重试队列"><a href="#重试队列" class="headerlink" title="重试队列"></a>重试队列</h3><p><img src="https://i.loli.net/2019/09/24/KtZJI3bVgrvLYPm.png" alt="Snipaste_2019-09-24_09-18-26.png"></p>
<h3 id="优先级队列"><a href="#优先级队列" class="headerlink" title="优先级队列"></a>优先级队列</h3><p><img src="https://i.loli.net/2019/09/24/lPjVXzr2OmxRUyY.png" alt="Snipaste_2019-09-24_09-19-09.png"></p>
<ul>
<li>上面的代码中设置队列的优先级为10。消息的优先级默认最低为0，最高为队列设置的最大优先级。对于超过优先级队列指定的最大优先级的消息，优先级以最大优先级对待。</li>
<li>这个也是有前提的: 如果在消费者的消费速度大于生产者的速度且Broker 中没有消息堆积的情况下， 对发送的消息设置优先级也就没有什么实际意义。因为生产者刚发送完一条消息就被消费者消费了，那么就相当于Broker 中至多只有一条消息，对于单条消息来说优先级是没有什么意义的。</li>
</ul>
<h3 id="ROC实现"><a href="#ROC实现" class="headerlink" title="ROC实现"></a>ROC实现</h3><p><img src="https://i.loli.net/2019/09/24/EUHP4eGlQpTjzYi.png" alt="Snipaste_2019-09-24_09-21-00.png"></p>
<h2 id="RabbitMQ集群"><a href="#RabbitMQ集群" class="headerlink" title="RabbitMQ集群"></a>RabbitMQ集群</h2><ul>
<li>RabbitMQ集群节点没有leader和follower之分， 所有节点是平等的。</li>
<li>RabbitMQ集群的queue有master和slave之分(这是采用Mirror queue的场景。 如果没有配置Mirror queue，则queue所处的节点也可称为该queue的master节点)。</li>
<li>RabbitMQ集群正常情况下， 客户端能够连接到集群中的任何节点对queue做操作，所有的操作会被RabbitMQ route到queue的master节点。</li>
<li>如果关闭了集群中的所有节点， 则需要确保在启动的时候最后关闭的那个节点是第一个启动的。 如果第一个启动的不是最后关闭的节点， 那么这个节点会等待最后关闭的节点启动</li>
<li>如果RabbitMQ集群节点没有采用Mirror queue，则某个节点宕机，则该节点上非持久化的消息将丢失。</li>
<li>采用Mirror queue设置RabbitMQ集群后， 到达queue的master节点的消息会被分发到queue的每个slave节点，防止消息丢失，保证RabbitMQ的高可用。</li>
<li>若queue的master节点宕机， “资历最老” 的queue的slave节点将被提升为新的master节点</li>
</ul>
<h3 id="消息队列对比"><a href="#消息队列对比" class="headerlink" title="消息队列对比"></a>消息队列对比</h3><table>
<thead>
<tr>
<th align="center">****</th>
<th align="center"><strong>RabbitMQ</strong></th>
<th align="center"><strong>Kafka</strong></th>
<th align="center"><strong>RocketMQ</strong></th>
<th align="center"><strong>Pulsar</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">成熟度</td>
<td align="center">成熟</td>
<td align="center">成熟</td>
<td align="center">比较成熟</td>
<td align="center">/</td>
</tr>
<tr>
<td align="center">所属社区/公司</td>
<td align="center">Mozilla Public License</td>
<td align="center">Apache</td>
<td align="center">Ali</td>
<td align="center">Apache</td>
</tr>
<tr>
<td align="center">活跃度</td>
<td align="center">高</td>
<td align="center">高</td>
<td align="center">中</td>
<td align="center">/</td>
</tr>
<tr>
<td align="center">开发语言</td>
<td align="center">Erlang</td>
<td align="center">Scala&amp;Java</td>
<td align="center">Java</td>
<td align="center">Java</td>
</tr>
<tr>
<td align="center">客户端支持语言</td>
<td align="center">Java/python/go/C/C++/Erl ang等，几乎支持所有常用语言</td>
<td align="center">Java/python/go/C/ C++等</td>
<td align="center"></td>
<td align="center">ava/python/go/C/ C++/websocket</td>
</tr>
<tr>
<td align="center">数据可靠性</td>
<td align="center">可以保证数据不丢失，有slave做备份</td>
<td align="center">数据可靠，并且有 replica机制，有容错容 灾能力</td>
<td align="center">支持异步实时刷盘，同 步刷盘，同步复制，异 步复制。</td>
<td align="center">实时刷盘，按用户配置， quorum-vote的方式并 发写入多个存储节点</td>
</tr>
<tr>
<td align="center">单机吞吐量</td>
<td align="center">万级</td>
<td align="center">十万级</td>
<td align="center">十万级</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">消息延迟</td>
<td align="center">微秒级</td>
<td align="center">微秒级</td>
<td align="center">微秒级，比kafka快</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">HA</td>
<td align="center">Master/Slave模式， master 提供服务， Slave作备份</td>
<td align="center">支持replica机制， leader宕掉后，基于 zookeeper在备份节点中 重新选举新的leader</td>
<td align="center">多Master模式 多Master多Slave模 式—异步复制 多Master多Slave模 式—同步双写</td>
<td align="center">服务/存储分层架构，服 务层无状态。 无Master/Slave，服务 层broker宕机， topic的 owner会被自动转到其 他alive的broker。 存储层节点宕机，服务 层和client不受影响</td>
</tr>
<tr>
<td align="center">模式</td>
<td align="center">发布/订阅</td>
<td align="center">发布/订阅</td>
<td align="center">发布/订阅</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">消息持久性</td>
<td align="center">内存/硬盘</td>
<td align="center">硬盘</td>
<td align="center">硬盘</td>
<td align="center">硬盘</td>
</tr>
<tr>
<td align="center">消息推拉模式</td>
<td align="center">多协议，Pull/Push均支持</td>
<td align="center">Pull</td>
<td align="center">多协议，Pull/Push均支持</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">是否有序</td>
<td align="center">若想有序，只能使用一个client</td>
<td align="center">多client保证有序</td>
<td align="center">有序</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">消息批量操作</td>
<td align="center">不支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
</tr>
<tr>
<td align="center">顺序投递</td>
<td align="center">不支持</td>
<td align="center">不支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
</tr>
<tr>
<td align="center">事务</td>
<td align="center">不支持</td>
<td align="center">不支持</td>
<td align="center">支持</td>
<td align="center">不支持</td>
</tr>
<tr>
<td align="center">集群</td>
<td align="center">支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
</tr>
<tr>
<td align="center">负载均衡</td>
<td align="center">支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/09/19/实践操作札记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/19/实践操作札记/" itemprop="url">实践操作札记</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-19T19:01:47+08:00">
                2019-09-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>更新ing</p>
</blockquote>
<h2 id="Route-53"><a href="#Route-53" class="headerlink" title="Route 53"></a>Route 53</h2><h3 id="路由策略"><a href="#路由策略" class="headerlink" title="路由策略"></a>路由策略</h3><ol>
<li>简单路由策略–对于域执行功能给定功能的单一资源(例如为 example.com 网站提供内容的 Web 服务器)，可以使用该策略</li>
<li>故障转移路由策略– 如果想要配置主动-被动故障转移，则可以使用该策略</li>
<li>地理位置路由策略—如果想要根据用户的位置来路由流量，则可以使用该策略</li>
<li>地理位置林进度路由策略–用于更具资源的位置来路由通信，以及（可选）将流量从一个位置中的资源转移到另一个位置中的资源</li>
<li>延迟路由策略–如果资源位于多个AWS区域，并且想要将流量路由到提供给哦你最佳延迟的区域，则可以使用该策略</li>
<li>多值应答路由策略–想要让Route 53用随机选择的正常记录（最多八条）响应DNS查询，则可是用该策略</li>
<li>甲醛路由策略—用于按照指定的比例将流量路由到多个资源</li>
</ol>
<h3 id="记录集"><a href="#记录集" class="headerlink" title="记录集"></a>记录集</h3><ul>
<li>一个Record只能有一个alias target</li>
<li>加权路由：加权路由允许将多个资源关联至单个域名 (example.com) 或子域名 (acme.example.com)，并选择向每个资源路由多少流量。这可用于多种用途，例如负载均衡、测试软件新版本等。要配置加权路由，可以创建与每个资源同名、同类型的记录，然后根据要发送到每个资源的流量的规模为每条记录分配相对权重。Amazon Route 53 将根据分配给记录的权重 (占该组中所有记录总权重的比例) 向资源发送流量</li>
</ul>
<h3 id="R53运行状态检查类型"><a href="#R53运行状态检查类型" class="headerlink" title="R53运行状态检查类型"></a>R53运行状态检查类型</h3><ol>
<li>监控指端节点的运行状况检查：可以配置运行状况检查来监控通过 IP 地址或域名指定的终端节点。Route 53 按照指定的固定间隔，通过 Internet 向您的应用程序、服务器或其他资源自动提交请求，以验证其是否可到达、是否可用及功能是否正常。也可以通过配置运行状况检查来发出与用户发出的请求类似的请求，如从特定 URL 请求网页</li>
<li>监控其他运行状况检查的运行状况检查：可以创建运行状况检查，以监控 Route 53 是将其他运行状况检查视为运行状况良好还是不佳。在下面的情况下，这种运行状况检查可能很有用：您有多个执行相同功能的资源 (如多台 Web 服务器)，主要关注的是运行状况良好的资源数是否达到最少数目。您可以为每个资源创建运行状况检查，而不为这些运行状况检查配置通知。然后，可以创建一个运行状况检查，来监控其他运行状况检查的状态，并且仅在可用的 Web 资源数低于指定阈值时通知</li>
<li>监控CloudWatch报警的运行状况检查：可以创建用于监控 CloudWatch 指标状态的 CloudWatch 警报，这些指标包括 Amazon DynamoDB 数据库的受限读取事件数或被认为运行状况良好的 Elastic Load Balancing 主机数。在创建警报后，可以创建运行状况检查，使其监控与 CloudWatch 针对警报监控的数据流相同的数据流。为了提高复原能力和可用性，Route 53 不等待 CloudWatch 警报进入 ALARM 状态。运行状况检查的状态会根据数据流以及 CloudWatch 警报中的条件从运行状况良好更改为运行状况不佳</li>
</ol>
<h2 id="AutoScaling"><a href="#AutoScaling" class="headerlink" title="AutoScaling"></a>AutoScaling</h2><ul>
<li>启动配置创建后不可修改，只能创建新的启动配置与最新的映像关联，然后再修改 Auto Scaling Group 与新创建的启动配置关联。替换掉的启动配置不好管理。</li>
<li>启动模板的优势在于有版本的概念。可以在上一版的基础上，替换最新制作的映像生成启动模板的新版本。不需要再更新 Auto Scaling Group 的相关属性。通过版本这个概念也可以很好的管理历史的映像。</li>
</ul>
<h2 id="Cloudfront"><a href="#Cloudfront" class="headerlink" title="Cloudfront"></a>Cloudfront</h2><ul>
<li>当使用 https 协议访问网站时，CNAME 跳转会有 SSL 证书的问题</li>
<li>创建 CloudFront Distribution 时一定要添加 Alternate Domain Names (CNAMEs)，否则 CloudFront 会报错<ul>
<li>因为 CloudFront 服务的边缘站点使用的是一个资源共享的模式，所以在默认的情况下 Distribution 本身并没有独立的专属 IP 地址，而是共享同一群IP地址，因此需要通过 Host 标头去匹配请求和 Distribution 之间的关联</li>
</ul>
</li>
</ul>
<h2 id="CloudWatch"><a href="#CloudWatch" class="headerlink" title="CloudWatch"></a>CloudWatch</h2><ul>
<li>CloudWatch base：5分钟传输一次指标，不需要付费，这个是开通的默认选项</li>
<li>Cloudwatch detailed：1分钟传输一次指标，需要支付额外的费用</li>
</ul>
<h2 id="EC2"><a href="#EC2" class="headerlink" title="EC2"></a>EC2</h2><ul>
<li>EC2访问公网需要有公共IP或者EIP，同时需要IGW网关，并attach到实例所在的VPC，创建一个路由表 0.0.0.0/0 指向IGW，最后就是检查acl和安全组是否开放了相关端口允许流量出入</li>
<li>不建议创建IAM user或者IAM group 通过用户的授信信息保存到应用中调用资源。</li>
<li>建议通过为EC2创建 IAM role，将应用部署到EC2上，来获取访问AWS其他服务资源的权限。将角色的授信策略绑定到角色上。</li>
</ul>
<h2 id="S3"><a href="#S3" class="headerlink" title="S3"></a>S3</h2><ul>
<li>read after write for new object是提供了一致性的存储；</li>
<li>只有改变了现有的对象，才有可能导致最终一致性的问题发生；</li>
<li>S3的跨region复制必须启动versioning</li>
</ul>
<h2 id="VPC"><a href="#VPC" class="headerlink" title="VPC"></a>VPC</h2><ul>
<li>Nat gateway 不能直接与vpc endpoints、vpn connections、AWS Direct Connect或者vpc peering connection进行流量互通，如果你的实例在private subnet中需要通过vpc endpoint、vpn、AWS Direct Connect连接，可以直接用private subnet的路由表直接路由到这设备上；</li>
<li>不能直接从NAT gateway上通过VPC PEER/VPN/DC进行路由。NAT GATEWAY不能被这些连接的另一端直接使用</li>
<li>Custom VPC不支持DNS HOSTNAME ENABLE,当你在这个VPC创建一个EC2的时候不会带private DNS name。你需要修改VPC的属性，设置dns hostname被设置为enable。</li>
<li>DNS resolution是一个解决DNS HOSTNAME在AWS内部生效的能力，是通过AWS的DNS server。感觉有点类似我们管理host表；</li>
<li>自动赋予public IP这个事情如果是在public subnet中可以在操作的时候设定。如果是在private subnet中创建EC2，默认是disabled的</li>
</ul>
<h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><ul>
<li>流量控制：如果web server与db instance在一个VPC中，设置流量访问控制建议直接使用SecurityGroup；</li>
<li>NACL的使用场景：主要用于你想拒绝一个指定的IP访问或者一个CIDR 块的访问的时候</li>
<li>简单来说，只是流量控制，使用SecurityGroup，如果有拒绝某些IP和CIDR的场景，就配合上NACL来控制流量</li>
</ul>
<h2 id="容灾"><a href="#容灾" class="headerlink" title="容灾"></a>容灾</h2><ul>
<li>Multi-AZ deployments解决的是高可用问题；</li>
<li>跨region复制才是解决容灾问题；</li>
<li>RDS采用了不同的技术来支持高可用的failover机制<ul>
<li>采用AWS failover 技术的有：oracle、Postgre、mysql、mariadb</li>
<li>sqlserver使用的是mirroring技术</li>
<li>Aurora使用的是集群下的数据库复制技术</li>
</ul>
</li>
</ul>
<h2 id="elasticache"><a href="#elasticache" class="headerlink" title="elasticache"></a>elasticache</h2><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><ul>
<li>描述：缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</li>
<li>解决方案方案：<ol>
<li>接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截；</li>
<li>从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击</li>
</ol>
</li>
</ul>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><ul>
<li>描述：缓存击穿是指缓存中没有但数据库中有的数据（一般是指缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力</li>
<li>解决方案<ol>
<li>设置热点数据永远不过期</li>
<li>家户斥锁</li>
</ol>
</li>
</ul>
<h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><ul>
<li>描述:缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是,缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库</li>
<li>解决方案：<ol>
<li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li>
<li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。</li>
<li>设置热点数据永远不过期</li>
</ol>
</li>
</ul>
<h3 id="双写一致性"><a href="#双写一致性" class="headerlink" title="双写一致性"></a>双写一致性</h3><ul>
<li><p>先更新数据库，再更新缓存</p>
</li>
<li><p>先删除缓存，在更新数据库</p>
</li>
<li><p><strong>先更新数据库，在删除缓存</strong></p>
</li>
<li><p>使用分布式锁：缓存失效后，加锁查询、更新缓存，更新数据库时加锁删除缓存</p>
<h2 id="ELB-访问日志中捕获客户端-IP-地址"><a href="#ELB-访问日志中捕获客户端-IP-地址" class="headerlink" title="ELB 访问日志中捕获客户端 IP 地址"></a>ELB 访问日志中捕获客户端 IP 地址</h2></li>
<li><p>对于具有 HTTP/HTTPS 侦听器的 Application Load Balancers 和 Classic Load Balancer ，必须使用 X-Forwarded-For 标头来捕获客户端 IP 地址。然后&gt;，必须输出访问日志中的这些客户端 IP 地址。</p>
<ul>
<li>对于具有 TCP/SSL 侦听器的 Classic Load Balancer，必须在 Classic Load Balancer 和目标应用程序上启用代理协议支持。确保两端都配置代理协议支&gt;持，否则应用程序可能会遇到问题。还可以使用 AWS CLI 启用代理协议支持。</li>
<li>对于网络负载均衡器，您可以按实例 ID 注册目标，以捕获客户端 IP 地址，而无需额外的 Web 服务器配置。</li>
</ul>
</li>
</ul>
<h2 id="通过“三段封装”来规划应用结构"><a href="#通过“三段封装”来规划应用结构" class="headerlink" title="通过“三段封装”来规划应用结构"></a>通过“三段封装”来规划应用结构</h2><h3 id="第一段：基础设施封装"><a href="#第一段：基础设施封装" class="headerlink" title="第一段：基础设施封装"></a>第一段：基础设施封装</h3><p> 通过基础设施即代码技术构建出一个应用程序的平台，这个平台可以做到隔离应用且对开发者透明。例如：Kubernetes 或者 AWS CloudFormation。前者可以为开发者提供一个简单的应用部署平台，并很好的支持了很多高可用的特性。后者可以用来配置包括网络在内的所有 AWS 资源。<br> 这里需要注意的是要根据基础设施的变更频率对基础设施实施分层管理，将经常变动的部分独立成一个风险最小的变更单元，避免和其它部分相互影响。</p>
<h3 id="第二段：应用封装"><a href="#第二段：应用封装" class="headerlink" title="第二段：应用封装"></a>第二段：应用封装</h3><p>通过构建持续交付流水线构建出应用镜像或者虚拟机镜像，要做到快速复制以实现水平扩展。例如 Docker 镜像或者用 Packer 构建出 AMI。<br>这里需要注意的是构建镜像的时候一定要考虑无状态特性，每个镜像被创建后所展现出来的最终效果和操作都是幂等的。</p>
<h3 id="第三段：数据封装"><a href="#第三段：数据封装" class="headerlink" title="第三段：数据封装"></a>第三段：数据封装</h3><p>通过数据全量+增量的备份把数据库或者文件存储在更稳妥的地方，并修改访问方式。例如：采用 S3 或者 RDS 来存储。<br>这里需要注意的是如果你没有用 RDS 等高可靠的数据存储服务，就要要定时对数据进行备份恢复测试，避免需要恢复数据的时候备份不起作用。备份策略可以按照全量 + 增量的方式进行，具体的方式可以参考不同数据库的方案。</p>
<p>+————————-VPC————————–+<br>  |                                                      |<br>+—-+ap-southeast-1a+—-+      +—-+ap-southeast-1b+—-+<br>| |                       |      |                       | |<br>| | +—————–+   |      |   +—————–+ | |<br>| | | Public Subnet A |   |      |   | Public Subnet B | | |<br>| | +—————–+   |      |   +—————–+ | |<br>| |                       |      |                       | |<br>| |                       |      |                       | |<br>| | +—————–+   |      |   +—————–+ | |<br>| | | Nat Subnet A    |   |      |   | Nat Subnet B    | | |<br>| | +—————–+   |      |   +—————–+ | |<br>| |                       |      |                       | |<br>| |                       |      |                       | |<br>| | +—————–+   |      |   +—————–+ | |<br>| | | Private Subnet A|   |      |   | Private Subnet B| | |<br>| | +—————–+   |      |   +—————–+ | |<br>| |                       |      |                       | |<br>+————————-+      +————————-+<br>  |                                                      |<br>  +——————————————————+</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/09/08/AWS-IAM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/08/AWS-IAM/" itemprop="url">AWS IAM</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-08T15:42:35+08:00">
                2019-09-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS/" itemprop="url" rel="index">
                    <span itemprop="name">AWS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="IAM-Overview"><a href="#IAM-Overview" class="headerlink" title="IAM Overview"></a>IAM Overview</h2><ul>
<li>AWS Identity and Access Management (IAM) 够安全地管理对 AWS 服务和资源的访问</li>
<li>IAM用于控制<ul>
<li><strong>Identity</strong> - 谁可以使用AWS资源（身份验证）</li>
<li><strong>Access</strong> - 他们可以使用哪些资源以及以何种方式（授权）</li>
</ul>
</li>
<li>IAM还可以将帐户凭据保密</li>
<li>使用IAM，可以在AWS账户的保护下创建多个IAM用户，也可以通过与AD身份联合来启用临时访问。或者第三方提供商<br>IAM</li>
<li>也允许跨AWS账户访问资源（中国区特殊）</li>
</ul>
<h2 id="IAM-功能"><a href="#IAM-功能" class="headerlink" title="IAM 功能"></a>IAM 功能</h2><ul>
<li>对AWS账户的共享访问权限<ul>
<li>可以向其他人员授予管理和使用AWS 账户中的资源的权限，而不必共享您的密码或访问密钥</li>
</ul>
</li>
<li>精细权限<ul>
<li>可以针对不同资源向不同人员授予不同权限</li>
<li>在 Amazon EC2 上运行的应用程序针对 AWS 资源的安全访问权限</li>
</ul>
</li>
<li>联合身份<ul>
<li>允许已在其他位置（例如，在企业网络中或通过 Internet 身份提供商）获得密码的用户获取对AWS 账户的临时访问权限</li>
<li>CloudTrail可用于接收日志记录，其中包含有关在帐户中提出资源请求的人员的信息</li>
</ul>
</li>
<li>PCI DSS合规性<ul>
<li>IAM 支持由商家或服务提供商处理、存储和传输信用卡数据，而且已经验证符合支付卡行业 (PCI) 数据安全标准 (DSS)</li>
</ul>
</li>
<li>已与很多 AWS 服务集成</li>
<li>最终一致性<ul>
<li>与许多其他 AWS 服务一样，IAM 具有最终一致性。IAM 通过在 Amazon 的全球数据中心中的多个服务器之间复制数据来实现高可用性。如果成功请求更改某些数据，则更改会提交并安全存储。不过，更改必须跨 IAM 复制，这需要时间。</li>
</ul>
</li>
<li>多重验证（MFA）</li>
<li>免费试用<ul>
<li>IAM 和STS 是为 AWS 账户提供的功能，不另行收费；当使用 IAM 用户或 AWS STS 临时安全凭证访问其他 AWS 服务时，才会向收取费用</li>
</ul>
</li>
</ul>
<h2 id="Identities"><a href="#Identities" class="headerlink" title="Identities"></a>Identities</h2><blockquote>
<p>IAM身份确定谁可以访问并帮助为AWS账户中的人员和流程提供身份验证<br><img src="https://i.loli.net/2019/09/09/6UqQ1OV9SmGeIAi.png" alt="IAM-Identities.png"></p>
</blockquote>
<h3 id="账户root用户"><a href="#账户root用户" class="headerlink" title="账户root用户"></a>账户root用户</h3><ul>
<li>Root帐户凭据是登录AWS账户的电子邮件地址和密码</li>
<li>Root Credentials具有对AWS账户的完全不受限制的访问权限，包括包含敏感信息的帐户安全凭证</li>
<li>IAM最佳实践 - 创建AWS账户后，请勿使用或共享Root帐户，而应创建具有管理员权限的单独用户</li>
<li>可以为除账户安全凭证，账单信息和更改密码的能力之外的对AWS账户具有完全访问权限的所有活动创建管理员帐户</li>
</ul>
<h3 id="IAM用户"><a href="#IAM用户" class="headerlink" title="IAM用户"></a>IAM用户</h3><ul>
<li>IAM用户是在 AWS 中创建的实体。IAM 用户表示使用 IAM 用户与 AWS 互动的人员或服务</li>
<li>IAM最佳实践——创建个人用户</li>
<li>用户凭据包含以下内容<ul>
<li>通过AWS管理控制台访问AWS服务的密码</li>
<li>访问密钥/秘密访问密钥，通过API，CLI或SDK访问AWS服务</li>
</ul>
</li>
<li>IAM用户无权限启动，无权在任何AWS资源上执行任何AWS操作，应根据工作职能要求授予权限</li>
<li>IAM最佳实践——授予最低权限</li>
<li>每个IAM用户都与一个且仅一个AWS账户相关联</li>
<li>无法从AWS管理控制台重命名IAM用户，必须通过CLI或SDK工具完成</li>
<li>用户是访问策略标识的主体</li>
</ul>
<p><img src="https://i.loli.net/2019/09/09/vVyOgbGlhUE7WK1.png" alt="screen-shot-2016-04-06-at-10-41-58-am.png"></p>
<h3 id="IAM-组"><a href="#IAM-组" class="headerlink" title="IAM 组"></a>IAM 组</h3><ul>
<li>IAM组是IAM用户的集合</li>
<li>IAM组可用于为共享相同作业功能的用户集合指定权限，从而使其更易于管理</li>
<li>IAM最佳实践——使用组为IAM用户分配权限</li>
<li>组不是真正的标识，因为它无法在访问策略中被标识为主体。它只是一种将策略附加到多个用户的方法</li>
<li>一个组可以有多个用户，而一个用户可以属于多个组（最多10个）</li>
<li>组不能嵌套，只能包含用户</li>
<li>AWS不提供任何默认组来容纳其中的所有用户，如果需要，则应创建分配给它的所有用户</li>
<li>删除组要求在删除组之前分离用户和托管策略并删除任何内联策略。使用AWS管理控制台，可以完成删除和分离</li>
</ul>
<h3 id="IAM-角色"><a href="#IAM-角色" class="headerlink" title="IAM 角色"></a>IAM 角色</h3><ul>
<li>IAM角色与用户非常相似，因为它是具有权限策略的标识，用于确定身份在AWS中可以做什么和不能做什么。</li>
<li>角色旨在让需要它的任何人代入，而不是唯一地与某个人员关联</li>
<li>角色没有与之关联的任何凭据（密码或访问密钥），并且为角色提供动态临时凭证的人员</li>
<li>角色有助于访问委派，以授予允许访问控制的资源的某人的权限</li>
<li>角色可以帮助防止意外访问或修改敏感资源</li>
<li>可以随时修改角色，并且更改会立即反映在与角色关联的所有实体中</li>
<li>IAM角色在以下场景中起着非常重要的作用<ul>
<li>运行需要访问其他AWS服务的应用程序的EC2实例等服务</li>
<li>允许来自不同AWS账户的用户可以访问不同账户中的AWS资源，而无需创建用户</li>
<li>公司使用企业身份验证机制，不希望用户进行两次身份验证或在AWS中创建重复用户</li>
<li>应用程序允许通过外部认证机制登录 亚马逊，Facebook，谷歌等</li>
</ul>
</li>
<li>角色可由以下用户使用：<ul>
<li>与该角色在相同 AWS 账户中的 IAM 用户</li>
<li>位于与该角色不同的 AWS 账户中的 IAM 用户</li>
<li>由 AWS 提供的 Web 服务，如 Amazon Elastic Compute Cloud (Amazon EC2)</li>
<li>由与 SAML 2.0 或 OpenID Connect 兼容的外部身份提供商 (IdP) 服务或定制的身份代理进行身份验证的外部用户</li>
</ul>
</li>
<li>角色包含两种策略<ul>
<li>Trust policy<ul>
<li>信任策略定义——谁可以担任此角色</li>
<li>信任策略涉及在拥有资源的帐户（信任帐户）与拥有需要访问资源的用户的帐户（可信帐户）之间建立信任</li>
</ul>
</li>
<li>Permissions policy<ul>
<li>权限策略定义——可以访问的内容</li>
<li>权限策略确定授权，授予角色的用户在资源上执行所需任务所需的权限</li>
</ul>
</li>
</ul>
</li>
<li>如果是管理 AWS 外部的用户身份，则可以使用IAM身份提供商而不必在AWS账户中创建IAM用户。利用身份提供商 (IdP)，可以管理 AWS 外部的用户身份，并向这些外部用户身份授予使用账户中的AWS资源的权限<ul>
<li>用户还可以登录与SAML兼容的企业身份系统</li>
<li>用户可以登录Web身份提供商，例如使用Amazon，Facebook，Google或任何与OpenID connect（OIDC）兼容的IdP登录。</li>
<li>使用OIDC和SAML 2.0配置这些外部身份提供程序与AWS之间的信任关系时，会将用户分配给IAM角色并接收临时凭据，以使用户能够访问AWS资源</li>
</ul>
</li>
<li>IAM最佳实践 - 为在EC2实例上运行的应用程序使用角色</li>
<li>IAM最佳实践 - 使用角色而不是共享凭据进行委派</li>
</ul>
<h2 id="AWS-STS-或临时访问凭证"><a href="#AWS-STS-或临时访问凭证" class="headerlink" title="AWS STS 或临时访问凭证"></a>AWS STS 或临时访问凭证</h2><ul>
<li>使用 AWS Security Token Service (AWS STS) 创建可控制对AWS 资源的访问的临时安全凭证，并将这些凭证提供给受信任用户</li>
<li>AWS STS是一个具有单一endpoint的<a href="https://sts.amazonaws.com的全球服务" target="_blank" rel="noopener">https://sts.amazonaws.com的全球服务</a></li>
<li>AWS STS API调用可以发送到全局端点或其中一个区域端点。 区域端点可以帮助减少延迟并提高API调用的性能</li>
<li>临时凭证类似于长期凭证，除了<ul>
<li>短期有效，并定期轮换，可配置为持续几分种到几小时</li>
<li>不必随应用程序分配或嵌入长期 AWS 安全凭证</li>
<li>临时安全凭证不随用户一起存储，而是动态生成并在用户提出请求时提供给用户</li>
<li>可允许用户访问 AWS 资源，而不必为这些用户定义AWS身份。<strong>临时凭证是角色和联合身份验证的基础</strong></li>
</ul>
</li>
</ul>
<h2 id="角色类型"><a href="#角色类型" class="headerlink" title="角色类型"></a>角色类型</h2><h3 id="AWS服务角色"><a href="#AWS服务角色" class="headerlink" title="AWS服务角色"></a>AWS服务角色</h3><ul>
<li>一些AWS服务需要与其他AWS服务进行交互，例如 EC2与S3，SQS等交互</li>
<li>最佳做法是使用IAM角色分配这些服务，而不是将IAM用户凭据直接嵌入或传递到实例中，因为将长期凭据分发和轮换到多个实例对于管理和潜在的安全风险来说是一项挑战</li>
<li>AWS自动为这些服务提供临时安全凭证，例如 代表其应用程序使用的Amazon EC2实例</li>
<li>删除与正在运行的EC2实例关联的角色或实例配置文件将破坏在该实例上运行的所有应用程序</li>
</ul>
<h4 id="创建流程"><a href="#创建流程" class="headerlink" title="创建流程"></a>创建流程</h4><ul>
<li>创建一个带有服务的IAM角色，这些服务将使用它作为受信任的实体，例如EC2，并定义具有访问服务需求的权限策略</li>
<li>启动实例时将角色(实际上是实例概要文件)与EC2服务关联</li>
<li>临时安全凭据在实例上可用，并在过期前自动旋转，以便始终可用有效集</li>
<li>应用程序可以直接使用实例元数据或通过AWS SDK检索临时凭据</li>
<li>运行在EC2实例上的应用程序现在可以使用角色中定义的权限访问其他AWS资源</li>
<li>应用程序(如果缓存凭据)需要确保在凭据过期之前使用正确的凭据</li>
</ul>
<h4 id="实例配置文件"><a href="#实例配置文件" class="headerlink" title="实例配置文件"></a>实例配置文件</h4><ul>
<li>实例配置文件是IAM角色的容器，可用于在实例启动时将角色信息传递给EC2实例</li>
<li>如果为EC2实例或通过AWS管理控制台使用EC2的任何其他服务创建了角色，AWS将自动创建与角色同名的实例概要文件。但是，如果角色是通过CLI创建的，那么还需要创建实例概要文件</li>
<li>实例概要文件只能包含一个IAM角色。然而，一个角色可以包含在多个实例概要文件中</li>
</ul>
<h3 id="跨账户访问角色"><a href="#跨账户访问角色" class="headerlink" title="跨账户访问角色"></a>跨账户访问角色</h3><ul>
<li>可以授予IAM用户权限来切换相同AWS帐户中的角色，或者切换到拥有的其他AWS帐户中定义的角色</li>
<li>角色还可用于从第三方拥有的AWS账户向IAM用户委派权限</li>
<li>必须显式地授予用户权限来承担此角色</li>
<li>用户必须使用AWS管理控制台主动切换到角色</li>
<li>可以为角色启用多重身份验证（MFA）保护，以便只有使用MFA设备登录的用户才能担任该角色</li>
<li>但是，一次只能应用一组权限。 承担角色的用户暂时放弃自己的权限，而是接受角色的权限。 当用户退出或停止使用该角色时，将恢复原始用户权限</li>
</ul>
<h4 id="创建流程-1"><a href="#创建流程-1" class="headerlink" title="创建流程"></a>创建流程</h4><p><img src="https://i.loli.net/2019/09/09/W6TnGrRz7oaBScI.png" alt="roles-usingroletodelegate.png"></p>
<ol>
<li>信任账户创建IAM 角色<ul>
<li>信任策略，该策略将帐户(受信任帐户)定义为可以访问资源的主体</li>
<li>权限策略，定义用户可以在可信帐户中访问哪些资源</li>
</ul>
</li>
<li>信任帐户向受信任帐户提供帐户ID和角色名称（或ARN）</li>
<li>信任帐户向受信任帐户提供帐户ID和角色名称(或ARN)</li>
<li>如果可信帐户是由第三方拥有的，它可以选择性地提供一个外部ID(建议用于附加安全性)，这是惟一标识可信帐户所必需的，可以将其作为一个条件添加到可信策略中</li>
<li>可信帐户创建一个IAM用户，该用户具有权限(调用AWS安全令牌服务(AWS STS)的权限，假设角色使用API)来承担角色/切换到角色</li>
<li>可信帐户中的IAM用户切换到角色/假设该角色并传递该角色的ARN</li>
<li>属于第三方的可信帐户也将传递映射到可信帐户的外部ID</li>
<li>AWS STS验证对角色ARN、外部ID(如果有)的请求，以及是否来自与角色的信任策略匹配的受信任资源，以及的请求<br>AWS在验证成功后返回临时凭证</li>
<li>临时凭证允许用户访问信任帐户的资源</li>
<li>当用户退出角色时，用户的权限将恢复到切换到角色之前所持有的原始权限</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/08/30/AWS-DynamoDB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/30/AWS-DynamoDB/" itemprop="url">AWS DynamoDB</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-30T21:23:32+08:00">
                2019-08-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS/" itemprop="url" rel="index">
                    <span itemprop="name">AWS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>DynamoDB</p>
<ul>
<li>Amazon DynamoDB 是一种完全托管的 NoSQL 数据库服务，提供快速且可预测的性能，同时还能够实现无缝扩展</li>
<li>DynamoDB使客户能够将操作和扩展分布式数据库的管理负担卸载到AWS，而无需担心硬件配置，设置和配置，复制，软件修补或群集扩展。</li>
<li>DynamoDB表没有固定的模式，表由项组成，每个项可能具有不同数量的属性。</li>
<li>DynamoDB在AWS区域中的三个设施之间同步复制数据，从而提供高可用性和数据持久性。</li>
<li>DynamoDB支持快速就地更新。 可以使用单个API调用连续递增或递减数字属性</li>
<li>DynamoDB使用经过验证的加密方法来安全地验证用户身份并防止未经授权的数据访问</li>
<li>内置耐用性，性能，可靠性和安全性，具有SSD（固态驱动器）存储和自动3向复制。</li>
<li>DynamoDB吞吐量和单位数毫秒级延迟使其非常适合游戏，广告技术，移动和许多其他应用程序</li>
<li>ElastiCache可以在DynamoDB之前使用，以便为非频繁更改的数据卸载大量读取</li>
</ul>
<h2 id="DynamoDB-核心组件"><a href="#DynamoDB-核心组件" class="headerlink" title="DynamoDB 核心组件"></a>DynamoDB 核心组件</h2><ul>
<li>在 DynamoDB 中，表、项目和属性是使用的核心组件。表 是项目 的集合，而每个项目是属性 的集合。</li>
<li>DynamoDB 使用主键来唯一标识表中的每个项目，并且使用二级索引来提供更大的查询灵活性。</li>
<li>可以使用 DynamoDB 流 捕获 DynamoDB 表中的数据修改事件</li>
</ul>
<h3 id="表、项目和属性"><a href="#表、项目和属性" class="headerlink" title="表、项目和属性"></a>表、项目和属性</h3><ul>
<li>表 – 类似于其他数据库系统，DynamoDB 将数据存储在表中。表 是数据的集合。例如，请参阅名为 People 的示例表，该表可用于存储有关好友、家人或关注的任何其他人的个人联系信息。也可以建立一个 Cars 表，存储有关人们所驾驶的车辆的信息。</li>
<li>项目 – 每个表包含零个或更多个项目。项目 是一组属性，具有不同于所有其他项目的唯一标识。在 People 表中，每个项目表示一位人员。在 Cars 表中，每个项目代表一种车。DynamoDB 中的项目在很多方面都类似于其他数据库系统中的行、记录或元组。在 DynamoDB 中，对表中可存储的项目数没有限制。</li>
<li>属性 – 每个项目包含一个或多个属性。属性 是基础的数据元素，无需进一步分解。例如，People 表中的一个项目包含名为 PersonID、LastName、FirstName 等的属性。对于 Department 表，项目可能包含 DepartmentID、Name、Manager 等属性。DynamoDB 中的属性在很多方面都类似于其他数据库系统中的字段或列。</li>
</ul>
<p><img src="https://i.loli.net/2019/08/30/C9BSzdZ574DRbKr.png" alt="HowItWorksPeople.png"></p>
<ul>
<li>表中的每个项目都有一个唯一的标识符或主键，用于将项目与表中的所有其他内容区分开来。在 People 表中，主键包含一个属性 (PersonID)。</li>
<li>与主键不同，People 表是无架构的，这表示属性及其数据类型都不需要预先定义。每个项目都能拥有其自己的独特属性。</li>
<li>大多数属性是标量 类型的，这表示它们只能具有一个值。字符串和数字是标量的常见示例。</li>
<li>某些项目具有嵌套属性 (Address)。DynamoDB 支持最高 32 级深度的嵌套属性。<br><img src="https://i.loli.net/2019/08/30/GSYNeTnXLj5ECK6.png" alt="HowItWorksMusic.png"></li>
<li>Music 的主键包含两个属性（Artist 和 SongTitle）。表中的每个项目必须具有这两个属性。Artist 和 SongTitle 的属性组合用于将表中的每个项目与所有其他内容区分开来。</li>
<li>与主键不同，Music 表是无架构的，这表示属性及其数据类型都不需要预先定义。每个项目都能拥有其自己的独特属性。</li>
<li>其中一个项目具有嵌套属性 PromotionInfo，该属性包含其他嵌套属性。DynamoDB 支持最高 32 级深度的嵌套属性。</li>
</ul>
<h3 id="主键"><a href="#主键" class="headerlink" title="主键"></a>主键</h3><p>DynamoDB 支持两种不同类型的主键：</p>
<ul>
<li><p>分区键 – 由一个名为 partition key 的属性构成的简单主键。</p>
<ul>
<li>DynamoDB 使用分区键的值作为内部散列函数的输入。来自散列函数的输出决定了项目将存储到的分区 (DynamoDB 内部的物理存储)。</li>
<li>在只有分区键的表中，任何两个项目都不能有相同的分区键值。</li>
<li>表、项目和属性 中所述的 People 表是带简单主键 (PersonID) 的示例表。可以直接访问 People 表中的任何项目，方法是提供该项目的 PersonId 值。</li>
</ul>
</li>
<li><p>分区键和排序键 – 称为复合主键，此类型的键由两个属性组成。第一个属性是分区键，第二个属性是排序键。</p>
<ul>
<li>DynamoDB 使用分区键值作为对内部散列函数的输入。来自散列函数的输出决定了项目将存储到的分区 (DynamoDB 内部的物理存储)。具有相同分区键值的所有项目按排序键值的排序顺序存储在一起。</li>
<li>在具有分区键和排序键的表中，两个项目可能具有相同的分区键值。但是，这两个项目必须具有不同的排序键值。</li>
<li>表、项目和属性中所述的 Music 表是包含一个复合主键（Artist 和 SongTitle）的表的示例。可以直接访问 Music 表中的任何项目，方法是提供该项目的 Artist 和 SongTitle 值。</li>
<li>在查询数据时，复合主键可让获得额外的灵活性。例如，如果仅提供了 Artist 的值，则 DynamoDB 将检索该艺术家的所有歌曲。要仅检索特定艺术家的一部分歌曲，可以提供一个 Artist 值和一系列 SongTitle 值。</li>
</ul>
</li>
<li><p>项目的分区键也称为其哈希属性。哈希属性 一词源自 DynamoDB 中使用的内部哈希函数，以基于数据项目的分区键值实现跨多个分区的数据项目平均分布。</p>
</li>
<li><p>项目的排序键也称为其范围属性。范围属性 一词源自 DynamoDB 存储项目的方式，它按照排序键值有序地将具有相同分区键的项目存储在互相紧邻的物理位置。</p>
</li>
<li><p>每个主键属性必须为标量 (表示它只能具有一个值)。主键属性唯一允许的数据类型是字符串、数字和二进制。对于其他非键属性没有任何此类限制。</p>
</li>
</ul>
<h3 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h3><ul>
<li>DynamoDB 支持两种索引：<ul>
<li>Global secondary index – 一种带有可能与表中不同的分区键和排序键的索引。</li>
<li>本地二级索引 – 分区键与表中的相同但排序键与表中的不同的索引。</li>
</ul>
</li>
<li>DynamoDB 中的每个表具有 20 个全局二级索引（默认限制）和 5 个本地二级索引的限制。</li>
<li>在前面显示的示例 Music 表中，可以按 Artist（分区键）或按 Artist 和 SongTitle（分区键和排序键）查询数据项。如果还想要按 Genre 和 AlbumTitle 查询数据，该怎么办？ 若要达到此目的，可在 Genre 和 AlbumTitle 上创建一个索引，然后通过与查询 Music 表相同的方式查询索引。</li>
<li>下图显示了示例 Music 表，该表包含一个名为 GenreAlbumTitle 的新索引。在索引中，Genre 是分区键，AlbumTitle 是排序键。<br><img src="https://i.loli.net/2019/08/30/YkLegfJ5RuO6cI4.png" alt="HowItWorksGenreAlbumTitle.png"><ul>
<li>每个索引属于一个表（称为索引的基表）。在上述示例中，Music 是 GenreAlbumTitle 索引的基表。</li>
<li>DynamoDB 将自动维护索引。当添加、更新或删除基表中的某个项目时，DynamoDB 会添加、更新或删除属于该表的任何索引中的对应项目。</li>
<li>当创建索引时，可指定哪些属性将从基表复制或投影 到索引。DynamoDB 至少会将键属性从基表投影到索引中。对于 GenreAlbumTitle 也是如此，只不过此时只有 Music 表中的键属性会投影到索引中。</li>
<li>可以查询 GenreAlbumTitle 索引以查找某个特定流派的所有专辑（例如，所有 Rock 专辑）。还可以查询索引以查找特定流派中具有特定专辑名称的所有专辑（例如，名称以字母 H 开头的所有 Country 专辑）。</li>
</ul>
</li>
</ul>
<h2 id="DynamoDB-流"><a href="#DynamoDB-流" class="headerlink" title="DynamoDB 流"></a>DynamoDB 流</h2><ul>
<li>DynamoDB 流 是一项可选功能，用于捕获 DynamoDB 表中的数据修改事件。有关这些事件的数据将以事件发生的顺序近乎实时地出现在流中。</li>
<li>每个事件由一条流记录 表示。如果对表启用流，则每当以下事件之一发生时，DynamoDB 流 都会写入一条流记录：<ul>
<li>向表中添加了新项目：流将捕获整个项目的映像，包括其所有属性。</li>
<li>更新了项目：流将捕获项目中已修改的任何属性的“之前”和“之后”映像。</li>
<li>从表中删除了项目：流将在整个项目被删除前捕获其映像。</li>
</ul>
</li>
<li>每条流记录还包含表的名称、事件时间戳和其他元数据。流记录具有 24 个小时的生命周期；在此时间过后，它们将从流中自动删除。</li>
</ul>
<h2 id="DynamoDB-性能"><a href="#DynamoDB-性能" class="headerlink" title="DynamoDB 性能"></a>DynamoDB 性能</h2><ul>
<li>自动水平缩放</li>
<li>固态硬盘（SSD）上运行<ul>
<li>SSD有助于实现可预测的低延迟响应时间的设计目标，以便以任何规模存储和访问数据。</li>
<li>SSD高I / O性能使其能够经济高效地为大规模请求工作负载提供服务，并以低请求定价传递此效率</li>
</ul>
</li>
<li>允许配置读写速率<ul>
<li>按需扩大吞吐量</li>
<li>每个UTC日历可以缩减吞吐量</li>
</ul>
</li>
<li>自动分区，重新分配和重新分区数据，并提供额外的服务器容量<ul>
<li>随着表的增大</li>
<li>预配置吞吐量增加</li>
</ul>
</li>
<li>全局二级索引<ul>
<li>可以预先创建或稍后添加</li>
</ul>
</li>
</ul>
<h2 id="DynamDB-一致性"><a href="#DynamDB-一致性" class="headerlink" title="DynamDB 一致性"></a>DynamDB 一致性</h2><ul>
<li>每个DynamoDB表自动存储在三个分散的地理位置，以确保数据一致性；</li>
<li>读取一致性表示在同一项的后续读取操作中反映数据项的成功写入或更新的方式和时间</li>
<li>DynamoDB 支持最终一致性 和强一致性 读取。<ul>
<li>最终一致性读取<ul>
<li>最终一致性选项可最大化读取吞吐量。</li>
<li>所有副本的一致性通常在一秒钟内达到</li>
<li>但是，最终一致的读取可能不会反映最近完成的写入的结果。</li>
<li>短时间后重复读取应返回更新的数据。 </li>
</ul>
</li>
<li>强一致性读取<ul>
<li>强一致性读取返回的结果反映了在读取之前收到成功响应的所有写入</li>
</ul>
</li>
</ul>
</li>
<li>Query，GetItem和BatchGetItem操作默认执行最终一致的读取<ul>
<li>Query和GetItem操作可以强制一致</li>
<li>查询操作无法对全局二级索引执行强一致性读取</li>
<li>可以强制BatchGetItem操作在每个表的基础上强一致</li>
</ul>
</li>
</ul>
<h2 id="DynamoDB-安全"><a href="#DynamoDB-安全" class="headerlink" title="DynamoDB 安全"></a>DynamoDB 安全</h2><ul>
<li>细粒度访问控制（FGAC）可以高度控制表中的数据</li>
<li>FGAC帮助控制谁（调用者）可以访问表的哪些项或属性并执行哪些操作（读/写功能）</li>
<li>FGAC与IAM集成，后者管理安全凭证和相关权限</li>
</ul>
<h2 id="DynamoDB跨区域复制"><a href="#DynamoDB跨区域复制" class="headerlink" title="DynamoDB跨区域复制"></a>DynamoDB跨区域复制</h2><ul>
<li><p>DynamoDB跨区域复制允许在一个或多个AWS区域中维护DynamoDB表（称为主表）的相同副本（称为副本）</p>
</li>
<li><p>对表的写入将自动传播到所有副本</p>
</li>
<li><p>跨区域复制当前支持单主模式。单主具有一个主表和一个或多个副本表</p>
</li>
<li><p>读取副本将异步更新，因为一旦主表接受了写入操作，DynamoDB就会将写入操作确认为成功。然后，写入将稍微延迟地传播到每个副本</p>
</li>
<li><p>跨区域复制在一下场景中很有用</p>
<ul>
<li>如果发生数据中心故障，则进行快速灾难恢复</li>
<li>通过从最近的AWS数据中心读取DynamoDB表，更快地提供数据，从而更快地为多个地区的客户进行读取。</li>
<li>更轻松的流量管理，可以跨表分配读取工作负载，从而在主表中消耗更少的读取容量。</li>
<li>通过提升读取副本成主来轻松实现区域迁移</li>
<li>实时数据迁移，复制数据以及表同步时，切换应用程序以写入目标区域</li>
</ul>
</li>
<li><p>跨区域复制成本取决于</p>
<ul>
<li>预配置吞吐量（写入和读取）</li>
<li>存储副本表的大小</li>
<li>跨地区的数据传输</li>
<li>从DynamoDB Streams读取数据以使表保持同步</li>
<li>根据实例类型和区域配置EC2实例的成本，以承载复制过程。</li>
</ul>
<p>注意：已执行DynamoDB上的跨区域复制，定义AWS Data Pipeline作业，该作业在DynamoDB流和开箱即用跨区域复制支持之前在内部使用EMR传输数据</p>
<h2 id="全局表"><a href="#全局表" class="headerlink" title="全局表"></a>全局表</h2><ul>
<li>Amazon DynamoDB 全局表 为部署多区域、多主机数据库提供了完全托管的解决方案，而不必构建和维护自己的复制解决方案。</li>
<li>可支持数据访问位置和数据库工作负载的区域容错</li>
<li>应用程序现在可以在世界各地的AWS区域中对DynamoDB执行读取和写入操作，任何区域中的更改都会传播到复制表的每个区域</li>
<li>全局表有助于构建应用程序以利用数据局部性来减少总体延迟。</li>
<li>全局表确保最终的一致性</li>
<li>全局表在单个AWS账户内的区域之间复制数据，目前不支持跨账户访问</li>
</ul>
<h2 id="DynamoDB-Streams"><a href="#DynamoDB-Streams" class="headerlink" title="DynamoDB Streams"></a>DynamoDB Streams</h2><ul>
<li>AWS 为 DynamoDB 和 DynamoDB 流 维护单独的终端节点。要使用数据库表和索引，应用程序需要访问 DynamoDB 终端节点。要读取和处理 DynamoDB 流 记录，应用程序需要访问相同区域内的 DynamoDB 流 终端节点</li>
<li>DynamoDB Streams提供按时间排序的项目级更改序列，在过去24小时内对表中的数据进行更改，之后将其删除</li>
<li>DynamoDB Streams维护每个项目的有序事件序列，但不维护项目例</li>
<li>例如，假设有一个DynamoDB表跟踪游戏的高分，并且表中的每个项目代表一个单独的玩家。如果按此顺序进行以下三次更新：  <ul>
<li>更新1：将玩家1的高分改为100分  </li>
<li>更新2：将玩家2的高分改为50分</li>
<li>更新3：将玩家1的高分改为125分</li>
<li>DynamoDB Streams将维护Player 1得分事件的顺序。但是，它不会维持玩家之间的秩序。因此，在2个玩家1事件之间无法保证玩家2得分事件</li>
</ul>
</li>
<li>DynamoDB 流 确保以下内容：<ul>
<li>每个流记录仅在流中显示一次。</li>
<li>对于 DynamoDB 表中修改的每个项目，流记录将按照对该项目进行的实际修改的顺序显示</li>
</ul>
</li>
<li>DynamoDB流可用于多区域复制，以使其他数据存储与DynamoDB的最新更改保持同步，或根据对表所做的更改执行操作</li>
<li>DynamoDB Streams API可帮助开发人员在更改项目之前和之后使用更新并接收项目级数据 </li>
<li>DynamoDB Streams允许读取速度高达DynamoDB表的预配置写入容量的两倍</li>
<li>必须基于每个表启用DynamoDB Streams</li>
</ul>
<h2 id="DynamoDB-触发器"><a href="#DynamoDB-触发器" class="headerlink" title="DynamoDB 触发器"></a>DynamoDB 触发器</h2><ul>
<li>DynamoDB触发器（就像数据库trigger）是一种允许基于表上的项级更新执行自定义操作的功能</li>
<li>DynamoDB触发器可用于发送通知，更新聚合表以及将DynamoDB表连接到其他数据源等方案</li>
<li>DynamoDB触发器流程<ul>
<li>DynamoDB触发器的自定义逻辑作为代码存储在AWS Lambda函数中。</li>
<li>可以通过将AWS Lambda函数与表上的流（通过DynamoDB Streams）相关联来创建给定表的触发器。</li>
<li>更新表后，更新将发布到DynamoDB Streams。</li>
<li>反过来，AWS Lambda从关联的流中读取更新并执行函数中的代码。</li>
</ul>
</li>
</ul>
<h2 id="DynamoDB-Accelerator-DAX"><a href="#DynamoDB-Accelerator-DAX" class="headerlink" title="DynamoDB Accelerator DAX"></a>DynamoDB Accelerator DAX</h2><ul>
<li>DynamoDB Accelerator（DAX）是DynamoDB的完全托管，高可用性内存缓存，可提供高达10倍的性能提升 - 从毫秒到微秒 - 甚至可达到每秒数百万个请求。</li>
<li>DAX完成了向表中添加内存加速所需的所有繁重工作，而无需开发人员管理缓存失效，数据填充或集群管理。</li>
<li>DAX具有容错性和可扩展性。</li>
<li>DAX群集具有主节点和零个或多个读副本节点。 当主节点发生故障时，DAX将自动进行故障转移并选择新的主节点。 对于缩放，添加或删除只读副本</li>
</ul>
<h2 id="VPC端点"><a href="#VPC端点" class="headerlink" title="VPC端点"></a>VPC端点</h2><ul>
<li>DynamoDB的VPC端点通过在VPC内启用对DynamoDB的私有访问，而无需Internet网关或NAT网关，从而提高了隐私和安全性，尤其是那些处理具有合规性和审计要求的敏感工作负载的端点。</li>
<li>DynamoDB的VPC端点支持IAM策略以简化DynamoDB访问控制，其中访问可以限制为特定的VPC端点。</li>
<li>只能为与VPC位于同一AWS区域中的Amazon DynamoDB表创建VPC端点</li>
<li>无法使用DynamoDB的VPC端点访问DynamoDB Streams</li>
</ul>
<h2 id="DynamoDB-加密"><a href="#DynamoDB-加密" class="headerlink" title="DynamoDB 加密"></a>DynamoDB 加密</h2><ul>
<li>传输加密<ul>
<li>可以通过在客户端加密敏感数据或使用加密连接（TLS）来完成</li>
</ul>
</li>
<li>静态加密<ul>
<li>存储在 Amazon DynamoDB 中的所有用户数据完全处于静态加密之中</li>
<li>DynamoDB 静态加密通过在加密表中保护数据来提供额外的一层数据保护，包括其主键、本地和全局二级索引、流、全局表、备份和 DynamoDB Accelerator (DAX) 集群</li>
<li>静态加密与 AWS KMS 集成，以管理用于加密表的加密密钥。</li>
<li>只能为新表启用静态加密，而不能为现有表启用加密</li>
<li>一旦为表启用加密，就无法禁用</li>
<li>DynamoDB Streams不支持加密</li>
<li>使用S3的服务器端加密对加密的DynamoDB表的按需备份进行加密</li>
<li>静态加密使用256位AES加密对数据进行加密。</li>
</ul>
</li>
</ul>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ul>
<li>使用的表的数量保持最小值</li>
<li>在DynamoDB中存储元数据，在Amazon S3中存储大型BLOB</li>
<li>使用每天，每周，每月等表来存储时间序列数据</li>
<li>使用条件或乐观并发控制（OCC）更新</li>
<li>乐观并发控制就像RDMS中的乐观锁定一样</li>
<li>OCC通常用于数据争用较少的环境，冲突很少，可以完成事务而无需管理锁和事务</li>
<li>OCC假设可以经常完成多个交易而不会相互干扰</li>
<li>使用数据资源执行事务，而不获取对这些资源的锁定并等待清除其他事务锁定</li>
<li>在提交事务之前，将验证数据是否被任何其他事务修改。如果是这样，它将被回滚并需要使用更新的数据重新启动</li>
<li>与其他并发控制方法（如悲观锁定）相比，OCC导致更高的吞吐量，因为即使在避免死锁时，锁定也会极大地限制有效并发性</li>
<li>避免热键和热分区</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/08/30/AWS-CloudFront/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/30/AWS-CloudFront/" itemprop="url">AWS CloudFront</a></h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-30T19:44:53+08:00">
                2019-08-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS/" itemprop="url" rel="index">
                    <span itemprop="name">AWS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="CloudFront-overview"><a href="#CloudFront-overview" class="headerlink" title="CloudFront overview"></a>CloudFront overview</h2><ul>
<li>Amazon CloudFront 是一个 Web 服务，它加快将静态和动态 Web 内容（如 .html、.css、.js 和图像文件）分发到用户的速度</li>
<li>CloudFront 通过全球数据中心网络传输内容，这些数据中心称为边缘站点。当用户请求用 CloudFront 提供的内容时，用户被路由到提供最低延迟 (时间延迟) 的边缘站点，从而以尽可能最佳的性能传送内容</li>
<li>CloudFront通过将每个用户请求路由到最能为内容提供服务的边缘位置来加速内容的分发，从而提供最低的延迟</li>
<li>CloudFront可显着减少用户请求必须通过的网络跃点数，从而有助于提高性能，提供更低的延迟和更高的数据传输速率</li>
<li>CloudFront是分发经常访问的静态内容的最好选择，这些内容受益于边缘交付 - 如流行的网站图像，视频，媒体文件或软件下载</li>
</ul>
<h2 id="CloudFront-Benefits"><a href="#CloudFront-Benefits" class="headerlink" title="CloudFront Benefits"></a>CloudFront Benefits</h2><ul>
<li>CloudFront消除了在互联网上多个站点中进行缓存服务器网络的费用和复杂性，以及过度配置容量的需要，以便在潜在的流量爆发中也能提供服务</li>
<li>提供数据更高的可靠性和可用性，对象的副本保存在世界各地的边缘位置</li>
<li>CloudFront与源服务器保持持久连接，以便可以尽快从源服务器获取这些文件</li>
<li>在诸如多个用户同时在边缘位置同时获取相同源文件请求中，折叠请求次数，减少对源站点的负载</li>
<li>CloudFront与AWS WAF集成，后者一种web应用程序防火墙，允许通过基于IP地址，HTTP标头和自定义URL字符串配置的规则来保护web应用</li>
</ul>
<h2 id="Configuration-amp-Content-Delivery"><a href="#Configuration-amp-Content-Delivery" class="headerlink" title="Configuration &amp; Content Delivery"></a>Configuration &amp; Content Delivery</h2><ul>
<li>Configuration<ol>
<li>指定源服务器以获取要分发的文件。源服务器将存储对象的原始最终版本。如果通过 HTTP 提供内容，源服务器将为 Amazon S3 存储桶或 HTTP 服务器；使用 Adobe Media Server RTMP 协议按需分发媒体文件，则源服务器始终为 Amazon S3 存储桶</li>
<li>添加/上载到源服务器上的文件请使用公共读取权限或限制性OAI权限</li>
<li>创建一个 CloudFront 分配，在用户通过网站或应用程序请求文件时，这会指示 CloudFront 从哪些源服务器中获取文件</li>
<li>CloudFront 将分配的配置（而不是的内容）发送到它的所有边缘站点，边缘站点是位于地理位置分散的数据中心（CloudFront 在其中缓存对象的副本）的服务器集合</li>
<li>网站可与CloudFront提供的域名或自定义备用域名一起使用</li>
<li>Origin服务器可以配置为限制访问协议，缓存行为，向文件添加标头以添加TTL或到期时间</li>
</ol>
</li>
<li>Content delivery to users<ol>
<li>当用户访问网站时，DNS将请求路由指向到CloudFront边缘站点，该位置可以最低的延迟响应用户对网站文件或对象的访问</li>
<li>如果请求对象存在于edge 位置缓存中，则cloudfront会立即返回该对象</li>
<li>如果请求对象不在edge位置缓存中，则cloudfront会从origin服务器请求对象，并在它开始接收数据事就返回给用户</li>
<li>当对象到达其TTL值时，对于任何新请求，cloudfront会向origin服务器检查任何新版本，若有则更新，若没有则继续当前版本</li>
</ol>
</li>
</ul>
<h2 id="Delivery-Methods"><a href="#Delivery-Methods" class="headerlink" title="Delivery Methods"></a>Delivery Methods</h2><h3 id="Web-分发"><a href="#Web-分发" class="headerlink" title="Web 分发"></a>Web 分发</h3><ul>
<li>支持静态或动态内容，例如使用HTTP或HTTPS的html、css、js、图像等</li>
<li>多媒体内容支持HLS或渐进式下载使用<ul>
<li>对于按需流式传输，可以使用 CloudFront 以常见格式（如 MPEG DASH、Apple HLS、Microsoft 平滑流和 CMAF）将内容流式传输到任何设备。</li>
<li>对于广播实时流，可以在边缘站点缓存媒体片段，以便将按正确顺序传输片段的清单文件的多个请求组合起来，从而减小源服务器的负载</li>
</ul>
</li>
<li>只是实时活动内容，如会议、音乐会、演唱会等。对于实时数据流，可以使用AWS Cloudformation堆栈自动创建分发</li>
<li>源站可以是S3或HTTP服务器，如web server或ELB</li>
</ul>
<h3 id="RTMP分发"><a href="#RTMP分发" class="headerlink" title="RTMP分发"></a>RTMP分发</h3><ul>
<li>支持使用Adobe Media Server和Adobe实时消息传递协议（RTMP）传输媒体文件</li>
<li>必须使用S3作为源站</li>
<li>使用cloudfront流逝传输媒体文件，需要一下支持<ul>
<li>媒体文件</li>
<li>媒体播放器，JW Player，Flowplayer或Adobe Flash</li>
</ul>
</li>
<li>最终用户使用提供的媒体播放器查看媒体文件，而不是本地安装的播放器</li>
<li>用户使用流逝传输媒体文件时，一边播放一遍下载</li>
<li>媒体文件并不存放于本地存储系统上</li>
<li>需要创建两个cloudfront分配，媒体播放器的web分发和媒体文件的RMTP分发</li>
<li>媒体播放器和媒体文件可以存储在同一个源S3或不同bucket中</li>
</ul>
<h3 id="源"><a href="#源" class="headerlink" title="源"></a>源</h3><ul>
<li>源站可以是S3或者HTTP服务器</li>
<li>HTTP服务器作为源站，需要映射其资源的域名，且文件必须是公共可读的</li>
<li>对于使用S3 作为源站，使用bucket地址或静态网址端点地址，文件需要公开读取或OAI受限保护</li>
<li>可以使用Origin Access Identity配置源限制访问（仅限S3），以防止直接访问S3对象</li>
<li>每个存储同，支持分配多个源，并将其用户请求分配到不同的缓存规则上。缓存行为中的路径模式决定哪些请求路由到与缓存行为关联的源(S3 bucket)</li>
</ul>
<h2 id="Cache-behavior"><a href="#Cache-behavior" class="headerlink" title="Cache behavior"></a>Cache behavior</h2><p>缓存行为为网站上文件的特定 URL 路径模式配置各种 CloudFront 功能</p>
<ul>
<li>路径模式。</li>
<li>如果为 CloudFront 分配配置了多个源，希望 CloudFront 将的请求转发到哪个源。</li>
<li>是否将查询字符串转发到源。</li>
<li>是否访问指定文件需要签名 URL。</li>
<li>是否要求用户使用 HTTPS 访问那些文件。</li>
<li>那些文件保留在 CloudFront 缓存中的最小时间长度，不管源添加到文件中的任何 Cache-Control 标头的值。</li>
</ul>
<h2 id="Vuewer-Protocol-Policy"><a href="#Vuewer-Protocol-Policy" class="headerlink" title="Vuewer Protocol Policy"></a>Vuewer Protocol Policy</h2><blockquote>
<p>可以配置查看器协议策略以定义允许的访问协议。 可以是HTTP和HTTPS，也可以是仅HTTPS或HTTP重定向到HTTPS</p>
</blockquote>
<h3 id="HTTPS-connection"><a href="#HTTPS-connection" class="headerlink" title="HTTPS connection"></a>HTTPS connection</h3><ul>
<li>在CloudFront和Viewers之间，可以将缓存分发配置为允许HTTP或HTTPS请求，或仅使用HTTPS，或将所有HTTP请求重定向到HTTPS</li>
<li>在CloudFront和Origin之间，可以将缓存分布配置为要求CloudFront使用HTTPS从源中提取对象，或者CloudFront使用查看器用于请求对象的协议。</li>
<li>S3 作为源站<ul>
<li>对于网站，协议必须是HTTP，因为不支持HTTPS</li>
<li>对于S3存储桶，默认的Origin协议策略是Match Viewer，无法更改。 因此，当CloudFront配置为在查看器和CloudFront之间需要HTTPS时，它会自动使用HTTPS与S3通信。</li>
</ul>
</li>
<li>通过使用以下方法，还可以将CloudFront配置为使用HTTPS处理备用域名： <ul>
<li>使用专用IP地址提供HTTPS请求</li>
<li>CloudFront将备用域名与专用IP地址相关联，并且证书与IP地址关联。 当从DNS服务器收到IP地址的请求时，</li>
<li>CloudFront使用IP地址标识分发和SSL / TLS证书以返回给查看者</li>
<li>无论用户使用何种浏览器或其他查看器，此方法都适用于每个HTTPS请求。</li>
<li>使用专用IP地址会产生额外的每月费用</li>
</ul>
</li>
<li>使用SNI提供HTTPS请求<ul>
<li>SNI自定义SSL依赖于TLS协议的SNI扩展，它允许通过包含主机名在同一IP地址上提供多个域</li>
<li>使用SNI方法，CloudFront将IP地址与备用域名相关联，但IP地址不是专用的</li>
<li>CloudFront无法根据IP地址确定请求所针对的域，因为IP地址不是专用的 </li>
<li>支持SNI的浏览器会自动从请求URL获取域名，并将其添加到请求标头中的新字段。</li>
<li>当CloudFront从支持SNI的浏览器收到HTTPS请求时，它会在请求标头中找到域名，并使用适用的SSL / TLS证书响应该请求。</li>
<li>Viewer和CloudFront执行SSL协商，CloudFront将请求的内容返回给查看器。</li>
<li>较旧的浏览器不支持它</li>
<li>除标准CloudFront数据传输和请求费用外，SNI Custom SSL无需额外费用</li>
</ul>
</li>
<li>对于端到端HTTPS连接，需要在Viewers和CloudFront＆CloudFront和Origin之间应用证书，并满足以下要求<ul>
<li>查看者和CloudFront之间的HTTPS<ul>
<li>由受信任的证书颁发机构（CA）（如Comodo，DigiCert或Symantec）颁发的证书;</li>
<li>由AWS Certificate Manager（ACM）提供的证书;</li>
<li>自签名证书。</li>
<li>CloudFront与自定义源之间的HTTPS</li>
<li>如果源不是ELB负载平衡器，则证书必须由受信任的CA（如Comodo，DigiCert或Symantec）颁发。</li>
<li>对于ELB负载平衡器，可以使用ACM提供的证书</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="允许的HTTP-方法"><a href="#允许的HTTP-方法" class="headerlink" title="允许的HTTP 方法"></a>允许的HTTP 方法</h3><ul>
<li>CloudFront支持GET，HEAD，OPTIONS，PUT，POST，PATCH，DELETE来获取，添加，更新和删除对象，以及获取对象标头。</li>
<li>GET，HEAD，OPTIONS方法仅使用CloudFront获取对象，对象标题或检索从源支持的选项列表</li>
<li>POST，PUT操作也可以用于加速，例如PUT操作，从Web表单提交数据，这些数据直接代理回原始服务器</li>
<li>CloudFront仅缓存对GET和HEAD请求以及（可选）OPTIONS请求的响应。 CloudFront不会缓存对PUT，POST，PATCH，DELETE请求方法的响应，并且这些请求将定向到源</li>
<li>PUT，POST http方法也有助于加速内容上传，因为这些操作将被发送到源，例如S3通过CloudFront边缘位置，提高效率，减少延迟，并允许应用程序受益于CloudFront从边缘位置到源服务器维护的受监视的持久连接</li>
</ul>
<h3 id="优化缓存和可用性"><a href="#优化缓存和可用性" class="headerlink" title="优化缓存和可用性"></a>优化缓存和可用性</h3><ul>
<li>控制cache max-age<ul>
<li>要增加缓存命中率，可以将origin配置为向对象添加Cache-Control max-age指令。</li>
<li>间隔越长，从原点检索的频率越低</li>
</ul>
</li>
<li>针对查询字符串参数进行缓存<ul>
<li>对于Web分发，可以将CloudFront配置为基于查询参数进行缓存</li>
<li>缓存性能可以提高<ul>
<li>将CloudFront配置为仅转发源将返回唯一对象的查询字符串。</li>
<li>对于例如参数值使用相同的情况。 参数值A或a，即使返回的响应或对象相同，CloudFront也会将相同的请求缓存两次</li>
<li>使用相同的参数顺序，例如 对于请求a = x＆b = y和b = y＆a = x，即使返回的响应或对象相同，CloudFront也会缓存相同的请求两次</li>
<li>对于RTMP分发，当CloudFront从源服务器请求对象时，它会删除任何查询字符串参数。</li>
</ul>
</li>
</ul>
</li>
<li>基于Cookie值的缓存<ul>
<li>对于Web分发，可以将CloudFront配置为基于cookie值进行缓存。</li>
<li>默认情况下，它在边缘位置缓存时不考虑cookie</li>
<li>缓存性能可以通过以下提高<ul>
<li>将 CloudFront 配置为仅转发指定的 Cookie 而不是转发所有 Cookie。对于配置 CloudFront 以转发到源的 Cookie，CloudFront 转发 Cookie 名称和值的所有组合，并分别缓存源返回的对象，即使这些对象完全相同。例如，如果请求包含2个包含3个可能值的cookie，则即使响应考虑了单个cookie，CloudFront也会缓存所有可能的组合，Cookie名称和值都区分大小写，因此最好坚持使用相同的大小写<ul>
<li>为静态和动态内容创建单独的缓存行为，并将CloudFront配置为仅将Cookie转发到源，例如用于动态内容。对于css文件，cookie没有意义，因为对象不会随cookie值而改变</li>
</ul>
</li>
<li>如果可能，为动态内容创建单独的缓存行为，对于每个用户，cookie值是唯一的（例如用户ID），动态内容根据较少数量的唯一值而变化，从而减少组合的数量</li>
</ul>
</li>
<li>对于RTMP分发，无法配置CloudFront进行处理cookie<ul>
<li>当CloudFront从源服务器请求对象时，它会在将请求转发到源之前删除所有cookie。 如果源返回任何cookie以及对象CloudFront在将对象返回给查看器之前删除它们。</li>
</ul>
</li>
</ul>
</li>
<li>请求标头进行缓存<ul>
<li>默认情况下，CloudFront在边缘位置缓存对象时不考虑标头。</li>
<li>CloudFront配置为基于请求标头进行缓存，不会更改CloudFront转发的标头，只会更改CloudFront是否根据标头值缓存对象</li>
<li>通过以下方式提高缓存性能<ul>
<li>将 CloudFront 配置为仅基于指定标头进行转发和缓存，而不是基于所有标头转发和缓存</li>
<li>尝试避免基于具有大量唯一值的请求标头进行缓存</li>
<li>CloudFront配置为将所有标头转发到源，CloudFront不会缓存与此缓存行为关联的对象。 相反，它将每个请求发送到原点</li>
<li>CloudFront基于标头值进行缓存，它不考虑标题名称的情况，但考虑标题值的情况</li>
</ul>
</li>
<li>对于RTMP分发，无法将CloudFront配置为基于标头值进行缓存。</li>
</ul>
</li>
</ul>
<h3 id="对象缓存和过期"><a href="#对象缓存和过期" class="headerlink" title="对象缓存和过期"></a>对象缓存和过期</h3><ul>
<li>对象到期时间即对象在从Origin再次获取之前保留在CloudFront缓存中的时间</li>
<li>低过期时间有助于提供频繁更改的内容，长过期时间有助于提高性能并减少原始负载</li>
<li>到期时间后，CloudFront会检查它是否仍具有最新版本</li>
<li>到期时间后，CloudFront会检查它是否仍具有最新版本<ul>
<li>如果缓存已具有最新版本，则origin返回304状态代码（未修改）。</li>
<li>如果CloudFront缓存没有最新版本，则原点返回200状态代码（OK）和对象的最新版本</li>
</ul>
</li>
<li>如果不经常请求边缘位置中的对象，CloudFront可能会逐出该对象，在其到期日期之前删除该对象，以便为最近请求的对象腾出空间。</li>
<li>默认情况下，每个对象在24小时后自动过期</li>
<li>对于Web分发，可以通过更改默认行为<ul>
<li>对于整个路径模式，可以通过设置Minimum TTL，Maximum TTL和Default TTL值来配置缓存行为</li>
<li>对于单个对象，可以将origin配置为向对象添加Cache-Control max-age或Cache-Control s-maxage指令或Expires头字段。</li>
<li>AWS建议在Expires标头上使用Cache-Control max-age指令来控制对象缓存行为</li>
<li>如果同时指定了Cache-Control max-age指令和Expires标头，则CloudFront仅使用<strong>Cache-Control max-age</strong>的值</li>
<li>来自查看器的GET请求中的HTTP Cache-Control或Pragma标头字段不能用于强制CloudFront返回到对象的源服务器</li>
<li>默认情况下，当原始返回HTTP 4xx或5xx状态代码时，CloudFront会将这些错误响应缓存五分钟，然后将该对象的下一个请求提交到原点以查看是否请求的对象可用</li>
</ul>
</li>
<li>对于RTMP分发<ul>
<li>可以将Cache-Control或Expires标头添加到对象，以更改CloudFront在将另一个请求转发到源之前将对象保留在边缓存中的时间。</li>
<li>最短持续时间为3600秒（一小时）。如果指定较低的值，CloudFront将使用3600秒。  </li>
</ul>
</li>
</ul>
<h2 id="配置安全访问和限制对内容的访问"><a href="#配置安全访问和限制对内容的访问" class="headerlink" title="配置安全访问和限制对内容的访问"></a>配置安全访问和限制对内容的访问</h2><h3 id="提供私有内容"><a href="#提供私有内容" class="headerlink" title="提供私有内容"></a>提供私有内容</h3><ul>
<li>可采用两种方式控制用户对私有内容的访问，如下图所示：<ul>
<li>限制对 CloudFront 边缘缓存中的文件的访问</li>
<li>通过执行下列操作之一，限制对源中文件的访问：<ul>
<li>为 Amazon S3 存储桶（除非已将其配置为网站终端节点）设置源访问身份 (OAI)</li>
<li>为私有 HTTP 服务器配置自定义标头或者将 Amazon S3 存储桶配置作为网站终端节点<br><img src="https://i.loli.net/2019/08/30/d2QlFRyZ4nkm6c8.png" alt="001.png"></li>
</ul>
</li>
</ul>
</li>
<li>创建签名 URL 或签名 Cookie 以控制对文件的访问时，可以指定以下限制：<ul>
<li>结束日期和时间，在此之后，URL 不再有效</li>
<li>（可选）URL 生效的日期和时间</li>
<li>（可选）可用于访问内容的 IP 地址或计算机的地址范围</li>
</ul>
</li>
<li>选择保护 Amazon S3 存储桶中的内容，以便用户可以通过 CloudFront 访问内容，但无法使用 Amazon S3 URL 直接访问内容。这可防止其他人绕过 CloudFront 并使用 Amazon S3 URL 访问希望限制访问的内容。虽然此步骤未要求使用签名 URL，但我们建议使用。</li>
<li>签名URL或签名Cookie可以使用HTTP服务器作为源，与CloudFront一起使用。 它要求内容可公开访问，并且应注意不要共享内容的直接URL</li>
<li>源端限制可适用于<ul>
<li>对于S3，使用Origin Access Identity仅使用Bucket策略或Object ACL授予CloudFront访问权限，以及删除任何其他访问权限</li>
<li>对于HTTP服务器，可以通过CloudFront添加自定义标头，可以在Origin使用它来验证请求来自CloudFront</li>
</ul>
</li>
</ul>
<h3 id="可信签署人"><a href="#可信签署人" class="headerlink" title="可信签署人"></a>可信签署人</h3><ul>
<li>要创建签名 URL 或签名 Cookie，至少需要一个具有有效 CloudFront 密钥对的 AWS 账户。该账户被称为可信签署人。</li>
<li>只要将可信签署人的 AWS 账户 ID 添加到分配中，CloudFront 就会立即开始要求用户使用签名 URL 或签名 Cookie 访问文件</li>
<li>创建签名 URL 或签名 Cookie 时，使用可信签署人的私有密钥来签署 URL 或 Cookie 的一部分。当某人请求限制的文件时，CloudFront 会比较 URL 或 Cookie 的已签名部分与未签名部分，以确认 URL 或 Cookie 未被篡改。CloudFront 还会验证 URL 或 Cookie 是否有效，例如是否未超过过期日期和时间</li>
<li>指定可信签署人时，还会间接指定要求签名 URL 或签名 Cookie 的文件：<ul>
<li>Web 分配 – 将可信签署人添加到缓存行为中。如果分配只有一个缓存行为，用户则必须使用签名 URL 或签名 Cookie 访问与该分配关联的任何文件。如果创建了多个缓存行为，并将可信签署人添加到某些缓存行为中而没有添加到其他缓存行为中，则可要求用户使用签名 URL 或签名 Cookie 访问某些文件而不是其他文件。</li>
<li>RTMP 分配（仅签名 URL） – 将可信签署人添加到分配中。在将可信签署人添加到 RTMP 分配后，用户必须使用签名 URL 访问与该分配相关联的任何文件。</li>
</ul>
</li>
<li>用于创建CloudFront签名URL或签名cookie的每个可信签署者AWS账户必须拥有自己的活动CloudFront密钥对，应该经常轮换</li>
<li>每个缓存行为或RTMP分配最多可以分配5个可信签名者</li>
</ul>
<h3 id="签名URL-vs-签名cookie"><a href="#签名URL-vs-签名cookie" class="headerlink" title="签名URL vs 签名cookie"></a>签名URL vs 签名cookie</h3><ul>
<li>在以下情况下使用签名 URL：<ul>
<li>希望使用 RTMP 分配。RTMP 分配不支持签名 Cookie。</li>
<li>希望限制对单个文件的访问，例如应用程序的安装程序下载。</li>
<li>用户使用不支持 Cookie 的客户端 (例如，自定义 HTTP 客户端)。</li>
</ul>
</li>
<li>在以下情况下使用签名 Cookie：<ul>
<li>希望提供对多个限制文件的访问，例如，HLS 格式视频的所有文件或者网站订户区域中的所有文件。</li>
<li>不希望更改当前 URL。</li>
</ul>
</li>
</ul>
<h3 id="标准策略-vs-自定义策略"><a href="#标准策略-vs-自定义策略" class="headerlink" title="标准策略 vs 自定义策略"></a>标准策略 vs 自定义策略</h3><ul>
<li>创建签名 URL 时，需要编写 JSON 格式的策略声明，以指定对签名 URL 的限制，例如，URL 的有效期。可以使用标准策略或自定义策略。以下是标准策略和自定义策略的比较</li>
</ul>
<table>
<thead>
<tr>
<th>描述</th>
<th>标准策略</th>
<th>自定义策略</th>
</tr>
</thead>
<tbody><tr>
<td>可对多个文件重复使用策略声明。要重复使用策略声明，必须在 Resource 对象中使用通配符。有关更多信息，请参阅 在使用自定义策略的签名 URL 的策略声明中指定的值。)</td>
<td>否</td>
<td>是</td>
</tr>
<tr>
<td>可指定用户开始访问内容的日期和时间。</td>
<td>否</td>
<td>是（可选）</td>
</tr>
<tr>
<td>可指定用户无法再访问内容的日期和时间。</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>可指定能够访问内容的用户的 IP 地址或 IP 地址范围。</td>
<td>否</td>
<td>是（可选）</td>
</tr>
<tr>
<td>签名 URL 包括策略的 Base64 编码版本，这会导致更长的 URL。</td>
<td>否</td>
<td>是</td>
</tr>
</tbody></table>
<ul>
<li>CloudFront 何时检查签名 URL 中的过期日期和时间来确定该 URL 是否仍有效，取决于该 URL 是用于 Web 分配还是用于 RTMP 分配<ul>
<li>Web 分配 – 在发出 HTTP 请求时，CloudFront 检查签名 URL 中的过期日期和时间。如果客户端刚好在过期时间之前开始下载大型文件，即使在下载过程中到了过期时间，该下载也应该完成。如果客户端使用 Range GET 来获取较小的文件，在过期时间到期后发生的任何 GET 请求将会失败。</li>
<li>RTMP分配 - 播放事件开始时，CloudFront 检查签名 URL 中的过期时间。如果客户端在过期时间到期之前开始播放媒体文件，CloudFront 将允许播放整个媒体文件。然而，根据媒体播放器，暂停和重新开始可能触发另一个播放事件。跳到媒体文件中另一个位置将触发另一个播放事件。如果在过期时间到期后发生播放事件，CloudFront 不会提供媒体文件。</li>
</ul>
</li>
</ul>
<h3 id="提供压缩"><a href="#提供压缩" class="headerlink" title="提供压缩"></a>提供压缩</h3><ul>
<li>将 CloudFront 配置为在查看器请求的请求标头中包含 Accept-Encoding: gzip 时自动压缩某些类型的文件，并提供压缩文件</li>
<li>在压缩内容时，由于文件更小，因此下载速度更快，在某些情况下，大小不到原件的四分之一。—特别是对于 JavaScript 和 CSS 文件，更快的下载转化为向用户更快地提供网页。</li>
<li>查看器请求必须在请求标头中包含 Accept-Encoding: gzip，否则，CloudFront 不会压缩请求的文件</li>
<li>如果使用自定义或 Amazon S3 源，可以将源配置为使用或不使用 CloudFront 压缩功能压缩文件。源可以压缩 CloudFront 无法压缩的文件类型。</li>
<li>如果源向 CloudFront 返回压缩文件，CloudFront 将根据 Content-Encoding 标头值检测到已压缩该文件，而不会再次压缩该文件。</li>
<li>使用 CloudFront 压缩内容<ol>
<li>创建或更新 CloudFront 分配，并配置 CloudFront 以压缩内容。</li>
<li>查看器请求文件。查看器将 Accept-Encoding: gzip 标头添加到请求中。这表示查看器支持压缩的内容。</li>
<li>在边缘站点，CloudFront 将在缓存中检查请求中引用的文件的压缩版本。</li>
<li>如果压缩的文件已在缓存中，则 CloudFront 将文件返回到查看器并跳过剩余步骤。</li>
<li>如果压缩文件没有位于缓存中，则 CloudFront 将请求转发到源服务器，它可以是 Amazon S3 存储桶或自定义源。</li>
<li>源服务器将请求文件的未压缩版本返回到 CloudFront。</li>
<li>CloudFront 确定文件是否可压缩：<ul>
<li>文件必须是 CloudFront 可压缩的类型。</li>
<li>文件大小必须介于 1000 和 10000000 字节之间。</li>
<li>响应必须包含 Content-Length 标头，以便 CloudFront 可以确定文件大小是否在 CloudFront 压缩的范围内。如果缺少    </li>
<li>Content-Length 标头，则 CloudFront 不会压缩文件。</li>
<li>该响应不得包含 Content-Encoding 标头。</li>
</ul>
<ol start="8">
<li>如果文件是可压缩的，则 CloudFront 将压缩文件，将压缩后的文件返回到查看器并将它添加到缓存中。</li>
<li>查看器将解压缩文件。</li>
</ol>
</li>
</ol>
</li>
</ul>
<h2 id="Distribution-Details"><a href="#Distribution-Details" class="headerlink" title="Distribution Details"></a>Distribution Details</h2><h3 id="替代域名（CNAME）"><a href="#替代域名（CNAME）" class="headerlink" title="替代域名（CNAME）"></a>替代域名（CNAME）</h3><ul>
<li>默认情况下，CloudFront为分发分配域名，例如d111111abcdef8.cloudfront.net</li>
<li>备用域名（也称为CNAME）可用于将自己的自定义域名用于指向对象的链接</li>
<li>Web和RTMP分发都支持备用域名。</li>
<li>CloudFront在域名开头支持*通配符，而不是单独指定子域。</li>
<li>但是，通配符不能替换部分子域名，例如， * domain.example.com，或者不能替换域名中间的子域名，例如子域.*.example.com</li>
</ul>
<h3 id="限制内容的地理分配"><a href="#限制内容的地理分配" class="headerlink" title="限制内容的地理分配"></a>限制内容的地理分配</h3><ul>
<li>当用户请求内容时，CloudFront 通常会提供请求的内容，而不考虑用户所在的位置。如果需要阻止特定国家/地区的用户访问内容，可以使用 CloudFront 地理限制功能来执行下列操作之一：<ul>
<li>仅当用户位于批准的国家/地区白名单中的某个国家/地区时，才允许他们访问内容。</li>
<li>当用户位于阻止的国家/地区黑名单中的某个国家/地区时，阻止他们访问内容。<blockquote>
<p>CloudFront 使用第三方 GeoIP 数据库确定用户的位置。IP 地址和国家/地区之间映射的准确性因区域而异。根据最近的测试，整体准确性为 99.8%。请注意，如果 CloudFront 无法确定用户的位置，CloudFront 将提供用户请求的内容。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="CloudFront与Amazon-S3"><a href="#CloudFront与Amazon-S3" class="headerlink" title="CloudFront与Amazon S3"></a>CloudFront与Amazon S3</h3><ul>
<li>CloudFront可用于分发S3存储桶中的内容</li>
<li>对于RTMP分发，S3存储区是唯一受支持的源，并且不能使用自定义源</li>
<li>在S3上使用CloudFront具有以下优势<ul>
<li>如果在更高的使用频率下频繁访问对象，则可以更具成本效益，CloudFront数据传输的价格远低于S3数据传输的价格。</li>
<li>CloudFront的下载速度比单独使用S3更快，因为对象存储的距离更接近用户</li>
<li>当使用S3作为分发的原点并将存储桶移动到其他区域时，如果满足以下两个条件，则CloudFront最多可能需要一个小时来更新其记录以包括区域更改：<ul>
<li>源访问标识（OAI）用于限制对存储桶的访问</li>
<li>存储桶被移动到需要签名版本4进行身份验证的S3区域</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="源站访问识别"><a href="#源站访问识别" class="headerlink" title="源站访问识别"></a>源站访问识别</h3><ul>
<li>以S3为源站，S3中的对象必须被授予公共读取权限，因此可以从S3和CloudFront访问对象</li>
<li>尽管CloudFront不公开底层S3 URL，但如果直接共享或由应用程序使用，则可以为用户所知</li>
<li>要使用CloudFront签名URL或签名cookie来提供对对象的访问，有必要阻止用户直接访问S3对象</li>
<li>直接访问S3对象会导致 <ul>
<li>绕过CloudFront签名URL或签名cookie提供的控制，例如，控制用户无法再访问内容的日期时间，并且IP地址可用于访问内容</li>
<li>CloudFront访问日志不太有用，因为它们不完整。</li>
</ul>
</li>
<li>源访问标识（OAI）可用于防止用户直接从S3访问对象</li>
<li>可以创建原始访问标识（一种特殊的CloudFront用户）并将其与分发相关联。</li>
<li>需要将S3存储桶/对象权限配置为仅提供对源访问标识的访问</li>
<li>当用户从CloudFront访问该对象时，它使用OAI代表用户获取内容，同时限制对S3对象的直接访问</li>
</ul>
<h3 id="使用对象"><a href="#使用对象" class="headerlink" title="使用对象"></a>使用对象</h3><ul>
<li>CloudFront可以配置为包括自定义标头或修改现有标头，只要它将请求转发到源</li>
<li>验证用户没有直接访问源，绕过CDN</li>
<li>如果用户使用不支持CORS的查看器，请配置CloudFront以将Origin标头转发到源。 这将导致origin为每个请求返回Access-Control-Allow-Origin标头</li>
</ul>
<h3 id="添加和更新对象"><a href="#添加和更新对象" class="headerlink" title="添加和更新对象"></a>添加和更新对象</h3><ul>
<li>只需要将对象添加爱到Origin，CloudFront将在访问时开发分发他们</li>
<li>通过以下方式更新<ul>
<li>覆盖原始对象</li>
<li>创建不同的版本并更新向用户公开的链接</li>
</ul>
</li>
<li>为了更新对象，建议使用版本控制，例如拥有文件或带有版本的整个文件夹，因此在更新对象时强制刷新可以更改链接</li>
<li>版本控制<ul>
<li>在CloudFront开始提供新版本之前，没有时间等待对象过期</li>
<li>从边缘提供的对象的一致性没有差异</li>
<li>支付对象失效不涉及任何费用。</li>
</ul>
</li>
</ul>
<h3 id="删除-使对象无效"><a href="#删除-使对象无效" class="headerlink" title="删除/使对象无效"></a>删除/使对象无效</h3><ul>
<li>默认情况下，对象将在到期时被删除（TTL），并且最新的对象将从Origin获取</li>
<li>对象也可以在到期之前从边缘缓存中删除<ul>
<li>更改对象名称（版本控制）已提供具有不同名称的对象的不同版本</li>
<li>在边缘缓存中使对象失效，对于下一个请求，cloudfront返回到Origin以获取对象</li>
</ul>
</li>
<li>Web分发<ul>
<li>如果需要频繁更新对象，则建议更改对象名称（版本控制），而不是像对象那样更改对象<ul>
<li>即使用户在本地或在缓存代理后面缓存了版本，也可以控制请求返回的对象。如果对象无效，则用户可能会继续查看旧版本，直到它们从这些缓存过期。</li>
<li>由于CloudFront访问日志包含对象的名称，因此可以更轻松地分析对象更改的结果</li>
<li>提供了向不同用户提供不同版本的方法。</li>
<li>简化了对象修订之间的前滚和后退。</li>
<li>更便宜，因为没有收取使对象无效的费用。</li>
<li>例如将header-v1.jpg更改为header-v2.jpg</li>
</ul>
</li>
<li>使缓存中的对象失效<ul>
<li>缓存中的对象可以在它们到期之前显式无效以强制刷新</li>
<li>允许使所选对象无效</li>
<li>允许使多个对象无效，例如如果目录中的对象或名称以相同字符开头的所有对象，则可以在失效路径的末尾包含*通配符</li>
<li>无效路径可以用于例如单个对象。 /js/ab.js或多个对象，例如： / js / <em>并且即使</em>通配符请求可能使数千个对象无效，也会被计为单个请求</li>
</ul>
</li>
</ul>
</li>
<li>对于RTMP分发，对象不能无效</li>
</ul>
<h3 id="Range-GETS"><a href="#Range-GETS" class="headerlink" title="Range GETS"></a>Range GETS</h3><ul>
<li>在GET请求中使用Range标头的部分请求有助于以较小的单位下载对象，从而提高部分下载的效率和部分失败的传输的恢复。</li>
<li>对于partial get 请求，cloudfront <ul>
<li>检查边缘位置中的缓存是否包含请求的范围或整个对象，如果存在，则立即提供</li>
<li>如果请求的范围不存在，它会将请求转发到源，并且可能请求比客户端请求更大的范围以优化性能</li>
<li>如果origin支持范围标头，则返回请求的对象范围，CloudFront将其返回给查看器</li>
<li>如果原点不支持范围标题，则返回完整对象，CloudFront将为整个对象提供服务并将其缓存以备将来使用。</li>
<li>CloudFront使用缓存的整个对象来提供任何未来范围的GET标头请求</li>
</ul>
</li>
</ul>
<h2 id="访问日志"><a href="#访问日志" class="headerlink" title="访问日志"></a>访问日志</h2><ul>
<li>可以将CloudFront配置为创建包含有关CloudFront接收的每个用户请求的详细信息的日志文件</li>
<li>可用于Web和RTMP分发</li>
<li>启用日志记录后，可以指定一个S3存储桶，CloudFront将保存文件</li>
<li>CloudFront定期为分发提供访问日志，最多可达一小时几次</li>
<li>CloudFront通常会在日志中显示的事件的一小时内将该时间段的日志文件传递到S3存储桶。 但请注意，某段时间内的某些或所有日志文件条目有时可能会延迟最多24小时</li>
</ul>
<h2 id="CloudFront-费用"><a href="#CloudFront-费用" class="headerlink" title="CloudFront 费用"></a>CloudFront 费用</h2><ol>
<li>数据传输到Internet<ul>
<li>对于从CloudFront边缘位置传输的数据量，将收取费用，以GB为单位</li>
<li>不再收取从AWS源（例如，S3，EC2等）到CloudFront的数据传输。</li>
<li>适用于从所有AWS区域到所有全球CloudFront边缘位置的数据传输</li>
</ul>
</li>
<li>HTTP/HTTPS 请求<ul>
<li>为内容进行的HTTP / HTTPS请求数</li>
</ul>
</li>
<li>失效请求<ul>
<li>无效请求中的每个路径</li>
<li>失效请求中列出的路径表示要从CloudFront缓存中失效的对象的URL（如果路径包含通配符，则为多个URL）</li>
</ul>
</li>
<li>与Cloudfront分配相关联的专用IP 自定义SSL证书</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">seven</p>
              <p class="site-description motion-element" itemprop="description">seven 的精神家园，学习笔记</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="1988xuegang@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">seven</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




<!-- 新增访客统计代码 -->

<div class="busuanzi-count">
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="site-uv">
      <i class="fa fa-user"></i>
      访问用户： <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 人
    </span>
    <div class="powered-by"></div>
    <span class="site-uv">
      <i class="fa fa-eye"></i>
      访问次数： <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次
    </span>
    <!-- 博客字数统计 -->
    <span class="site-pv">
      <i class="fa fa-pencil"></i>
      博客全站共： <span class="post-count"></span> 字
    </span>
</div>
<!-- 新增访客统计代码 END-->


<!-- 在网页底部添加网站运行时间 -->
<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("07/21/2018 00:00:00");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "Run for "+dnum+" Days ";
        document.getElementById("times").innerHTML = hnum + " Hours " + mnum + " m " + snum + " s";
    }
setInterval("createtime()",250);
</script>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
