<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="seven 的精神家园，学习笔记">
<meta name="keywords" content="云计算,大数据，kuberntes">
<meta property="og:type" content="website">
<meta property="og:title" content="岳阳北寒">
<meta property="og:url" content="http://sevengarden.club/index.html">
<meta property="og:site_name" content="岳阳北寒">
<meta property="og:description" content="seven 的精神家园，学习笔记">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="岳阳北寒">
<meta name="twitter:description" content="seven 的精神家园，学习笔记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://sevengarden.club/">





  <title>岳阳北寒</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">岳阳北寒</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">要有最朴素的生活和最遥远的梦想，即使明日天寒地冻，路远马亡.......</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-somrthing">
          <a href="/有料" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            somrthing
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/08/12/Kubernetes-架构/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/12/Kubernetes-架构/" itemprop="url">Kubernetes 架构</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-12T18:51:51+08:00">
                2019-08-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/K8S/" itemprop="url" rel="index">
                    <span itemprop="name">K8S</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Kubernetes-架构"><a href="#Kubernetes-架构" class="headerlink" title="Kubernetes 架构"></a>Kubernetes 架构</h1><p> Kubernetes借鉴了Brog的设计理念，比如Pod、Service、Lables和单Pod单IP等。整体架构如下所示</p>
<p><img src="https://i.loli.net/2019/08/12/Wcv4PLCFgJ26imV.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6lf7UjRFyBsrhpw_components.png"></p>
<ul>
<li><p>etcd保存了集群的状态信息</p>
</li>
<li><p>kube-apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现机制</p>
</li>
<li><p>kube-controller-manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等</p>
</li>
<li><p>kube-scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上</p>
</li>
<li><p>kubelet 负责维持容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理</p>
</li>
<li><p>Container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI），默认的容器运行时为 Docker；</p>
</li>
<li><p>kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡</p>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/12/WyA6Jpo52BINwm8.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6ljrf3pM1bbtQ_0_core-packages.png"></p>
<p>除了核心组件，还有一些推荐的 Add-ons：</p>
<ul>
<li><p>kube-dns 负责为整个集群提供 DNS 服务</p>
</li>
<li><p>Ingress Controller 为服务提供外网入口</p>
</li>
<li><p>Heapster 提供资源监控</p>
</li>
<li><p>Dashboard 提供 GUI</p>
</li>
<li><p>Federation 提供跨可用区的集群</p>
</li>
<li><p>Fluentd-elasticsearch 提供集群日志采集、存储与查询</p>
</li>
</ul>
<h2 id="分层架构"><a href="#分层架构" class="headerlink" title="分层架构"></a>分层架构</h2><p><img src="https://i.loli.net/2019/08/12/xEBCcQ1YHAhqgP3.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6lnG-e8vfXmSbwl_core-ecosystem.png"></p>
<ul>
<li>核心层：Kubernetes 最核心的功能，对外提供 API 构建高层的应用，对内提供插件式应用执行环境</li>
<li>应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS 解析等）</li>
<li>管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态 Provision 等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy 等）</li>
<li>接口层：kubectl 命令行工具、客户端 SDK 以及集群联邦</li>
<li>生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴<ul>
<li>Kubernetes 外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS 应用、ChatOps 等</li>
<li>Kubernetes 内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等</li>
</ul>
</li>
</ul>
<h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><p><img src="https://i.loli.net/2019/08/12/vmC7XRnEJpOoHzb.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6llZfuE65sGzUkc_core-apis.png"></p>
<h2 id="核心API"><a href="#核心API" class="headerlink" title="核心API"></a>核心API</h2><p><img src="https://i.loli.net/2019/08/12/BXUHhx5ofuyJsL2.jpg" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6lhezSJ3ufUcmlH_14937095836427.jpg"></p>
<h2 id="生态系统"><a href="#生态系统" class="headerlink" title="生态系统"></a>生态系统</h2><p><img src="https://i.loli.net/2019/08/12/PO76KHBXYpUveaW.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6ldNQWZNfl3OJ9M_architecture.png"></p>
<h1 id="设计理念"><a href="#设计理念" class="headerlink" title="设计理念"></a>设计理念</h1><h2 id="API设计原则"><a href="#API设计原则" class="headerlink" title="API设计原则"></a>API设计原则</h2><ol>
<li><p>所有API都是声明式</p>
</li>
<li><p>API对象比西湖不而且可组合</p>
</li>
<li><p>高层API以操作意图为基础设计</p>
</li>
<li><p>底层API更具高层API的控制需要设计</p>
</li>
<li><p>尽量避免简单封装，不要有外部API无法显式知道内部隐藏的机制</p>
</li>
<li><p>API操作复杂度与对象数量成正比</p>
</li>
<li><p>API对象状态不能依赖于网络连接状态</p>
</li>
<li><p>尽量避免让操作机制依赖于全局状态，分布式系统中要保证全局状态的同步是非常困难的</p>
<h2 id="控制设计原则"><a href="#控制设计原则" class="headerlink" title="控制设计原则"></a>控制设计原则</h2></li>
</ol>
<ul>
<li>控制逻辑只依赖于当前状态</li>
<li>假设任何错误的可能，并做容错助理</li>
<li>尽量避免复杂状态机制，控制逻辑不要依赖无法监控的内部状态</li>
<li>假设任何操作都可能被任何操作对象拒绝，甚至错误解析</li>
<li>每个模块都可以在出错之后自动恢复</li>
<li>每个模块都可以在必要时优雅地降级服务<h2 id="架构设计原则"><a href="#架构设计原则" class="headerlink" title="架构设计原则"></a>架构设计原则</h2></li>
<li>只有apiserver可以直接访问etcd存储，其他服务必须通过KubernetesAPI来访问集群状态</li>
<li>单点故障不影响集群状态</li>
<li>在没有新请求的情况下，所有组件应该在故障恢复后继续执行上次最后收到的请求（比如网络分区或服务重启等）</li>
<li>所有组件都应该在内存中保持所需要的状态，apiserver将状态写入etcd存储，而其他组件则通过apiserver更新并监听所有的变化</li>
<li>优先使用事件监听而不是轮询<h1 id="核心技术概念和API对象"><a href="#核心技术概念和API对象" class="headerlink" title="核心技术概念和API对象"></a>核心技术概念和API对象</h1></li>
</ul>
<p>API对象是K8s集群中的管理操作单元。K8s集群系统每支持一项新功能，引入一项新技术，一定会新引入对应的API对象，支持对该功能的管理操作。例如副本集Replica Set对应的API对象是RS。</p>
<p>每个API对象都有3大类属性：<font color="red"><strong>元数据metadata、规范spec和状态status</strong></font>。元数据是用来标识API对象的，每个对象都至少有3个元数据：namespace，name和uid；除此以外还有各种各样的标签labels用来标识和匹配不同的对象，例如用户可以用标签env来标识区分不同的服务部署环境，分别用env=dev、env=testing、env=production来标识开发、测试、生产的不同服务。规范描述了用户期望K8s集群中的分布式系统达到的理想状态（Desired State），例如用户可以通过复制控制器Replication Controller设置期望的Pod副本数为3；status描述了系统实际当前达到的状态（Status），例如系统当前实际的Pod副本数为2；那么复本控制器当前的程序逻辑就是自动启动新的Pod，争取达到副本数为3。</p>
<p>K8s中所有的配置都是通过API对象的spec去设置的，也就是用户通过配置系统的理想状态来改变系统，这是k8s重要设计理念之一，即所有的操作都是声明式（Declarative）的而不是命令式（Imperative）的。声明式操作在分布式系统中的好处是稳定，不怕丢操作或运行多次，例如设置副本数为3的操作运行多次也还是一个结果，而给副本数加1的操作就不是声明式的，运行多次结果就错了。</p>
<h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2><ul>
<li>Master是集群控制节点，每个K8S集群里需要Master负责整个集群的管理和控制，K8S所有控制命令都是发给它，由其负责具体执行和调度。</li>
<li>Master上运行的关键进程<ul>
<li>Kubernetes API Server（Kube-apiserver）,提供哦你了HTTP Rest接口的关键服务进程，是K8S里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程</li>
<li>Kubernetes Controller Manager（kube-controller-manager）,K8S里所有资源对象的自动化控制中心，资源对象的“大总管”</li>
<li>Kubernetes Scheduler（kube-scheduler）,负责资源调度（Pod调度）的进程，相当于“调度室；</li>
<li>etcd Server进程，K8S集群资源对象的数据全部保存在etcd中<h2 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h2></li>
</ul>
</li>
<li>Node节点是K8S集群中工作负载节点，每个Node都会被Master分配相应的工作负载</li>
<li>Node节点上运行的关键进程<ul>
<li>kubelet:负责Pod对应的容器创建、启停等任务，同时与Master节点密切协作，实现集群管理的基本功能</li>
<li>kube-proxy:实现K8S Service的通信与负载均衡机制的重要组件</li>
<li>Docker Engine: Docker引擎，负责容器的创建和管理工作<h2 id="POD"><a href="#POD" class="headerlink" title="POD"></a>POD</h2></li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/12/3TdApJyxroRDPg9.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_rqip-tinVoiFZE0I_-LM_sIwx4E3-69Ml-jNW_pod.png"></p>
<ul>
<li>Pod是在K8s集群中运行部署应用或服务的最小单元，它是可以支持多容器的。Pod的设计理念是支持多个容器在一个Pod中共享网络地址和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。Pod对多容器的支持是K8s最基础的设计理念。</li>
<li>Pod是K8s集群中所有业务类型的基础，可以看作运行在K8s集群中的小机器人，不同类型的业务就需要不同类型的小机器人去执行。</li>
<li>目前K8s中的业务主要可以分为长期伺服型（long-running）、批处理型（batch）、节点后台支撑型（node-daemon）和有状态应用型（stateful application）；分别对应的小机器人控制器为Deployment、Job、DaemonSet和StatefulSet。<h2 id="Replication-controller（RC）"><a href="#Replication-controller（RC）" class="headerlink" title="Replication controller（RC）"></a>Replication controller（RC）</h2></li>
<li>RC是K8S系统中核心概念之一，定义了一个期望的场景，即生命某种Pod的副本数量在任意时刻都符合某个预期值。通过监控运行中的Pod来保证集群中运行指定数目的Pod副本。</li>
<li>RC的都能够以包括如下<ul>
<li>Pod期待的副本数（replicas）</li>
<li>用于筛选目标Pod的Label Selector</li>
<li>当Pod的副本书两小于预期数量的时候，用于创建新Pod的Pod模板（template）</li>
</ul>
</li>
<li>RC是K8s较早期的技术概念，<font color="green"><strong>只适用于长期伺服型的业务类型</strong></font>，比如控制小机器人提供高可用的Web服务。<h2 id="Replica-Set（RS）"><a href="#Replica-Set（RS）" class="headerlink" title="Replica Set（RS）"></a>Replica Set（RS）</h2></li>
<li>RS 是新一代RC，提供同样的高可用能力，能够支持更多种类的匹配模式。RS对象一般不单独使用，而是作为Deployment的理想状态参数使用。<h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2></li>
<li>解决Pod的编排问题</li>
<li>部署是一个比RS应用模式更广的API对象，可以是创建一个服务，更新一个服务，或者滚动升级一个服务（滚动升级实际是创建新的RS，然后逐渐在新的RS中副本增加到理想状态，然后逐步将旧的RS中的副本减少到0）</li>
</ul>
<h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><p> <img src="https://i.loli.net/2019/08/12/wlO8dfNvkq3r9sy.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_rqip-tinVoiFZE0I_-LM_sIx5Qc9S275Z49_6_14731220608865.png"></p>
<ul>
<li>RC、RS和Deployment只是保证了支撑服务的微服务Pod的数量，但是没有解决如何访问这些服务的问题。一个Pod只是一个运行服务的实例，随时可能在一个节点上停止，在另一个节点以一个新的IP启动一个新的Pod，因此不能以确定的IP和端口号提供服务。</li>
<li>要稳定地提供服务需要服务发现和负载均衡能力。服务发现完成的工作，是针对客户端访问的服务，找到对应的后端服务实例。在K8S集群中，客户端需要访问的服务就是Service对象。</li>
<li><strong>每个Service会对应一个集群内部有效的虚拟IP，集群内部通过虚拟IP访问一个服务</strong></li>
<li>*<em>在K8S集中微服务的负载均衡是由Kube-proxy实现的 *</em></li>
<li>Kube-proxy是K8s集群内部的负载均衡器。它是一个分布式代理服务器，在K8s的每个节点上都有一个；这一设计体现了它的伸缩性优势，需要访问服务的节点越多，提供负载均衡能力的Kube-proxy就越多，高可用节点也随之增多<h2 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h2></li>
<li>Job是K8s用来控制批处理型任务的API对象。批处理业务与长期伺服业务的主要区别是批处理业务的运行有头有尾，而长期伺服业务在用户不停止的情况下永远运行。Job管理的Pod根据用户的设置把任务成功完成就自动退出了。成功完成的标志根据不同的spec.completions策略而不同：单Pod型任务有一个Pod成功就标志完成；定数成功型任务保证有N个任务全部成功；工作队列型任务根据应用确认的全局成功而标志成功。<h2 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h2></li>
<li>后台支撑型服务的核心关注点在K8s集群中的节点（物理机或虚拟机），要保证每个节点上都有一个此类Pod运行。节点可能是所有集群节点也可能是通过nodeSelector选定的一些特定节点。</li>
<li>典型的后台支撑型服务包括，存储，日志和监控等在每个节点上支撑K8s集群运行的服务<h2 id="StatefulSett"><a href="#StatefulSett" class="headerlink" title="StatefulSett"></a>StatefulSett</h2></li>
<li>RC和RS主要是控制提供无状态服务的，其所控制的Pod的名字是随机设置的，一个Pod出故障了就被丢弃掉，在另一个地方重启一个新的Pod，名字变了、名字和启动在哪儿都不重要，重要的只是Pod总数。</li>
<li>StatefulSet是用来控制有状态服务，StatefulSet中的每个Pod的名字都是事先确定的，不能更改</li>
<li>对于RC和RS中的Pod，一般不挂载存储或者挂载共享存储，保存的是所有Pod共享的状态，Pod像牲畜一样没有分别（这似乎也确实意味着失去了人性特征）</li>
<li>对于StatefulSet中的Pod，每个Pod挂载自己独立的存储，如果一个Pod出现故障，从其他节点启动一个同样名字的Pod，要挂载上原来Pod的存储继续以它的状态提供服务</li>
<li>适合于StatefulSet的业务包括数据库服务MySQL和PostgreSQL，集群化管理服务Zookeeper、etcd等有状态服务</li>
</ul>
<h2 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h2><ul>
<li>Pod中能够被多个容器访问的共享目录，与Pod生命周期相同，与容器生命周期不相关</li>
<li>类型：<ol>
<li>emptyDir ：初始内容为空，无需指定宿主机上对应目录文件，临时空间</li>
<li>hostpath ：Pod上挂载宿主机上的文件或目录</li>
<li>gcePersistentDisk:Pod上的内容会被永久保存，即使Pod删除（node节点在GCE环境）</li>
<li>awsElasticBlockStore:同上，AWS云环境</li>
<li>NFS</li>
<li>其他类型：iscsi、glusterfs、rbd、gitRepo、flocker、secret(加密)</li>
</ol>
</li>
</ul>
<h2 id="Persistent-Volume"><a href="#Persistent-Volume" class="headerlink" title="Persistent Volume"></a>Persistent Volume</h2><ul>
<li>PV只能是网络存储，不属于任何Node，但可以在每个Node上访问</li>
<li>PV并不定义在Pod上，而是独立于Pod之外定义</li>
<li>PV目前只有几种类型：GCE Persistent Disks、NFS、RBD、iSCSI、AWSEBS、GlusterFS等</li>
</ul>
<h2 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h2><ul>
<li>集群内部的资源对象”分配“到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源同时还能被分别管理</li>
</ul>
<h2 id="Label（标签）"><a href="#Label（标签）" class="headerlink" title="Label（标签）"></a>Label（标签）</h2><ul>
<li>Label是一个Key=value的键值对，key和value由用户自己定义。Label可以附加到各种资源对象上，例如Node、Pod、Service、RS等，一个资源对象可以定义任意数量的Label，同一label也可以被添加到任意数量的资源对象上，label可以在定义资源对象是创建，也可以创建后动态添加或删除</li>
<li>通过LabelSelector(标签选择器)查询和筛选，K8S通过这种方式实现类似SQL的简单又通用的对象查询机制</li>
</ul>
<h2 id="Horizontal-Pod-Autoscaler（HPA）"><a href="#Horizontal-Pod-Autoscaler（HPA）" class="headerlink" title="Horizontal Pod Autoscaler（HPA）"></a>Horizontal Pod Autoscaler（HPA）</h2><ul>
<li>Pod横向自动扩容，通过追踪分析RS控制的所有目标Pod的负载变化情况，确定是否需要针对性调整目标Pod的副本数</li>
<li>度量指标<ul>
<li>CPUUtilizationPercentage （需要部署安装Heapster）</li>
<li>应用程序自定义的度量指标，比如服务在每秒内的相应的请求数（TPS或QPS）</li>
</ul>
</li>
</ul>
<h2 id="RBAC访问授权"><a href="#RBAC访问授权" class="headerlink" title="RBAC访问授权"></a>RBAC访问授权</h2><ul>
<li>基于角色的访问控制（Role-based Access Control，RBAC）的授权模式</li>
</ul>
<h1 id="核心组件-1"><a href="#核心组件-1" class="headerlink" title="核心组件"></a>核心组件</h1><p> ##组件通信<br>   K8S多组件之间通信原理</p>
<p><img src="https://i.loli.net/2019/08/12/GzcCtOFyV7pnHBX.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_rqip-tinVoiFZE0I_-LM_sEq_NuMALezRGMtG_workflow.png"></p>
<ul>
<li>apiserver 负责etcd存储的所有操作，且只有apiserver才直接操作etcd集群</li>
<li>apiserver 对内（集群中的其他组件）和对外（用户）提供统一的REST API，其他组件均通过apiserver进行通信<ul>
<li>controller manager、scheduler、kube-proxy和kubelet等均通过apiserver watch API检测资源变化情况，并对资源作相应的操作</li>
<li>所有需要更新资源状态的操作均通过apiserver的REST API进行</li>
</ul>
</li>
<li>apiserver也会直接调用kubelet API（如logs,exec,attach等），默认不校验kubelet证书，看可以通过–kubelet-certificate-autprity开启开启（GKE通过SSH隧道保护他们之间通信）<br>比如典型的创建Podcast的流程为</li>
</ul>
<p><img src="https://i.loli.net/2019/08/12/eg53NY8LvBa91q7.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_rqip-tinVoiFZE0I_-LM_sEqUTx_-gUuaPyw1_components.png"></p>
<ol>
<li><p>用户通过REST API创建一个Pod </p>
</li>
<li><p>apiserver 将其写入etcd</p>
</li>
<li><p>scheduler检测到未绑定Node的Pod，开始调度并更新Pod的Node绑定</p>
</li>
<li><p>kubelet检测到有新的Podcast调度过来，通过container runtime运行该Pod</p>
</li>
<li><p>kubelet通过container runtime取到Pod状态，并更新到apiserver中</p>
<h2 id="端口号"><a href="#端口号" class="headerlink" title="端口号"></a>端口号</h2></li>
</ol>
<h3 id="Master-1"><a href="#Master-1" class="headerlink" title="Master"></a>Master</h3><table>
<thead>
<tr>
<th align="center"><strong>Protocol</strong></th>
<th align="center"><strong>Direction</strong></th>
<th align="center"><strong>PortRange</strong></th>
<th align="center"><strong>Purpose</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">6443*</td>
<td align="center">Kubernetes API server</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">8080</td>
<td align="center">Kubernetes API insecure server</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">2379-2380</td>
<td align="center">etcd server client API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10250</td>
<td align="center">Kubelet API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10251</td>
<td align="center">kube-scheduler healthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10252</td>
<td align="center">kube-controller-manager healthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10253</td>
<td align="center">cloud-controller-manager healthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10255</td>
<td align="center">Read-only Kubelet API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10256</td>
<td align="center">kube-proxy healthz</td>
</tr>
</tbody></table>
<h3 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h3><table>
<thead>
<tr>
<th align="center"><strong>Protocol</strong></th>
<th align="center"><strong>Direction</strong></th>
<th align="center"><strong>PortRange</strong></th>
<th align="center"><strong>Purpose</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">4194</td>
<td align="center">Kubelet cAdvisor</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10248</td>
<td align="center">Kubelethealthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10249</td>
<td align="center">kube-proxy metrics</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10250</td>
<td align="center">Kubelet API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10255</td>
<td align="center">Read-only Kubelet API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10256</td>
<td align="center">kube-proxy healthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">30000-32767</td>
<td align="center">NodePort Services**</td>
</tr>
</tbody></table>
<h2 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h2><p>Etcd 是 CoreOS 基于 Raft 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障（如数据库选主、分布式锁等）。</p>
<h2 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h2><p><img src="https://i.loli.net/2019/08/12/RyPTzkrf1qw5VKg.png" alt="assets_-LDAOok5ngY4pc1lEDes_-L_kZB_hPn0h_fskH43w_-L_kZGkSetdfkFl6OL6N_post-ccm-arch.png"></p>
<p>Controller Manager 由 kube-controller-manager 和 cloud-controller-manager 组成，是 Kubernetes 的大脑，它通过 apiserver 监控整个集群的状态，并确保集群处于预期的工作状态。<br>Kube-controller-manager 由一系列的控制器组成<br><img src="https://i.loli.net/2019/08/13/5GwXKSWfODuFaVt.png" alt="20170721232653797.png"></p>
<ul>
<li>Replication Controller</li>
<li>Node Controller</li>
<li>CronJob Controller</li>
<li>Daemon Controller</li>
<li>Deployment Controller</li>
<li>Endpoint Controller</li>
<li>Garbage Collector</li>
<li>Namespace Controller</li>
<li>Job Controller</li>
<li>Pod AutoScaler</li>
<li>RelicaSet</li>
<li>Service Controller</li>
<li>ServiceAccount Controller</li>
<li>StatefulSet Controller</li>
<li>Volume Controller</li>
<li>Resource quota Controller<br>cloud-controller-manager 在 Kubernetes 启用 Cloud Provider 的时候才需要，用来配合云服务提供商的控制，也包括一系列的控制器，如</li>
<li>Node Controller</li>
<li>Route Controller</li>
<li>Service Controller<h2 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h2>kube-scheduler 负责分配调度 Pod 到集群内的节点上，它监听 kube-apiserver，查询还未分配 Node 的 Pod，然后根据调度策略为这些 Pod 分配节点（更新 Pod 的 NodeName 字段）<br>调度器需要充分考虑诸多的因素：</li>
<li>公平调度</li>
<li>资源高效利用</li>
<li>QoS</li>
<li>affinity 和 anti-affinity</li>
<li>数据本地化（data locality）</li>
<li>内部负载干扰（inter-workload interference）</li>
<li>deadlines<br>有三种方式指定 Pod 只运行在指定的 Node 节点上</li>
<li>nodeSelector：只调度到匹配指定 label 的 Node 上</li>
<li>nodeAffinity：功能更丰富的 Node 选择器，比如支持集合操作</li>
<li>podAffinity：调度到满足条件的 Pod 所在的 Node 上<h2 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h2></li>
<li>提供集群管理的 REST API 接口，包括认证授权、数据校验以及集群状态变更等</li>
<li>提供其他模块之间的数据交互和通信的枢纽（其他模块通过 API Server 查询或修改数据，只有 API Server 才直接操作 etcd）<h2 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h2>每个节点上都运行一个 kubelet 服务进程，默认监听 10250 端口，接收并执行 master 发来的指令，管理 Pod 及 Pod 中的容器。每个 kubelet 进程会在 API Server 上注册节点自身信息，定期向 master 节点汇报节点的资源使用情况，并通过 cAdvisor 监控节点和容器的资源。<h3 id="节点管理"><a href="#节点管理" class="headerlink" title="节点管理"></a>节点管理</h3>节点管理主要是节点自注册和节点装填更新：<ul>
<li>Kubelet可以通过设置启动参数–register-node来确定是否向API Server注册</li>
<li>如果Kubelet没有选择自注册模式，则需要用户自己配置Node资源信息，同时需要告知Kubelet集群上的API Server的位置</li>
<li>Kubelet在启动时通过API Server注册节点信息，并定时向API Server发送节点新消息，API Server在接受到新消息后，将信息写入etcd<h3 id="Pod管理"><a href="#Pod管理" class="headerlink" title="Pod管理"></a>Pod管理</h3></li>
<li>Kubelet 以 PodSpec 的方式工作。PodSpec 是描述一个 Pod 的 YAML 或 JSON 对象。 kubelet 采用一组通过各种机制提供的 PodSpecs（主要通过 apiserver），并确保这些 PodSpecs 中描述的 Pod 正常健康运行<h3 id="Static-Pod"><a href="#Static-Pod" class="headerlink" title="Static Pod"></a>Static Pod</h3></li>
<li>静态Pod是由kubelet进行管理的仅存在于特定Node上的Pod。不能通过API Server进行管理，无法与RC、Deployment或者DaemonSet进行管理，并且kubelet无法对其进行健康检查。</li>
<li>静态Pod总是由kubelet进行创建，并且总是在kuelet所在的Node上运行</li>
<li>所有以非 API Server 方式创建的 Pod 都叫 Static Pod。Kubelet 将 Static Pod 的状态汇报给 API Server，API Server 为该 Static Pod 创建一个 Mirror Pod 和其相匹配。Mirror Pod 的状态将真实反映 Static Pod 的状态。当 Static Pod 被删除时，与之相对应的 Mirror Pod 也会被删除。</li>
<li><h3 id="容器健康检查"><a href="#容器健康检查" class="headerlink" title="容器健康检查"></a>容器健康检查</h3></li>
</ul>
</li>
</ul>
<ol>
<li>LivenessProbe 探针：用于判断容器是否健康，告诉 Kubelet 一个容器什么时候处于不健康的状态。如果 LivenessProbe 探针探测到容器不健康，则 Kubelet 将删除该容器，并根据容器的重启策略做相应的处理。如果一个容器不包含 LivenessProbe 探针，那么 Kubelet 认为该容器的 LivenessProbe 探针返回的值永远是 “Success”</li>
<li>ReadinessProbe：用于判断容器是否启动完成且准备接收请求。如果 ReadinessProbe 探针探测到失败，则 Pod 的状态将被修改。Endpoint Controller 将从 Service 的 Endpoint 中删除包含该容器所在 Pod 的 IP 地址的 Endpoint 条目。<br>livenessProbe 包含如下三种实现方式：</li>
</ol>
<ul>
<li><p>ExecAction：在容器内部执行一个命令，如果该命令的退出状态码为 0，则表明容器健康；</p>
</li>
<li><p>TCPSocketAction：通过容器的 IP 地址和端口号执行 TCP 检查，如果端口能被访问，则表明容器健康；</p>
</li>
<li><p>HTTPGetAction：通过容器的 IP 地址和端口号及路径调用 HTTP GET 方法，如果响应的状态码大于等于 200 且小于 400，则认为容器状态健康。</p>
<h3 id="cAdvisor-资源监控"><a href="#cAdvisor-资源监控" class="headerlink" title="cAdvisor 资源监控"></a>cAdvisor 资源监控</h3><p>Kubernetes集群中，应用程序的执行情况可以在不同的级别上检测到，包括：容器、Pod、Servvice和整个集群。Heapster项目为K8S提供了一个基本监控平台，它是集群级别的监控事件数据集成器（Aggregator）.Heapster以Pod的方式运行在集群中，Heapster通过Kubelet发现所有运行在集群中的节点，并查看这些节点的资源使用情况。Kubelet通过cAdvisor获取其所在节点及容器的数据。</p>
<ul>
<li>cAdvisor 是一个开源的分析容器资源使用率和性能特性的代理工具，已集成到 Kubernetes 代码中。</li>
<li>cAdvisor 自动查找所有在其所在节点上的容器，自动采集 CPU、内存、文件系统和网络使用的统计信息。</li>
<li>cAdvisor 通过它所在节点机的 Root 容器，采集并分析该节点机的全面使用情况。</li>
<li>cAdvisor 通过其所在节点机的 4194 端口暴露一个简单的 UI<h3 id="Container-Runtime"><a href="#Container-Runtime" class="headerlink" title="Container Runtime"></a>Container Runtime</h3>负责真正管理镜像和容器的生命周期。Kubelet通过Container Runtime Interface（CRI）与容器云形式交互，以管理镜像和容器。</li>
<li>拆分成Sandbox和Container的gPRC接口，并将镜像管理和容器管理分离到不同的服务</li>
</ul>
<p><img src="https://i.loli.net/2019/08/13/FDv8ZWuRi3X5SCg.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LOmrfw3UHfIY1g0xnLo_-LOmroTRjl0FBixIYL5x_cri.png"></p>
<h2 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h2></li>
</ul>
<ul>
<li>每台node上都运行一个kube-proxy服务，监听API server和endpoint的变化情况，并通过iptables等来为服务配置负载均衡（仅支持TCP和UDP）</li>
<li>kube-proxy可以直接运行在物理机上，也可以在static pod或者daemonset的方式运行</li>
<li>实现方式<ul>
<li>userspace:用户控件监听端口，所有服务通过iptables转发到这个端口，然后在其内部负载均衡到实际pod</li>
<li>iptables:完全以iptables规则的方式实现service负载均衡（服务多的时候，产生太多iptables规则）</li>
<li>ipvs：解决iptables模式性能问题，增量式更新，保证service更新期间连接不断开</li>
<li>应用层的转发机制通过services是无法实现的，需要借助Ingress将不同URL的访问请求转发到后端不同的service<h2 id="kube-dns"><a href="#kube-dns" class="headerlink" title="kube-dns"></a>kube-dns</h2></li>
</ul>
</li>
<li>目前推荐CoreDNS替代kube-dns(skydns)</li>
<li>DNS 格式<ul>
<li>Service <ul>
<li>A record (cluster IP 或Pod IP列表)</li>
<li>SRV record</li>
</ul>
</li>
<li>Pod<ul>
<li>A record:</li>
<li>指定hostname和subdomain</li>
</ul>
</li>
</ul>
</li>
<li>工作原理<ul>
<li>kube-dns：DNS 服务的核心组件，主要由 KubeDNS 和 SkyDNS 组成<ul>
<li>KubeDNS 负责监听 Service 和 Endpoint 的变化情况，并将相关的信息更新到 SkyDNS 中</li>
<li>SkyDNS 负责 DNS 解析，监听在 10053 端口 (tcp/udp)，同时也监听在 10055 端口提供 metrics</li>
<li>kube-dns 还监听了 8081 端口，以供健康检查使用</li>
</ul>
</li>
<li>dnsmasq-nanny：负责启动 dnsmasq，并在配置发生变化时重启 dnsmasq<ul>
<li>dnsmasq 的 upstream 为 SkyDNS，即集群内部的 DNS 解析由 SkyDNS 负责</li>
</ul>
</li>
<li>sidecar：负责健康检查和提供 DNS metrics（监听在 10054 端口）</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/13/kV82oOjNUX6dQzC.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_tX5rWaCuzsx7xEcz_-LM_t_Oxw2Twn_BSf7GQ_kube-dns.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/08/11/AWS-Direct-Connect-Overview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/11/AWS-Direct-Connect-Overview/" itemprop="url">AWS Direct Connect Overview</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-11T13:45:05+08:00">
                2019-08-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS/" itemprop="url" rel="index">
                    <span itemprop="name">AWS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Direct-Connect-Overview"><a href="#Direct-Connect-Overview" class="headerlink" title="Direct Connect Overview"></a>Direct Connect Overview</h2><ul>
<li>AWS Direct Connect是一种网络服务，它是一种替代Internet来利用AWS云服务的一种方案</li>
<li>通过标准的以太网光纤电缆将内部网络链接到 AWS Direct Connect 位置。电缆的一端接到用户侧路由器，另一端接到 AWS Direct Connect 路由器</li>
<li>可以使用1Gbps和10Gbps端口建立直接连接。可以从任何支持AWS Direct Connect的APN合作伙伴订购50Mbps，100Mbps，200Mbps，300Mbps，400Mbps和500Mbps的速度</li>
<li>有了此连接以后，可以创建直接连接到公共 AWS 服务（如 Amazon S3）或 Amazon VPC 的虚拟接口，从而绕过网络路径中的 Internet 服务提供商</li>
<li>AWS Direct Connect位置提供对与其关联的区域中的Amazon Web Services的访问，以及对其他美国区域的访问（如果是美国地区的Direct Connect）。例如，可以为美国的任何AWS Direct Connect位置配置单个连接，并使用它来访问所有美国区域和AWS GovCloud（美国）中的公共AWS服务。</li>
<li>每个AWS Direct Connect位置都可以连接到地理位置最近的AWS区域内的所有可用区</li>
<li>公有区域或AWS GovCloud (US)中的 AWS Direct Connect 位置可以访问任何其他公有区域（不包括中国(北京和宁夏)）中的公有服务<br><img src="https://i.loli.net/2019/08/11/ab2uJTrhVCylmHW.png" alt="direct_connect_overview.png"></li>
</ul>
<h2 id="Direct-Connect-Advantages"><a href="#Direct-Connect-Advantages" class="headerlink" title="Direct Connect Advantages"></a>Direct Connect Advantages</h2><ul>
<li>降低带宽成本<ul>
<li>所有通过专用连接传输的数据均按AWS直接连接数据传输速率(而不是Internet数据传输速率)的，从而节省成本</li>
<li>在AWS之间传输数据直接减少了Internet服务提供商的带宽承诺</li>
</ul>
</li>
<li>一致的网络性能<ul>
<li>与互联网的网络变化（抖动、延迟）相比，Direct Connect提供专用连接和更一致的网络性能体验</li>
</ul>
</li>
<li>AWS 服务兼容性<ul>
<li>Direct Connect是一种网络服务，可与S3，EC2和VPC等所有AWS服务配合使用</li>
</ul>
</li>
<li>VPC的专用连接<ul>
<li>使用直接连接专用虚拟接口（Private virtual interface）可以在网络和VPC之间建立专用的专用高带宽网络连接</li>
</ul>
</li>
<li>弹性<ul>
<li>使用更高带宽的连接或建立多个连接，可以轻松扩展直接连接以满足需求</li>
</ul>
</li>
</ul>
<h1 id="Direct-Connect-vs-IPSec-VPN-Connections"><a href="#Direct-Connect-vs-IPSec-VPN-Connections" class="headerlink" title="Direct Connect vs IPSec VPN Connections"></a>Direct Connect vs IPSec VPN Connections</h1><ul>
<li>VPC VPN连接通过IPSec在Internet上建立内部网和Amazon VPC之间的加密网络连接</li>
<li>VPN连接可以在几分钟内进行配置，而对于需要一个具有低到适度的带宽需求，并能容忍在基于互联网连接的内在变化</li>
<li>AWS Direct Connect不涉及Internet; 相反，它使用Intranet和Amazon VPC之间的专用专用网络连接</li>
<li>与Direct Connect连接相比，VPN连接非常便宜，因为它需要实际的硬件和基础设施，可能需要数千个</li>
</ul>
<h1 id="Direct-Connect-Anatomy"><a href="#Direct-Connect-Anatomy" class="headerlink" title="Direct Connect Anatomy"></a>Direct Connect Anatomy</h1><p><img src="https://i.loli.net/2019/08/11/GumT4j7R1sLoiHE.png" alt="screen-shot-2016-05-17-at-1-56-15-pm.png"></p>
<ul>
<li>亚马逊在不同地点维护AWS Direct Connect PoP（称为主机托管设施），这与AWS区域不同</li>
<li>AWS本身维护从AWS Direct Connect PoP到AWS区域的连接</li>
<li>消费者，既可以购买机架空间，也可以使用任何已在主机托管设施中拥有基础架构的AWS APN合作伙伴并配置客户网关</li>
<li>Direct Connect PoP与Colocation Facility内的Customer网关之间的连接称为Cross Connect</li>
<li>可以使用任何服务提供商网络建立从客户网关到客户数据中心的连接</li>
<li>使用AWS创建直接连接连接后，将收到LOA-CFA（授权书 - 连接设施分配）。</li>
<li>LOA-CFA可以切换到主机托管设施或APN合作伙伴以建立交叉连接</li>
<li>一旦建立了Cross Connect以及CGW和Customer DataCenter之间的连接，就可以创建虚拟接口</li>
<li>AWS Direct Connect需要VGW才能访问AWS VPC</li>
<li>虚拟接口<ul>
<li>每个AWS Direct Connect连接都需要一个虚拟接口</li>
<li>每个AWS Direct Connect连接都可以配置一个或多个虚拟接口。</li>
<li>可以创建公共虚拟接口（public virtual interface）以连接到例如公共资源。 SQS，S3，EC2，Glacier等只能公开到达</li>
<li>可以创建专用虚拟接口以连接到例如VPC私有IP地址的实例</li>
<li>每个虚拟接口都需要VLAN ID，接口IP地址，ASN和BGP密钥</li>
</ul>
</li>
<li>要将AWS Direct Connect连接与其他AWS账户一起使用，可以为该账户创建托管虚拟接口。 这些托管虚拟接口与标准虚拟接口的工作方式相同，可以连接到公共资源或VPC。</li>
</ul>
<h1 id="Direct-Connect-Redundancy"><a href="#Direct-Connect-Redundancy" class="headerlink" title="Direct Connect Redundancy"></a>Direct Connect Redundancy</h1><p><img src="https://i.loli.net/2019/08/11/WU7kjK2xcd3uslJ.png" alt="screen-shot-2016-05-17-at-1-57-22-pm.png"></p>
<ul>
<li>直接连接不提供冗余，并且有多个单点故障，因为每个连接都包含路由器端口和Amazon路由器之间的单个专用连接</li>
<li>冗余连接<ul>
<li>建立第二个DX，最好使用不同的路由器和AWS Direct Connect PoP在不同的主机托管设施中建立连接</li>
<li>客户DC与VGW之间的IPsec VPN连接</li>
</ul>
</li>
<li>对于在同一AWS Direct Connect位置中请求的多个端口，Amazon本身确保在冗余Amazon路由器上配置它们以防止硬件故障的影响</li>
</ul>
<h1 id="Direct-Connect-LAG"><a href="#Direct-Connect-LAG" class="headerlink" title="Direct Connect LAG"></a>Direct Connect LAG</h1><ul>
<li>链接聚合组 (LAG) 是一个逻辑接口，使用链接聚合控制协议 (LACP) 在一个 AWS Direct Connect 终端节点处聚合多个连接，从而允许将这些连接视为一个托管连接</li>
<li>可从现有连接创建 LAG，也可配置新连接</li>
<li>在创建 LAG 之后，可将现有连接 (无论是独立连接还是其他 LAG 的一部分) 与 LAG 关联</li>
<li>LAG遵循以下规则<ul>
<li>LAG 中的所有连接都必须使用相同的带宽</li>
<li>LAG 中最多可有 4 个连接。LAG 中的每个连接都会计入区域的整体连接限制</li>
<li>LAG 中的所有连接都必须终止于同一 AWS Direct Connect 终端节点<h4 id="refer"><a href="#refer" class="headerlink" title="refer"></a>refer</h4></li>
</ul>
</li>
</ul>
<ul>
<li>AWS Direct Connect user guide</li>
<li><a href="http://jayendrapatil.com/aws-direct-connect-dx" target="_blank" rel="noopener">http://jayendrapatil.com/aws-direct-connect-dx</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/08/11/AWS地理组件/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/11/AWS地理组件/" itemprop="url">AWS地理组件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-11T10:11:31+08:00">
                2019-08-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS/" itemprop="url" rel="index">
                    <span itemprop="name">AWS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><font size="1">&gt; <em>前沿：本文主要描述AWS各种服务自身的作用范围（地理），AWS的各种服务所覆盖的地理区域包含全区域、Region、AZ等</em></font></p>
<h3 id="优先解释几个概念"><a href="#优先解释几个概念" class="headerlink" title="优先解释几个概念"></a>优先解释几个概念</h3><p><font color="red">AWS Regions &amp; Availability Zones</font></p>
<ul>
<li>Amazon服务托管在全球多个位置。Amazon提供将资源和数据放置在多个位置的能力，以提高性能、提供容错、高可用性和成本优化</li>
</ul>
<p><font color="red">Region</font></p>
<ul>
<li>AWS为客户提供了在多个地理区域(称为区域)中放置实例和存储数据的灵活性。每个区域都是一个定义地理位置上AWS资源的独立集合。</li>
<li>每个地区都是一个独立的地理区域，是完全独立的。</li>
<li>每个Amazon区域都被设计成与其他区域完全隔离，并帮助实现尽可能大的容错性和稳定性</li>
<li>区域间的通信是通过公共互联网进行的，应该采取适当的措施使用加密技术来保护数据</li>
<li>区域间的数据传输按Internet数据传输速率对发送和接收实例进行收费</li>
<li>除非显式复制，否则不会跨区域复制资源</li>
<li>一个地区的选择可以由许多因素驱动<ul>
<li>延迟—可以选择贴近目标用户群的区域，以减少数据延迟成本</li>
<li>AWS在所有地区提供相同的服务，但通常情况下，由于亚马逊的成本(由于土地、电力、带宽等)不同，服务的成本也会有所不同，因此在一个地区的服务成本可能会低于另一个地区</li>
</ul>
</li>
<li>法律遵从性——许多国家强制执行数据驻留在区域内的遵从性和法规要求（如欧盟的GDPR）</li>
<li>特性——由于并非所有区域都提供所有AWS特性和服务，因此区域选择可以依赖于该区域支持的服务</li>
</ul>
<p><font color="red"> Availability Zones</font></p>
<ul>
<li>每个区域由多个孤立的位置组成，这些位置称为可用性区域，每个可用性区域都运行在其物理上不同的、独立的基础设施上（风火水电完全独立），并且设计得非常可靠。</li>
<li>每个Region都有多个可用性区域。</li>
<li>每个AZ在物理上是相互隔离的（距离在KM以上），因此一个不常见的灾难，如火灾、地震，只会影响一个AZ</li>
<li>AZs在地理上相互分离，位于同一区域内，是一个独立的失效区。</li>
<li>AZ冗余地连接到多个运营商的链路。<br>区域中的AZ使用低延迟的私有链接连接，而不是通过公共internet。</li>
<li>多AZ，跨多个可用性区域的资源分布，特性可用于跨多个AZ分布实例，以提供高可用性。</li>
<li>AWS通过将每个帐户的可用性区域独立映射到标识符，确保资源分布在一个区域的可用性区域之间。例如，us-east-1区域的us-east-1a AZ可能与us-east-1a AZ位于不同的位置。无法协调帐户之间的可用性区域。</li>
</ul>
<p><font color="red">Edge Locations</font></p>
<ul>
<li>Edge location是AWS Cloud Front (CDN)面向全球提供数据加速访问的节点。</li>
<li>主要位于世界上大多数主要城市，CloudFront (CDN)使用这些位置向终端用户分发内容，以减少延迟。<h1 id="1-AWS-地理组件"><a href="#1-AWS-地理组件" class="headerlink" title="1. AWS 地理组件"></a>1. AWS 地理组件</h1></li>
</ul>
<ul>
<li>AWS 提供三种地理性组件：（<a href="https://infrastructure.aws/" target="_blank" rel="noopener">https://infrastructure.aws/</a> 获取最新信息，可查阅这个网站，具体网络连接，region内AZ数量，区域内的PoP节点都可以即时获得。）</li>
<li><strong>Regions</strong>：区域，即AWS提供云服务的一个区域，其目的是为了用户能就近接入，降低网络延迟。通常是一个城市的若干个AZ组成一个region。2016年，AWS 宣布在其全球region之间建设了100GbE 私有环网。</li>
<li><strong>Availability Zones</strong>：一个 region 内至少两个通常三个可用区，其用途是为了搭建高可用架构。一个比较常见的看法是一个AZ是一个数据中心。（其实这不尽然，有时候靠得非常近的几个数据中心也可以组成一个AZ。弗吉尼亚有6个AZ。部分AZ 超过30万台服务器。AZ拥有独立的包括电力和网络在内的基础设施等。）AZ 之间利用低延迟光纤网络互联，延迟控制在3ms以内，AZ内低于0.3ms。（目前所有新建区域的AZ都会保持3个及以上，北京区域属于特殊情况。）</li>
<li><strong>Edge Locations</strong>：指往往部署在大城市，以及主要人口汇聚区域的AWS 站点。它的主要作用是缓存数据，降低延迟。它们独立于region 和 AZ，数量比AZ多很多。它被多个AWS服务利用，比如AWS CloudFront 和 AWS Lambda@Edge。CloudFront 利用它来作为提供给用户分布在全球的接入点，通常称为Edge POP点。</li>
<li><strong>目前全球有21个区域，66个可用区，180个接入点（2019/07/23）</strong></li>
</ul>
<p><img src="https://i.loli.net/2019/08/11/PRfSLEvcx2Fe1h5.jpg" alt="001.jpg"><br><img src="https://i.loli.net/2019/08/11/vaZy2ekGKf37jiM.jpg" alt="003.jpg"></p>
<h1 id="2-AWS基础服务与地理组件关系"><a href="#2-AWS基础服务与地理组件关系" class="headerlink" title="2. AWS基础服务与地理组件关系"></a>2. AWS基础服务与地理组件关系</h1><p><img src="https://i.loli.net/2019/08/11/x1HuiApjYXPF6cR.jpg" alt="004.jpg"></p>
<p>例如：</p>
<ol>
<li>AWS 只有极少数全区域性的，不限于特定region，比如IAM、SES、S3 和 CloudFront（特殊区域除外，如AWS USA GOV、中国区域）</li>
<li>一些服务是覆盖区域的，其作用范围在某个特定区域内，比如经常使用的的S3、AMI</li>
<li>一些服务是覆盖可用区的，其作用范围在某可用区内，比如最常使用的 EC2和EBS</li>
</ol>
<p><img src="https://i.loli.net/2019/08/11/MxZpr82NsRJGl9O.jpg" alt="002.jpg"></p>
<h1 id="3-具体覆盖区域"><a href="#3-具体覆盖区域" class="headerlink" title="3. 具体覆盖区域"></a>3. 具体覆盖区域</h1> <style>
table {
    width: 100%; /*表格宽度*/
    max-width: 65em; /*表格最大宽度，避免表格过宽*/
    border: 1px solid #dedede; /*表格外边框设置*/
    margin: 15px auto; /*外边距*/
    border-collapse: collapse; /*使用单一线条的边框*/
    empty-cells: show; /*单元格无内容依旧绘制边框*/
}
table th,

table td {
  height: 35px; /*统一每一行的默认高度*/
  border: 1px solid #dedede; /*内部边框样式*/
  padding: 0 10px; /*内边距*/
          }
table tbody tr:nth-child(2n) {
    background: rgba(158,188,226,0.12); 
}

table tr:hover {
    background: #efefef; 
}




.table-area {
    overflow: auto;
}

  </style>






<table>
<thead>
<tr>
<th align="center">Service</th>
<th align="center">Global</th>
<th align="center">Region</th>
<th align="center">AZ</th>
<th align="center">subservices</th>
<th align="left">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">IAM</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Users, Groups, Roles, Accounts</td>
<td align="left">所有区域都可以使用相同的AWS帐户、用户、组和角色</td>
</tr>
<tr>
<td align="center">IAM</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Key Pairs</td>
<td align="left">关键对-全球或地区</td>
</tr>
<tr>
<td align="center">IAM</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Key Pairs</td>
<td align="left">IAM users 是与 AWS account 绑定的，不受限于某个region。</td>
</tr>
<tr>
<td align="center">IAM</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Key Pairs</td>
<td align="left">注：中国/美国 GOV区域除外，其都有自己独立的IAM账户体系，不与全球共用。</td>
</tr>
<tr>
<td align="center">IAM</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">Key Pairs</td>
<td align="left">Amazon EC2创建的密钥对是特定于该区域的</td>
</tr>
<tr>
<td align="center">IAM</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">RSA key pair</td>
<td align="left">RSA密钥对可以创建和上传，可以在所有区域使用。</td>
</tr>
<tr>
<td align="center">KMS</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">存储在创建区域，并且仅在该区域使用。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">VPC</td>
<td align="left">VPC是在一个区域内创建的</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">VPC 位于一个reigon内，且分布在该region的所有AZ内。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">VPC不能迁移至其它region，而只能新建。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">Subnet</td>
<td align="left">子网只能率属于AZ。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">Security groups</td>
<td align="left">安全组绑定到一个区域，并且只能分配给同一区域中的实例。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">VPC Endpoints</td>
<td align="left">您不能在不同区域的VPC和AWS服务之间创建端点。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">VPC Peering</td>
<td align="left">支持region内和跨region</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">-</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">NAT gateway</td>
<td align="left">NAT网关运行在AZ中</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">Virtual private gateway (VGW)</td>
<td align="left">VGW在Region范围内自身实现冗余度设计。但是，VPN 服务和DX 需要用户自配置其高可用设计。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">Internet gateway</td>
<td align="left">IGW在Region范围内自身实现高可用、冗余度设计，等同于有多条链路到达IGW。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">Elastic IP Address</td>
<td align="left">在区域内创建的弹性IP地址只能分配给区域内的实例。</td>
</tr>
<tr>
<td align="center">VPC</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">每个region有它自己的地址池，EIP 从该池中分配。</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">Resource Identifiers</td>
<td align="left">资源标识符属于Region范围内，每个资源标识符(如AMI ID、实例ID、EBS卷ID或EBS快照ID)都绑定到其区域，并且只能在创建资源的区域中使用。</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">Instances</td>
<td align="left">实例绑定到启动它的可用性区域。但是，请注意它的实例ID绑定到该区域。</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">EBS Volumes</td>
<td align="left">Amazon EBS卷绑定到它的可用性区域，并且只能附加到同一可用性区域（AZ）中的实例。</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">EBS Snapshot</td>
<td align="left">EBS快照绑定到它的区域，并且只能用于在同一区域创建卷，如果需要，必须从一个区域复制到另一个区域，可利用 Snapshot Copy 功能将其拷贝至其它region</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">AMIs （Aamzon Machine Images）</td>
<td align="left">AMI提供了启动EC2实例的模板</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">AMI与Amazon S3中文件所在的区域绑定。对于在不同区域使用AMI，可以将AMI复制到其他区域</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">AWS 提供 AMI Copy 功能来将某AMI 拷贝至其它region。</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">Auto Scaling</td>
<td align="left">自动扩展跨越同一区域内的多个可用性区域，但不能跨区域</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">ELB(Elastic Load Balancer)</td>
<td align="left">弹性负载均衡器在同一区域的多个可用性区域的多个实例之间分配流量</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">无法将 ELB 迁移至其它region，你只能在其它region中新建ELB实例。</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">SSH Public Keys</td>
<td align="left">保存在region内，AWS不跨region复制或同步keys。</td>
</tr>
<tr>
<td align="center">EC2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">Placement Groups</td>
<td align="left">集群放置组部署在同一可用性区域内的实例组</td>
</tr>
<tr>
<td align="center">S3</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">S3 bucket  name是全球性，但数据是区域性的</td>
</tr>
<tr>
<td align="center">S3</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">S3桶是在选定的区域内创建的Bucket 中的数据物理地位于一个region内，但是可以从其它region上访问它，此时需要考虑到延时问题。</td>
</tr>
<tr>
<td align="center">S3</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">存储的对象跨可用性区域复制，以提供高持久性，但除非显式地进行跨区域复制，否则不会跨区域复制</td>
</tr>
<tr>
<td align="center">Glacier</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">要迁移 Glacier 中的数据的话，需要经过几个步骤：1. 将 Glacier 中的数据restore到 S3 中。2. 利用 S3 Copy 功能将数据拷贝至另一个region 3. 利用 S3 lifecycle policy 将 S3 中的数据转移到新的region的 Glacier 内 4. 将原region的 Glacier 中的数据删除。</td>
</tr>
<tr>
<td align="center">Glacier</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">注：目前S3可以向S3 Deep Archive 直接归档数据（如北京region到宁夏）</td>
</tr>
<tr>
<td align="center">EFS</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">有两种数据在region间的迁移途径。1. 将EFS中的数据拷贝至 EBS，然后利用 EBS Snapshot Copy 功能将数据拷贝至另一个region内，再将数据从 EBS 拷贝到 EFS 内。 2. 将 EFS 中的数据拷贝到 S3 中，然后将利用 S3 Cross-region Replication 功能将数据拷贝至另一个region，再从S3 拷贝到EFS。</td>
</tr>
<tr>
<td align="center">Route53</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">Route53服务是在AWS的边缘位置提供的，并且是全球性的</td>
</tr>
<tr>
<td align="center">RDS</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="left">RDS 实例有单可用区的，也有跨多AZ 的</td>
</tr>
<tr>
<td align="center">RDS</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">可利用 AWS Database Migration Serivce 进行跨区域迁移</td>
</tr>
<tr>
<td align="center">RDS</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">跨区域的手工数据迁移步骤：1. 停止transactions 2. 在一个临时 EC2 将 DB 中的数据导出为文件 3. 利用工具将文件拷贝至远端region的EC2内 4. 创建RDS实例 5. 导入数据文件</td>
</tr>
<tr>
<td align="center">ElastiCache</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">支持 Redis 和 Memcached</td>
</tr>
<tr>
<td align="center">ElastiCache</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">Redis 迁移方法：1. 给集群手工创建一个 backup 2. 将backup 导入 S3. 4. S3 bucket 复制到另一个region。 5. 在新的region 内从 S3 restore 数据，其过程包括创建一个新的 Redis cluster 然后导入数据。</td>
</tr>
<tr>
<td align="center">ElastiCache</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">Memcached 数据跨region 迁移方法：在新的region 内创建一个 cluster，然后从应用层做数据复制。</td>
</tr>
<tr>
<td align="center">RedShift</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">集群迁移：利用 RedShift cross-region snapshot 功能创建snapshot 并将它拷贝到新的region内，然后将snapshot restore 到集群。</td>
</tr>
<tr>
<td align="center">RedShift</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">表迁移：利用 RedShift Upload 功能将数据导入 S3，再利用 S3 Cross-region Replication 功能将数据复制到另一个region，再在另一个region内创建 RedShift 集群并利用 COPY 功能从S3 中导入数据。</td>
</tr>
<tr>
<td align="center">EMR</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">跨region 迁移 EMR：在新的 region 内新建 EMR Cluster，然后导入数据</td>
</tr>
<tr>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">如果数据在 S3 中，则利用 S3 cross-region replication 功能将数据迁移到新的 region 内</td>
</tr>
<tr>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">如果数据在 HDFS 内，择利用 S3DistCp 命令将HDFS 内的数据拷贝到 S3， 然后再利用 S3DistCp 命令将S3 中的数据拷贝到目标 HDFS 内。</td>
</tr>
<tr>
<td align="center">Elasticsearch</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">为 ES domain 创建一个 snapshot，它会被保存到 S3 内。再利用 S3 做跨region 复制。再在新region内将数据从S3 恢复到 Elasticsearch 中。</td>
</tr>
<tr>
<td align="center">SQS</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">SQS queues 位于region内。需要利用应用，将消息从源region 的 queues 中导入目的 region的 queues 内。</td>
</tr>
<tr>
<td align="center">SNS</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">SNS topics 位于region 内</td>
</tr>
<tr>
<td align="center">Auroa</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">在另一个region 内创建一个 Aurora Cluster 作为 Read Replica。一旦创建后，Amazon RDS 对原 Aurora cluster 做snapshot，然后将 snapshot 发送只 Read Replica。</td>
</tr>
<tr>
<td align="center">DynamoDB</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">所有数据对象都存储在同一区域内，并跨同一区域中的多个可用性区域复制</td>
</tr>
<tr>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">可以使用跨区域复制显式地跨区域复制数据对象</td>
</tr>
<tr>
<td align="center">WAF</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">WAF服务保护Web应用程序免受常见Web攻击，它是在AWS边缘位置提供的，并且是全局的</td>
</tr>
<tr>
<td align="center">CloudFront</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">CloudFront是全球内容交付网络(CDN)服务，</td>
</tr>
<tr>
<td align="center">Storage Gateway</td>
<td align="center">-</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">AWS存储网关适用范围在Region范围内，提供存储卷、快照和磁带数据的网关。</td>
</tr>
<tr>
<td align="center">SES</td>
<td align="center">Y</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="left">SES 有 regional endpoint。你的应用既可以使用与它相同region内的 SES服务，也可以利用其它region内的SES服务。当然了，这里面需</td>
</tr>
</tbody></table>
<h4 id="Refer"><a href="#Refer" class="headerlink" title="Refer"></a>Refer</h4><ul>
<li>《Using Amazon Web Services for Disaster Recovery》</li>
<li>《Migrating AWS Resources to a New AWS Region》</li>
<li>《Building Fault-Tolerant Application on AWS》</li>
<li>刘世民 云计算 博客</li>
<li><a href="http://jayendrapatil.com/aws-global-vs-regional-vs-az-resources/" target="_blank" rel="noopener">http://jayendrapatil.com/aws-global-vs-regional-vs-az-resources/</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/08/10/AWS-VPC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/10/AWS-VPC/" itemprop="url">AWS VPC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-10T11:30:44+08:00">
                2019-08-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS/" itemprop="url" rel="index">
                    <span itemprop="name">AWS</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><font size="2"> &gt; <em>前言：在 Amazon Web Services (AWS) 云中预置一个逻辑隔离的部分，可以在自己定义的虚拟网络中启动 AWS 资源。完全掌控您的虚拟联网环境，包括选择自己的 IP 地址范围、创建子网以及配置路由表和网络网关。在 VPC 中可以使用 IPv4 和 IPv6，因此能够轻松安全地访问资源和应用程序。</em></font></p>
<h2 id="VPC-Overview-amp-Components"><a href="#VPC-Overview-amp-Components" class="headerlink" title="VPC Overview &amp; Components"></a>VPC Overview &amp; Components</h2><font face="微软雅黑">

<ul>
<li>虚拟私有云（VPC）是专用于AWS账户的虚拟网络， 它在逻辑上与AWS云中的其他虚拟网络隔离</li>
<li>VPC允许用户选择IP地址范围，创建子网，以及配置路由表，网络网关和安全设置</li>
<li>VPC sizing<ul>
<li>创建 VPC 时将单个无类别互联网域路由 (CIDR) IP 地址范围指定为主 CIDR 块，默认 VPC 分配有 172.31.0.0/16 的 CIDR 范围（允许2 ^ 16（65536）IP地址可用）</li>
<li>允许的CIDR块大小介于以下两者之间<ol>
<li>/ 28网络掩码（最小值为2 ^ 4  -  16个可用IP地址）</li>
<li>/ 16网络掩码（最大为2 ^ 16  -  65536 IP地址）</li>
</ol>
</li>
</ul>
</li>
<li>可以分配来自专用（非公共路由）IP地址的CIDR块<ol>
<li>10.0.0.0  -  10.255.255.255（10/8前缀）</li>
<li>172.16.0.0  -  172.31.255.255（172.16 /12前缀）</li>
<li>192.168.0.0  -  192.168.255.255（192.168/16前缀）<ul>
<li>可以指定一系列可公开路由的IP地址;然而，VPC中公开路由的CIDR块目前不支持直接访问Internet(public subnet)</li>
<li>现在可以调整VPC的size</li>
<li>每个VPC都与使用相同CIDR块创建的任何其他VPC分开，即使它位于同一AWS账户中</li>
</ul>
</li>
</ol>
</li>
<li>VPC允许VPC对等连接与相同或不同AWS账户中的其他VPC</li>
<li>可以建立VPC与公司或家庭办公网络之间的连接，但是CIDR块不应重叠，例如： 具有CIDR 10.0.0.0/16的VPC可以与10.1.0.0/16公司网络通信，但如果尝试连接到10.0.37.0/16公司网络导致重叠IP地址，则连接将被丢弃。</li>
<li>VPC允许其中启动的实例设置租期选项。 默认情况下，租赁选项是共享的。 如果选择了专用选项，则其中的所有实例都将在覆盖单个实例租用设置的专用硬件上启动</li>
<li>只有在终止VPC中的所有实例并删除具有VPC的所有组件之后，才可能删除VPC，包括子网，安全组，网络ACL，路由表，Internet网关，VPC对等连接和DHCP选项</li>
<li>AWS VPC组件<br><img src="https://i.loli.net/2019/08/10/fLeUIt8TSy6vD5Q.png" alt="AWS-VPC-Components.png"><h2 id="IP-Address"><a href="#IP-Address" class="headerlink" title="IP Address"></a>IP Address</h2>在VPC中启动的实例可以分配私有，公共和弹性IP地址，并且是ENI（弹性网络接口）的属性<h3 id="Private-IP-Addresses"><a href="#Private-IP-Addresses" class="headerlink" title="Private IP Addresses"></a>Private IP Addresses</h3></li>
<li>私有IP地址无法通过Internet访问，并且只能用于VPC内的实例之间的通信</li>
<li>所有实例都在子网的IP地址范围内分配给默认网络接口(eth0)的私有IP地址</li>
<li>主（Primary）IP地址在其生命周期内与网络接口相关联，即使实例已停止并重新启动，仅在实例终止时才释放</li>
<li>可以将其他私有IP地址（称为辅助专用IP地址）分配给实例，这些可以从一个网络接口重新分配给另一个网络接口（非eth0）<h3 id="Public-IP-Addresses"><a href="#Public-IP-Addresses" class="headerlink" title="Public IP Addresses"></a>Public IP Addresses</h3></li>
<li>公共IP地址可通过Internet访问，可用于实例与Internet之间的通信，也可用于具有公共端点的其他AWS服务</li>
<li>为实例分配公共IP地址取决于是否为子网启用了公共IP属性</li>
<li>通过在创建实例期间启用公共IP，也可以将公共IP分配给实例，从而覆盖子网的公共IP寻址属性</li>
<li>公共IP地址是从AWS IP地址池分配的，它与AWS账户无关，因此在实例停止并重新启动或终止时会释放<h3 id="Elastic-IP-Address"><a href="#Elastic-IP-Address" class="headerlink" title="Elastic IP Address"></a>Elastic IP Address</h3></li>
<li>弹性IP地址是静态的，持久的公共IP地址，可以根据需要与实例关联或解除关联</li>
<li>弹性IP地址在VPC上分配，并由帐户拥有，除非被释放</li>
<li>可以为网络接口分配公共IP或弹性IP。 如果分配已具有公共IP，分配弹性IP的实例时，则会释放公共IP</li>
<li>弹性IP地址可以从一个实例移动到另一个实例，该实例可以位于同一帐户中的相同或不同VPC内</li>
<li>弹性IP收取费用，即使其并未与相关实例绑定或ENI相关联<h2 id="Elastic-NetworkInterface（ENI）"><a href="#Elastic-NetworkInterface（ENI）" class="headerlink" title="Elastic NetworkInterface（ENI）"></a>Elastic NetworkInterface（ENI）</h2></li>
<li>每个实例都附带默认的弹性网络接口（主网络接口eth0），不能与实例分离</li>
<li>ENI包含以下属性<ul>
<li>Primary 私有IP</li>
<li>一个或多个辅助私有IP地址</li>
<li>每个privateIP地址一个弹性IP地址</li>
<li>一个公共IP地址，可以在启动实例时自动分配给eth0的网络接口，仅在为eth0创建网络接口而不是使用现有ENI</li>
<li>一个或多个安全组</li>
<li>一个MAC地址</li>
<li>源/目标检查标志</li>
<li>其他说明</li>
</ul>
</li>
<li>ENI的属性归属ENI，不属于实例，可以与实力连接或分离，并重新连接到另一个实例，属性仍然有效。 当ENI从一个实例移动到另一个实例时，网络流量将重定向到新实例。</li>
<li>实例可以附加多个ENI，有着一下好处<ul>
<li>独立管理网络</li>
<li>在VPC中使用网络和安全设施</li>
<li>使实例在不同子网上具有不同工作负载/角色</li>
<li>性价比、高可用的解决方案<h2 id="Route-Tables"><a href="#Route-Tables" class="headerlink" title="Route Tables"></a>Route Tables</h2></li>
</ul>
</li>
<li>路由表定义的规则，称为路由，确定在何处从子网的网络流量将被路由</li>
<li>每个VPC都有一个隐式路由器来路由网络流量</li>
<li>每个VPC都有一个主路由表，可以创建多个自定义路由表</li>
<li>VPC中的每个子网必须一次与一个路由表相关联，而路由表可以有多个与之关联的子网</li>
<li>如果未明确地与路由表关联，则子网与主路由表隐式关联</li>
<li>每个路由表都包含一个本地路由，该路由允许在VPC内进行无法修改或删除的通信</li>
<li>路由优先级通过匹配路由表中与流量匹配的最具体路由来确定</li>
<li>路由表需要更新，已经定义的好的网关设备如IGW，虚拟专用网关，VPC对等，VPC端点，NAT设备等<h2 id="Internet-Gateways-IGW"><a href="#Internet-Gateways-IGW" class="headerlink" title="Internet Gateways-IGW"></a>Internet Gateways-IGW</h2></li>
<li>IGW是一种水平扩展，冗余且高度可用的VPC组件，允许在VPC和Internet中的实例之间进行通信</li>
<li>IGW不对网络流量设置带宽限制或成为故障风险点（国内公有云有网络出口限制，同时这里的带宽不限制，是在不超过AWS自身网络限制）</li>
<li>IGW有两个用途：在VPC路由表中为可路由Internet的流量提供网关目标，以及实例（未分配公有IP地址）执行网络地址转换（NAT）</li>
<li>实例访问Internet需要满足一下要求<ul>
<li>将IGW关联到VPC</li>
<li>子网具有指向IGW网关的路由表</li>
<li>实例应分配公共IP或弹性IP</li>
<li>与实例关联的安全组和AACL应该允许其流量通过<h2 id="NAT"><a href="#NAT" class="headerlink" title="NAT"></a>NAT</h2></li>
</ul>
</li>
<li>NAT设备允许私有子网中的实例连接到Internet或其他AWS服务，但阻止Internet与实例的连接</li>
<li>NAT设备不支持IPv6流量，而应使用egress-only Internet gateway网关<h2 id="Egress-only-Internet-gateway"><a href="#Egress-only-Internet-gateway" class="headerlink" title="Egress-only Internet gateway"></a>Egress-only Internet gateway</h2></li>
<li>像NAT网关使用，并且仅支持IPv6</li>
<li>Egress Only Internet Gateway网关是一种水平扩展，冗余且高度可用的VPC组件，允许通过IPv6从VPC中的实例向Internet进行出站通信，并防止Internet实例的IPv6连接</li>
<li>仅用于IPv6,如果要启用IPv4请使用NGW<h2 id="VPC-amp-Subnet-Sizing"><a href="#VPC-amp-Subnet-Sizing" class="headerlink" title="VPC &amp; Subnet Sizing"></a>VPC &amp; Subnet Sizing</h2></li>
<li>VPC支持IPv4和IPv6寻址，并且每个都具有不同的CIDR块大小限制</li>
<li>VPC 可以同时有 IPv4 和 IPv6 CIDR 块与其关联</li>
<li>对于 IPv6，VPC 使用 /56 的固定大小</li>
<li>通过向现有 VPC 添加四 (4) 个辅助 IPv4 IP 范围 (CIDR) 来扩展 VPC。可通过删除已添加到 VPC 的辅助 CIDR 块来缩小 VPC；不能更改 VPC 的 IPv6 地址范围的大小</li>
<li>限制<ul>
<li>允许的块大小介于/ 28~ / 16网络掩码之间</li>
<li>CIDR块不得与任何与VPC关联的现有CIDR块重叠</li>
<li>CIDR块不能与任何VPC路由表中的路由的CIDR范围相同或更大，例如， 对于CIDR块10.0.0.0/24，只能关联较小的CIDR块，如10.0.0.0/25<h2 id="VPC-Security"><a href="#VPC-Security" class="headerlink" title="VPC Security"></a>VPC Security</h2>提供三种功能，以用来提高和监控 Virtual Private Cloud (VPC) 的安全性</li>
</ul>
</li>
<li>安全组 充当实例的虚拟防火墙以控制入站和出站流量</li>
<li>网络访问控制列表 (ACL) 是 VPC 的一个可选安全层，可用作防火墙来控制进出一个或多个子网的流量</li>
<li>VPC 流日志这项功能，捕获有关传入和传出VPC 中网络接口的 IP 流量的信息<br><img src="https://i.loli.net/2019/08/10/fQTSim9weNAOWLR.png" alt="security-diagram.png"><h3 id="Security-Groups"><a href="#Security-Groups" class="headerlink" title="Security Groups"></a>Security Groups</h3></li>
<li>在实例级别而不是在子网级别执行</li>
<li>可以为子网中的每个实例分配不同的安全组</li>
<li>可以为实例分配5个安全组，每个安全组具有50个规则</li>
<li>安全组允许为实例的入站（入口）和出站（出口）流量添加或删除规则（授权或撤消访问）<ul>
<li>默认安全组不允许外部入站流量，但允许来自具有相同安全组的实例的入站流量</li>
<li>默认安全组允许所有出站流量</li>
<li>新安全组仅以允许所有流量离开实例的出站规则开始</li>
</ul>
</li>
<li>安全组只能指定允许规则，但不包含拒绝规则</li>
<li>安全组可以授予对特定CIDR范围或VPC中的另一个安全组或对等VPC的访问权限（需要VPC对等连接）</li>
<li>安全组被评估为完整或累积规则，其中最宽松的规则优先。对于例如 如果有一个允许从IP地址203.0.113.1访问TCP端口22（SSH）的规则和允许从每个人访问TCP端口22的另一个规则，则每个人都可以访问TCP端口22</li>
<li>安全组是<font color="red">有状态的</font> - 无论出站规则如何，都允许对允许的入站流量的响应流出，反之亦然。 因此，不需要响应的出站规则</li>
<li>安全组与ENI（网络接口）相关联</li>
<li>可以更改与实例关联的安全组，这会更改与主网络接口（eth0）关联的安全组，并且更改将立即应用于与安全组关联的所有实例<h4 id="Connection-Tracking"><a href="#Connection-Tracking" class="headerlink" title="Connection Tracking"></a>Connection Tracking</h4></li>
<li>由于安全组是有状态的，基于流量的连接状态应用规则以确定允许还是拒绝流量</li>
<li>无论出站安全组规则如何，都允许对入站流量的响应流出实例，反之亦然。</li>
<li>仅当入站请求没有明确的出站规则时才会维护连接跟踪（响应流量基于允许响应流量的入站或出站规则流动，而不是基于跟踪信息流动）</li>
<li>但是，如果是入站请求一个明确的出站规则，响应流量被允许出站规则的基础上，而不是跟踪连接</li>
<li>跟踪流量</li>
</ul>
<ol>
<li>对于除 TCP、UDP 或 ICMP 以外的协议，仅跟踪 IP 地址和协议编号</li>
<li>实例将流量发送到另一个主机 (主机 B)，并且在原始请求或响应的 600 秒内，主机 B 在单独的请求中发起到实例的同一类型的流量，则无论入站安全组规则如何，实例都将接受该请求，因为该流量被视为响应流量</li>
</ol>
<ul>
<li>确保所有入站流量均遵循防火墙规则，可以使用网络 ACL — <font color="red">网络 ACL 是无状态的</font>，因此不会自动允许响应流量<h3 id="NACLs"><a href="#NACLs" class="headerlink" title="NACLs"></a>NACLs</h3></li>
<li>网络访问控制列表 (ACL) 是 VPC 的一个可选安全层，可用作防火墙来控制进出一个或多个子网的流量</li>
<li>NACL作用于子网级别控制，并且适用于该子网中的所有实例</li>
<li>网络ACL具有单独的入站和出站规则，每个规则可以允许或拒绝流量默认ACL允许所有入站和出站流量</li>
<li>新创建的ACL拒绝所有入站和出站流量</li>
<li>子网只能分配1个ACL，如果没有明确关联，则会与默认NACL隐式关联</li>
<li>网络ACL是按顺序评估的编号规则列表</li>
<li>从编号最小的规则开始，确定是否允许流量进出与网络ACL关联的任何子网</li>
<li>例如如果你有一个允许全部的规则100和一个全部拒绝的规则110，则允许全部优先，所有流量都将被允许</li>
<li>网络ACL是无状态的;对允许的入站流量的响应受出站流量规则的约束（反之亦然），例如：如果从特定IP地址启用端口22上的入站SSH，则还需要为响应添加出站规则<h4 id="安全组-vs-ACL"><a href="#安全组-vs-ACL" class="headerlink" title="安全组 vs ACL"></a>安全组 vs ACL</h4><table>
<thead>
<tr>
<th>安全组</th>
<th>ACL</th>
</tr>
</thead>
<tbody><tr>
<td>在实例级别运行</td>
<td>在子网级别运行</td>
</tr>
<tr>
<td>仅支持允许规则</td>
<td>支持允许规则和拒绝规则</td>
</tr>
<tr>
<td>有状态：返回数据流会被自动允许，不受任何规则的影响</td>
<td>无状态：返回数据流必须被规则明确允许</td>
</tr>
<tr>
<td>决定是否允许数据流前评估所有规则</td>
<td>决定是否允许数据流时按照数字顺序处理所有规则</td>
</tr>
<tr>
<td>只有在启动实例的同时指定安全组、或稍后将安全组与实例关联的情况下，操作才会被应用到实例</td>
<td>自动应用到关联子网内的所有实例（因此不需要依靠用户指定安全组）</td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="VPC-Flow-logs"><a href="#VPC-Flow-logs" class="headerlink" title="VPC Flow logs"></a>VPC Flow logs</h2><ul>
<li>VPC 流日志这项功能，捕获有关传入和传出 VPC 中网络接口的 IP 流量的信息。流日志数据可以发布到 Amazon CloudWatch Logs 和 Amazon S3。创建流日志后，可以在选定目标中检索和查看其数据</li>
<li>可以为 VPC、子网或网络接口创建流日志。如果为子网或 VPC 创建流日志，则会监视 VPC 或子网中的每个网络接口</li>
<li>流日志不会为网络接口捕获实时日志流(通常需要几分钟开始收集数据并发布到指定目标)</li>
<li>可以为其他 AWS 创建的网络接口创建流日志，例如 Elastic Load Balancing、Amazon RDS、Amazon ElastiCache、Amazon Redshift 和 Amazon WorkSpaces<h2 id="Subnets"><a href="#Subnets" class="headerlink" title="Subnets"></a>Subnets</h2></li>
<li>子网跨越单个可用区，不同的位置设计为AZ级别故障隔离</li>
<li>子网可以配置IGW以启用Internet通信，或虚拟专用网关（VPN）连接以启用与公司网络的连通</li>
<li>子网可以是公共的或私有的，它取决于它是否具有因特网连接，即能够通过IGW将流量路由到因特网</li>
<li>应为公共子网中的实例分配公共IP或弹性IP地址，以便能够与Internet通信</li>
<li>对于未连接到Internet的子网，但通过虚拟专用网关路由的流量称为VPN专属子网</li>
<li>可以将子网配置为默认为子网内启动的所有实例分配公共IP地址</li>
<li>Subnet sizing <ul>
<li>分配给子网的CIDR块可以与VPC CIDR相同，在这种情况下，只能在VPC中启动一个子网</li>
<li>分配给子网的CIDR块可以是VPC CIDR的子集，允许在VPC中启动多个子网</li>
<li>分配给子网的CIDR块不应重叠</li>
<li>允许的CIDR块大小介于两者之间<ul>
<li>/28网络掩码（最小值为2 ^ 4  -  16个可用IP地址）</li>
<li>16网络掩码（最大为2 ^ 16  -  65536 IP地址）</li>
</ul>
</li>
<li>AWS在每个子网中保留5个IP地址（前4个和后1个IP地址），这些地址不可用，无法分配给实例。 例如 对于具有CIDR块10.0.0.0/24的子网，保留以下五个IP<ul>
<li>10.0.0.0：网络地址</li>
<li>10.0.0.1：AWS为VPC路由器保留</li>
<li>10.0.0.2：由AWS保留，用于映射到亚马逊提供的DNS</li>
<li>10.0.0.3：AWS保留供将来使用</li>
<li>10.0.0.255：网络广播地址。 AWS不支持VPC中的广播，因此保留地址</li>
</ul>
</li>
</ul>
</li>
<li>子网路由<ul>
<li>每个子网都与一个路由表相关联</li>
</ul>
</li>
<li>子网安全<ul>
<li>可以使用安全组和NACL配置子网安全性</li>
<li>安全组在实例级别工作，NACL在子网级别工作<h2 id="Shared-VPCs"><a href="#Shared-VPCs" class="headerlink" title="Shared VPCs"></a>Shared VPCs</h2></li>
</ul>
</li>
<li>VPC 共享允许多个 AWS 账户在共享的集中式管理的 Amazon Virtual Private Cloud (VPC) 中创建自己的应用程序资源，如 Amazon EC2、Amazon Relational Database Service (RDS)、Amazon Redshift 群集和 AWS Lambda</li>
<li>在此模型中，拥有 VPC 的账户（所有者）与属于 AWS Organizations 中同一组织的其他账户（参与者）共享一个或多个子网</li>
<li>共享子网之后，参与者可以查看、创建、修改和删除与他们共享的子网中的应用程序资源。参与者无法查看、修改或删除属于其他参与者或 VPC 拥有者的资源<h2 id="VPC-Endpoints"><a href="#VPC-Endpoints" class="headerlink" title="VPC Endpoints"></a>VPC Endpoints</h2></li>
<li>VPC 终端节点能够将 VPC 创建专有链接连接到支持的 AWS 服务和 VPC 终端节点服务（由 PrivateLink 提供支持），而无需 Internet 网关、NAT 设备、VPN 连接或 AWS Direct Connect 连接。VPC 中的实例无需公有 IP 地址便可与服务中的资源通信。VPC 和其他服务之间的通信不会离开 Amazon 网络。</li>
<li>终端节点是虚拟设备。这些是水平扩展、冗余且具备高可用性的 VPC 组件，通过使用这些组件，可以在 VPC 中的实例与服务之间进行通信，而不会对网络通信带来可用性风险或带宽限制</li>
<li>端点当前不支持跨区域请求，请确保在与服务相同相同的区域中创建端点</li>
<li>VPC 终端节点有两种类型：接口终端节点 和 网关终端节点</li>
<li>VPC 终端节点策略是一种 IAM 资源策略，在创建或修改终端节点时可将它附加到终端节点</li>
<li>默认策略来允许对服务进行完全访问。终端节点策略不会覆盖或取代 IAM 用户策略或服务特定策略 (如 S3 存储桶策略)<h3 id="网关-VPC-终端节点"><a href="#网关-VPC-终端节点" class="headerlink" title="网关 VPC 终端节点"></a>网关 VPC 终端节点</h3></li>
<li>网关终端节点是一个网关，作为路由表中的指定路由的目标（用于发送到受支持的 AWS 服务的流量）</li>
<li>支持Amazon S3&amp;DynamoDB<br><img src="https://i.loli.net/2019/08/10/oQuy8DG35PSltWF.png" alt="AWS-VPC-Endpoints.png"></li>
<li>Configuration<ol>
<li>指定要在其中创建终端节点的 VPC 以及要连接到的服务</li>
<li>端点需要与Route表关联，并且不能修改路由表以删除路由条目。只能通过删除与Route表的Endpoint关联来删除它</li>
<li>路由会自动添加到每个路由表中，同时会添加一个指定服务的前缀列表 ID 的目的地 (pl-xxxxxxxx) 以及一个具有终端节点 ID 的目标 (vpce-xxxxxxxx)；例如：</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>目的地</th>
<th>目标</th>
</tr>
</thead>
<tbody><tr>
<td>10.0.0.0/16</td>
<td>本地</td>
</tr>
<tr>
<td>pl-1a2b3c4d</td>
<td>vpce-11bb22cc</td>
</tr>
</tbody></table>
<ol start="4">
<li>端点策略可以控制对其他服务中的资源的访问</li>
<li>需要修改安全组以允许从VPC到端点中指定的服务的出站流量。 使用服务前缀列表ID，例如 com.amazonaws.us-east-1.s3作为出站规则中的目的地<ol start="6">
<li>在一个路由表中拥有针对不同服务的多个终端节点路由，并且可以在不同的路由表中拥有针对同一服务的多个终端节点路由，但不能在一个路由表中拥有针对同一服务的多个终端节点路由。例如，如果 VPC 中有两个针对 Amazon S3 的终端节点，则不能同时对这两个终端节点使用相同的路由表</li>
</ol>
</li>
</ol>
<ul>
<li>限制<ul>
<li>仅在同一地区内支持终端节点。无法在 VPC 和其他区域内的服务之间创建终端节点</li>
<li>无法将终端节点从一个 VPC 转移到另一个 VPC，也无法将终端节点从一项服务转移到另一项服务</li>
<li>无法将终端节点连接扩展到 VPC 之外。VPC 中的 VPN 连接、VPC 对等连接、AWS Direct Connect 连接或 ClassicLink 连接的另一端的资源不能使用终端节点与终端节点服务中的资源进行通信<h3 id="接口终端节点"><a href="#接口终端节点" class="headerlink" title="接口终端节点"></a>接口终端节点</h3></li>
</ul>
</li>
<li>接口 VPC 终端节，可连接到由 AWS PrivateLink 提供支持的服务</li>
<li>服务包括一些AWS服务，例如： CloudTrail，CloudWatch等，由其他AWS客户和合作伙伴在其自己的VPC（称为端点服务）中托管的服务，以及受支持的AWS Marketplace合作伙伴服务<br><img src="https://i.loli.net/2019/08/10/7VcIfgrZWMyF4GT.png" alt="VPC-Interface-Endpoints.png"></li>
<li>配置</li>
</ul>
<ol>
<li>选择要在其中创建接口终端节点的 VPC，然后提供要连接到的 AWS 服务、终端节点服务或 AWS Marketplace 服务的名称。</li>
<li>在 VPC 中选择使用接口终端节点的子网。将在该子网中创建一个终端节点网络接口</li>
<li>指定要与终端节点网络接口关联的安全组</li>
<li>为终端节点启用私有 DNS 以使能够使用服务的默认 DNS 主机名对服务发出请求（可选）</li>
</ol>
<ul>
<li>限制</li>
</ul>
<ol>
<li>对于每个接口终端节点，每个可用区只能选择一个子网</li>
<li>默认情况下，每个可用区的每个接口终端节点可支持高达 10 Gbps 的带宽</li>
<li>子网的网络ACL可以限制流量，需要正确配置</li>
<li><font color="red">接口终端节点仅支持 TCP 流量</font></li>
<li>仅在同一地区内支持终端节点</li>
<li>仅支持 IPv4 流量</li>
<li>无法将终端节点从一个 VPC 转移到另一个 VPC，也无法将终端节点从一项服务转移到另一项服务<h2 id="VPC-Peering"><a href="#VPC-Peering" class="headerlink" title="VPC Peering"></a>VPC Peering</h2></li>
</ol>
<ul>
<li>VPC 对等连接是两个 VPC 之间的网络连接，可通过此连接不公开地在这两个 VPC 之间路由流量(Private IP address)</li>
<li>两个 VPC 中的实例可以彼此通信，就像它们在同一网络中一样</li>
<li>可以在自己的 VPC 之间、自己的 VPC 与另一个 AWS 账户中的 VPC 或与其他 AWS 区域中的 VPC 之间创建 VPC 对等连接</li>
<li>AWS 使用 VPC 的现有基础设施来创建 VPC 对等连接；该连接既非网关也非 AWS Site-to-Site VPN 连接，且不依赖某个单独的物理硬件。</li>
<li>没有单点通信故障也没有带宽瓶颈</li>
</ul>
<h3 id="VPC-对等连接规则和限制"><a href="#VPC-对等连接规则和限制" class="headerlink" title="VPC 对等连接规则和限制"></a>VPC 对等连接规则和限制</h3><ol>
<li><p>不能在重叠CIDR块的VPC之间创建VPC对等连接<br><img src="https://i.loli.net/2019/08/10/xHQWgin81pjRylO.png" alt="Screen-Shot-2016-06-15-at-12.33.07-PM.png"></p>
</li>
<li><p>每个 VPC 创建数量有限的活动和待定 VPC 对等连接</p>
<table>
<thead>
<tr>
<th>源</th>
<th>默认限制</th>
<th>注释</th>
</tr>
</thead>
<tbody><tr>
<td>每个 VPC 的活动 VPC 对等连接</td>
<td>50</td>
<td>每个 VPC 的最大限制为 125 个对等连接。应相应地增加每个路由表的条目数；但是，网络性能可能会受到影响</td>
</tr>
<tr>
<td>未完成的 VPC 对等连接请求</td>
<td>25</td>
<td>这是账户请求的未完成 VPC 对等连接请求数的限制</td>
</tr>
<tr>
<td>未接受的 VPC 对等连接请求的过期时间</td>
<td>1</td>
<td>周 (168 小时)</td>
</tr>
</tbody></table>
</li>
<li><p>VPC 对等不支持传递的对等关系。在 VPC 对等连接中， VPC 无权访问对等 VPC 可能与之对等的任何其他 VPC<br><img src="https://i.loli.net/2019/08/10/Z7nO2QzRpqYMtld.png" alt="Screen-Shot-2016-06-15-at-12.33.00-PM.png"></p>
</li>
<li><p>VPC对等不支持通过网关或专用连接进行边缘到边缘路由</p>
</li>
<li><p>在VPC对等连接中，VPC无法访问对等VPC可能具有的任何其他连接， </p>
<ul>
<li>与企业网络之间的 VPN 连接或 AWS Direct Connect 连接</li>
<li>通过 Internet 网关建立的 Internet 连接</li>
<li>在私有子网中通过 NAT 设备建立的 Internet 连接</li>
<li>AWS 服务的 VPC 终端节点；例如，Amazon S3 的终端节点<br><img src="https://i.loli.net/2019/08/10/kciwbLvoAMqHDYj.png" alt="Screen-Shot-2016-06-15-at-12.35.38-PM.png"></li>
</ul>
</li>
<li><p>在同一个两个VPC之间只能建立一个VPC对等连接</p>
</li>
<li><p>VPC对等连接上的最大传输单元（MTU）为1500字节</p>
</li>
<li><p>置放组（place group）可在同一区域内建立对等连接，但在对等连接中无法获得全部带宽</p>
</li>
<li><p>VPC 对等连接创建的任何标签仅在创建它们的账户或区域中应用</p>
</li>
<li><p>不支持在 VPC 对等连接中进行单一地址反向传输路径转发</p>
</li>
<li><p><font color="red">必须为 VPC 对等连接启用 DNS 解析支持才能将对等 VPC 的私有 DNS 主机名解析为私有IP地址</font></p>
<h3 id="VPC-Peering-Architecture"><a href="#VPC-Peering-Architecture" class="headerlink" title="VPC Peering Architecture"></a>VPC Peering Architecture</h3><p><img src="https://i.loli.net/2019/08/10/H19WGByM87D6log.png" alt="Screen-Shot-2016-11-12-at-3.20.55-PM.png"></p>
</li>
</ol>
<ul>
<li>可以应用VPC对等来创建共享服务或使用本地实例执行身份验证</li>
<li>这将有助于创建单个联系，并将VPN连接限制到单个帐户或VPC<h2 id="VPC-VPN-Connections-amp-CloudHub"><a href="#VPC-VPN-Connections-amp-CloudHub" class="headerlink" title="VPC VPN Connections &amp; CloudHub"></a>VPC VPN Connections &amp; CloudHub</h2></li>
<li>VPC  VPN 连接用于将本地数据中心扩展到AWS云中</li>
<li>通过IPSec技术实现安全连接</li>
<li>硬件VPN<ul>
<li>VPC和远程网络之间创建IPSec隧道，硬件VPN连接来建立连接</li>
<li>在VPN连接的AWS端，虚拟专用网关（VGW）提供两个VPN端点以进行自动故障转移</li>
<li>在客户端需要配置客户网关（CGW），这是VPN连接远程端的物理设备或软件应用程序</li>
</ul>
</li>
<li>AWS Direct Connect<ul>
<li>AWS Direct Connect提供从远程网络到VPC的专用专用连接</li>
<li>Direct Connect可与AWS硬件VPN连接结合使用，以创建IPsec加密连接</li>
</ul>
</li>
<li>AWS VPN CloudHub<ul>
<li>有多个远程网络（例如，多个分公司），则可以通过虚拟专用网关创建多个 AWS Site-to-Site VPN 连接，来启用这些网络之间的通信</li>
</ul>
</li>
<li>Software VPN<ul>
<li>通过在 VPC 中使用正在运行软件 VPN 设备的 Amazon EC2 实例来创建与远程网络的 VPN 连接</li>
<li>AWS 不提供或维护第三方软件 VPN 设备；但是，可以选择合作伙伴和开源社区提供的一系列产品<h3 id="Hardware-VPN"><a href="#Hardware-VPN" class="headerlink" title="Hardware VPN"></a>Hardware VPN</h3><img src="https://i.loli.net/2019/08/10/1DJ9cQhp4KTznjE.png" alt="VPN-Connection.png"><h4 id="VPN-组件"><a href="#VPN-组件" class="headerlink" title="VPN 组件"></a>VPN 组件</h4></li>
</ul>
</li>
<li>虚拟专有网关—VGW<ul>
<li>VPN连接的AWS侧的VPN集中器</li>
</ul>
</li>
<li>客户网关——CGW<ul>
<li>客户网关是连接中用户侧使用的定位标记。它可以是物理或软件设备</li>
<li>VPN连接时，会在创建两端创建VPN隧道</li>
<li>VGW不是发起者，需要CGW启动VPN连接</li>
<li>若VPN链接建立之后超过10秒的空闲连接（具体看配置属性），隧道会自动关闭。为了避免这种情况，建议用网络监控工具保持周期性的ping，例如使用IP SLA。<h4 id="VPN-配置"><a href="#VPN-配置" class="headerlink" title="VPN 配置"></a>VPN 配置</h4></li>
</ul>
</li>
</ul>
<ul>
<li>VPC包含的VGW，并且远程网络部署客户网关，必须将两者配置为启用</li>
<li>配置路由，以便来自绑定到远程网络的VPC的任何流量都路由到虚拟专用网关（VGW）</li>
<li>每个VPN都有两个与之关联的隧道，可以在客户路由器上配置，因为不是单点故障</li>
<li>可以创建到单个VPC的多个VPN连接，并且可以配置第二个CGW以创建到同一外部位置的冗余连接或创建到多个地理位置的VPN连接<h4 id="VPN-路由"><a href="#VPN-路由" class="headerlink" title="VPN 路由"></a>VPN 路由</h4></li>
</ul>
<ul>
<li>对于VPN连接，应使用的路由类型（动态或静态）更新子网的路由表</li>
<li>路由表确定网络流量的定向。 发往VPN连接的流量必须经过到虚拟专用网关</li>
<li>路由的类型（VPN的设备和型号）<ul>
<li>静态路由<ul>
<li>如果设备不支持BGP，请指定静态路由。</li>
<li>使用静态路由，可以指定应传送到虚拟专用网关的路由（IP前缀）。</li>
<li>不支持BGP的设备也可以执行运行状况检查，以帮助在需要时故障转移到第二个隧道。</li>
</ul>
</li>
</ul>
</li>
<li>BGP动态路由<ul>
<li>如果VPN设备支持边界网关协议（BGP），请使用VPN连接指定动态路由。</li>
<li>使用BGP设备时，不需要为VPN连接指定静态路由，因为设备使用BGP进行自动发现并将其路由通告给虚拟专用网关。</li>
<li>建议使用支持BGP的设备，因为BGP协议提供强大的活动检测检查，如果第一个隧道出现故障，可以帮助故障转移到第二个VPN隧道</li>
<li>只有通过BGP通告或静态路由条目的虚拟专用网关已知的IP前缀才能从VPC接收流量。</li>
<li>VGW不会路由发布在BGP之外的任何其他流量，静态路由条目或其附加的VPC CIDR<h4 id="VPN-Connection-Redundancy"><a href="#VPN-Connection-Redundancy" class="headerlink" title="VPN Connection Redundancy"></a>VPN Connection Redundancy</h4><img src="https://i.loli.net/2019/08/10/yAYVsuhQUOBLtNv.png" alt="VPN-Connection-Redundancy.png"></li>
</ul>
</li>
<li>每个VPN连接都有两个隧道，以防止VGW成为单点故障，每个隧道使用唯一的虚拟专用网关公共IP地址</li>
<li>当一个隧道变得不可用时，例如为了维护，网络流量会自动路由到特定VPN连接的可用隧道</li>
<li>为防止在客户网关不可用时丢失连接，建议使用第二个客户网关为VPC和虚拟专用网关建立第二个VPN连接</li>
<li>建议使用边界网关协议（BGP）动态路由VPN连接，以在客户网关和虚拟专用网关之间交换路由信息</li>
<li>静态路由的VPN连接需要在客户网关侧输入网络的静态路由。</li>
<li>BGP通告和静态输入的路由信息允许双方的网关确定哪些隧道可用，并在发生故障时重新路由流量<h3 id="VPN-CloudHub"><a href="#VPN-CloudHub" class="headerlink" title="VPN CloudHub"></a>VPN CloudHub</h3></li>
<li>VPN CloudHub可用于在多站点之间提供多个VPN通道安全通信</li>
<li>远程站点彼此进行通信，而不只是与 VPC 进行通信</li>
<li>VPN CloudHub 在简单的星型拓扑连接模型上操作，可以在使用或不使用 VPC 的情况下操作 VPN CloudHub。</li>
<li>这种设计适合有多间分公司和现有 Internet 连接的客户，帮助他们实施方便、潜在低成本的星型拓扑连接模型，以便在这些远程办公室之间建立主要或备用连接<br><img src="https://i.loli.net/2019/08/10/4rd7DFAWt1SvoZe.png" alt="AWS_VPN_CloudHub-diagram.png"></li>
<li>蓝色虚线表示网络远程站点之间的流量通过其VPN连接进行路由的流量通道</li>
<li>使用 AWS VPN CloudHub，必须创建具有多个客户网关的虚拟专用网关</li>
<li>每个CGW使用唯一的边界网关协议 (BGP) 自治系统编号 (ASN)</li>
<li>客户网关可通过它们的 Site-to-Site VPN 连接传播适当的路由（BGP 前缀）</li>
<li>路由通告会被每个 BGP 对等体接收并重新通告，使每个站点都可以向其他站点发送或接受数据</li>
<li>每个辐射路由必须具有唯一的ASN，并且站点不得具有重叠的IP范围</li>
<li>每个站点还可以发送和从 VPC 接收数据（与使用标准 Site-to-Site VPN 连接的方式相同）</li>
<li>使用AWS Direct Connect连接到虚拟专用网关的站点也可以是AWS VPN CloudHub的一部分</li>
<li>配置VPN CloudHub VPN<ol>
<li>创建多个客户网关，每个网关都具有网关和ASN的唯一公共IP地址</li>
<li>每个CGW到公共虚拟专用网（VGW）关创建VPN连接</li>
<li>每个VPN连接必须通告其特定的BGP路由。 VPN连接的VPN配置文件来完成<h2 id="NAT网关-vs-NAT实例"><a href="#NAT网关-vs-NAT实例" class="headerlink" title="NAT网关 vs NAT实例"></a>NAT网关 vs NAT实例</h2></li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>NAT网关</th>
<th>NAT实例</th>
</tr>
</thead>
<tbody><tr>
<td>可用性</td>
<td>高度可用。每个可用区中的 NAT 网关都采用冗余实施。在每个可用区中创建一个 NAT 网关可确保架构不依赖于可用区</td>
<td>使用脚本管理实例之间的故障转移</td>
</tr>
<tr>
<td></td>
<td>NAT网关</td>
<td>NAT实例</td>
</tr>
<tr>
<td>————-</td>
<td>————-</td>
<td>——</td>
</tr>
<tr>
<td>可用性</td>
<td>高度可用。每个可用区中的 NAT 网关都采用冗余实施。在每个可用区中创建一个 NAT 网关可确保架构不依赖于可用区</td>
<td>使用脚本管理实例之间的故障转移</td>
</tr>
<tr>
<td>带宽</td>
<td>可以扩展到 45 Gbps</td>
<td>取决于实例类型的带宽</td>
</tr>
<tr>
<td>维护</td>
<td>由 AWS 管理。不需要进行任何维护</td>
<td>自行管理，例如需要对实例安装软件更新或操作系统补丁</td>
</tr>
<tr>
<td>性能</td>
<td>软件经过优化以便处理 NAT 流量</td>
<td>由配置来执行 NAT 的通用 AMI</td>
</tr>
<tr>
<td>费用</td>
<td>费用取决于使用的 NAT 网关的数量、使用时长以及通过 NAT 网关发送的数据量</td>
<td>费用取决于使用的 NAT 实例的数量、使用时长以及实例类型和大小</td>
</tr>
<tr>
<td>类型和大小</td>
<td>整合提供；不需要选择类型或范围</td>
<td>根据的预测工作负载选择适当的实例类型和大小</td>
</tr>
<tr>
<td>公有IP地址</td>
<td>在创建时选择弹性 IP 地址以与 NAT 网关关联</td>
<td>为 NAT 实例使用弹性 IP 地址或公有 IP 地址。随时可以通过将新的弹性 IP 地址与实例关联来更改公有 IP 地址</td>
</tr>
<tr>
<td>私有IP地址</td>
<td>在创建网关时自动从子网的 IP 地址范围中选择。</td>
<td>在启动实例时，从子网的 IP 地址范围内分配特定的私有 IP 地址</td>
</tr>
<tr>
<td>安全组</td>
<td>无法与 NAT 网关关联。可以将安全组与 NAT 网关之后的资源关联，以控制入站和出站流量。</td>
<td>与NAT 实例和 NAT 实例之后的资源关联，以控制入站和出站流量。</td>
</tr>
<tr>
<td>网络 ACL</td>
<td>使用网络 ACL 控制进出NAT 网关所在子网的流量</td>
<td>使用网络 ACL 控制进出 NAT 实例所在子网的流量</td>
</tr>
<tr>
<td>流日志</td>
<td>使用流日志捕获流量。</td>
<td>使用流日志捕获流量</td>
</tr>
<tr>
<td>端口转发</td>
<td>不支持</td>
<td>手动自定义配置以支持端口转发</td>
</tr>
<tr>
<td>堡垒服务器</td>
<td>不支持</td>
<td>用作堡垒服务器</td>
</tr>
<tr>
<td>流量指标</td>
<td><a href="https://docs.aws.amazon.com/zh_cn/vpc/latest/userguide/vpc-nat-gateway-cloudwatch.html" target="_blank" rel="noopener">查看 NAT 网关的 CloudWatch 指标</a></td>
<td>查看实例的 CloudWatch 指标</td>
</tr>
<tr>
<td>超时行为</td>
<td>如果连接超时，NAT 网关向 NAT 网关后方的任何资源返回 RST 数据包，尝试继续进行连接 (它不发送 FIN 数据包)。</td>
<td>如果连接超时，NAT 实例向 NAT 实例后方的资源发送 FIN 数据包，以关闭连接</td>
</tr>
<tr>
<td>IP 分段</td>
<td>支持转发 UDP 协议的 IP 分段数据包。不支持 TCP 和 ICMP 协议的分段。将删除这些协议的分段数据包。</td>
<td>支持重组 UDP、TCP 和 ICMP 协议的 IP 分段数据包。</td>
</tr>
</tbody></table>
<h3 id="Refer"><a href="#Refer" class="headerlink" title="Refer"></a>Refer</h3><ol>
<li><a href="https://docs.aws.amazon.com/zh_cn/vpc/latest/userguide/amazon-vpc-limits.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/zh_cn/vpc/latest/userguide/amazon-vpc-limits.html</a></li>
<li>Amazon Virtual Private Cloud user guide </li>
<li>AWS Site-to-Site VPN user guide</li>
</ol>



</font>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/09/27/NoSQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/27/NoSQL/" itemprop="url">NoSQL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-27T19:28:50+08:00">
                2018-09-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdat/" itemprop="url" rel="index">
                    <span itemprop="name">bigdat</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="NoSQL兴起原因"><a href="#NoSQL兴起原因" class="headerlink" title="NoSQL兴起原因"></a>NoSQL兴起原因</h1><ol>
<li>关系数据库已经无法满足Web2.0的需求。主要表现在以下几个方面：<ul>
<li>无法满足海量数据的管理需求</li>
<li>无法满足数据高并发的需求</li>
<li>无法满足高可扩展性和高可用性的需求</li>
</ul>
</li>
<li>One size fits all”模式很难适用于截然不同的业务场景<ul>
<li>关系模型作为统一的数据模型既被用于数据分析，也被用于在线业务。但这两者一个强调高吞吐，一个强调低延时，已经演化出完全不同的架构。用同一套模型来抽象显然是不合适的</li>
<li>Hadoop就是针对数据分析</li>
<li>MongoDB、Redis等是针对在线业务，两者都抛弃了关系模型</li>
</ul>
</li>
<li>关系数据库的关键特性包括完善的事务机制和高效的查询机制。但是，关系数据库引以为傲的两个关键特性，到了Web2.0时代却成了鸡肋，主要表现在以下几个方面：<ul>
<li>Web2.0网站系统通常不要求严格的数据库事务</li>
<li>Web2.0并不要求严格的读写实时性</li>
<li>Web2.0通常不包含大量复杂的SQL查询（去结构化，存储空间换取更好的查询性能）<h1 id="NoSQL与关系型数据库的比较"><a href="#NoSQL与关系型数据库的比较" class="headerlink" title="NoSQL与关系型数据库的比较"></a>NoSQL与关系型数据库的比较</h1></li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th align="left">比较标准</th>
<th align="left">RDBMS</th>
<th align="left">NoSQL</th>
<th align="left">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="left">数据库原理</td>
<td align="left">完全支持</td>
<td align="left">部分支持</td>
<td align="left">RDBMS有关系代数理论作为基础,NoSQL没有统一的理论基础</td>
</tr>
<tr>
<td align="left">数据规模</td>
<td align="left">大</td>
<td align="left">超大</td>
<td align="left">RDBMS很难实现横向扩展，纵向扩展的空间也比较有限，性能会随着数据规模的增大而降低,NoSQL可以很容易通过添加更多设备来支持更大规模的数据</td>
</tr>
<tr>
<td align="left">数据库模式</td>
<td align="left">固定</td>
<td align="left">灵活</td>
<td align="left">RDBMS需要定义数据库模式，严格遵守数据定义和相关约束条件,NoSQL不存在数据库模式，可以自由灵活定义并存储各种不同类型的数据</td>
</tr>
<tr>
<td align="left">查询效率</td>
<td align="left">快</td>
<td align="left">可以实现高效的简单查询，但是不具备高度结构化查询等特性，复杂查询的性能不尽人意</td>
<td align="left">RDBMS借助于索引机制可以实现快速查询（包括记录查询和范围查询）NoSQL数据库没有面向复杂查询的索引，虽然NoSQL可以使用MapReduce来加速查询，但是，在复杂查询方面的性能仍然不如RDBMS</td>
</tr>
<tr>
<td align="left">一致性</td>
<td align="left">强一致性</td>
<td align="left">弱一致性</td>
<td align="left">RDBMS严格遵守事务ACID模型，可以保证事务强一致性,很多NoSQL数据库放松了对事务ACID四性的要求，而是遵守BASE模型，只能保证最终一致性</td>
</tr>
<tr>
<td align="left">数据完整性</td>
<td align="left">容易实现</td>
<td align="left">很难实现</td>
<td align="left">任何一个RDBMS都可以很容易实现数据完整性，比如通过主键或者非空约束来实现实体完整性，通过主键、外键来实现参照完整性，通过约束或者触发器来实现用户自定义完整性,但是，在NoSQL数据库却无法实现</td>
</tr>
<tr>
<td align="left">扩展性</td>
<td align="left">一般</td>
<td align="left">好</td>
<td align="left">RDBMS很难实现横向扩展，纵向扩展的空间也比较有限,NoSQL在设计之初就充分考虑了横向扩展的需求，可以很容易通过添加廉价设备实现扩展</td>
</tr>
<tr>
<td align="left">可用性</td>
<td align="left">好</td>
<td align="left">很好</td>
<td align="left">RDBMS在任何时候都以保证数据一致性为优先目标，其次才是优化系统性能，随着数据规模的增大，RDBMS为了保证严格的一致性，只能提供相对较弱的可用性,大多数NoSQL都能提供较高的可用性</td>
</tr>
<tr>
<td align="left">标准化</td>
<td align="left">是</td>
<td align="left">否</td>
<td align="left">RDBMS已经标准化（SQL）,NoSQL还没有行业标准，不同的NoSQL数据库都有自己的查询语言，很难规范应用程序接口,StoneBraker认为：NoSQL缺乏统一查询语言，将会拖慢NoSQL发展</td>
</tr>
<tr>
<td align="left">技术支持</td>
<td align="left">高</td>
<td align="left">低</td>
<td align="left">RDBMS经过几十年的发展，已经非常成熟，Oracle等大型厂商都可以提供很好的技术支持,NoSQL在技术支持方面仍然处于起步阶段，还不成熟，缺乏有力的技术支持</td>
</tr>
<tr>
<td align="left">可维护性</td>
<td align="left">复杂</td>
<td align="left">复杂</td>
<td align="left">RDBMS需要专门的数据库管理员(DBA)维护 ,NoSQL数据库虽然没有DBMS复杂，也难以维护</td>
</tr>
<tr>
<td align="left"><strong>总结</strong></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1. 关系数据库</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">优势：以完善的关系代数理论作为基础，有严格的标准，支持事务ACID四性，借助索引机制可以实现高效的查询，技术成熟，有专业公司的技术支持</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">劣势：可扩展性较差，无法较好支持海量数据存储，数据模型过于死板、无法较好支持Web2.0应用，事务机制影响了系统的整体性能等</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2. NoSQL数据库</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">优势：可以支持超大规模数据存储，灵活的数据模型可以很好地支持Web2.0应用，具有强大的横向扩展能力等</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">劣势：缺乏数学理论基础，复杂查询性能不高，大都不能实现事务强一致性，很难实现数据完整性，技术尚不成熟，缺乏专业团队的技术支持，维护较困难等</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<ul>
<li>关系数据库应用场景：电信、银行等领域的关键业务系统，需要保证强事务一致性</li>
<li>NoSQL数据库应用场景：互联网企业、传统企业的非关键业务（比如数据分析）</li>
<li>采用混合架构</li>
<li>案例：亚马逊公司就使用不同类型的数据库来支撑它的电子商务应用<ul>
<li>对于“购物篮”这种临时性数据，采用键值存储会更加高效</li>
<li>当前的产品和订单信息则适合存放在关系数据库中</li>
<li>大量的历史订单信息则适合保存在类似MongoDB的文档数据库中</li>
</ul>
</li>
</ul>
<h1 id="NoSQL的四大类型"><a href="#NoSQL的四大类型" class="headerlink" title="NoSQL的四大类型"></a>NoSQL的四大类型</h1><blockquote>
<p>NoSQL数据库虽然数量众多，但是，归结起来，典型的NoSQL数据库通常包括键值数据库、列族数据库、文档数据库和图形数据库<br><img src="https://i.loli.net/2019/08/14/kMvYIWtdT8xOosR.png" alt="NoSQL-1.png"><br><img src="https://i.loli.net/2019/08/14/p5rvDxPIwzKhVAa.png" alt="NoSQL-2.png"><br><img src="https://i.loli.net/2019/08/14/OseyBMhXY2QZjl9.jpg" alt="四类数据库.jpg"></p>
</blockquote>
<h1 id="NoSQL的三大基石"><a href="#NoSQL的三大基石" class="headerlink" title="NoSQL的三大基石"></a>NoSQL的三大基石</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/09/23/HBase/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/23/HBase/" itemprop="url">HBase</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-23T19:19:04+08:00">
                2018-09-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote>
<p>HBase是一个高可靠、高性能、面向列、可伸缩的分布式数据库，是谷歌BigTable的开源实现，主要用来存储非结构化和半结构化的松散数据。HBase的目标是处理非常庞大的表，可以通过水平扩展的方式，利用廉价计算机集群处理由超过10亿行数据和数百万列元素组成的数据表 </p>
<ul>
<li>Hadoop可以很好地解决大规模数据的离线批量处理问题，但是，受限于Hadoop MapReduce编程框架的高延迟数据处理机制，使得Hadoop无法满足大规模数据实时处理应用的需求</li>
<li>HDFS面向批量访问模式，不是随机访问模式</li>
<li>传统的通用关系型数据库无法应对在数据规模剧增时导致的系统扩展性和性能问题（分库分表也不能很好解决）</li>
<li>传统关系数据库在数据结构变化时一般需要停机维护；空列浪费存储空间</li>
<li>因此，业界出现了一类面向半结构化数据存储和处理的高可扩展、低写入/查询延迟的系统，例如，键值数据库、文档数据库和列族数据库（如BigTable和HBase等）</li>
<li>HBase已经成功应用于互联网服务领域和传统行业的众多在线式数据分析处理系统中</li>
</ul>
</blockquote>
<h2 id="HBase与传统关系数据库的对比分析"><a href="#HBase与传统关系数据库的对比分析" class="headerlink" title="HBase与传统关系数据库的对比分析"></a>HBase与传统关系数据库的对比分析</h2><ol>
<li>数据类型：关系数据库采用关系模型，具有丰富的数据类型和存储方式，HBase则采用了更加简单的数据模型，它把数据存储为未经解释的字符串</li>
<li>数据操作：关系数据库中包含了丰富的操作，其中会涉及复杂的多表连接。HBase操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、清空等，因为HBase在设计上就避免了复杂的表和表之间的关系</li>
<li>存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的，每个列族都由几个文件保存，不同列族的文件是分离的</li>
<li>数据索引：关系数据库通常可以针对不同列构建复杂的多个索引，以提高数据访问性能。HBase只有一个索引——行键，通过巧妙的设计，HBase中的所有访问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来</li>
<li>数据维护：在关系数据库中，更新操作会用最新的当前值去替换记录中原来的旧值，旧值被覆盖后就不会存在。而在HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留</li>
<li>可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。相反，HBase和BigTable这些分布式数据库就是为了实现灵活的水平扩展而开发的，能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩</li>
</ol>
<h1 id="HBase访问接口"><a href="#HBase访问接口" class="headerlink" title="HBase访问接口"></a>HBase访问接口</h1><table>
<thead>
<tr>
<th>类型</th>
<th>特点</th>
<th>场合</th>
</tr>
</thead>
<tbody><tr>
<td>Native Java API</td>
<td>最常规和高效的访问方式</td>
<td>适合Hadoop MapReduce作业并行批处理HBase表数据</td>
</tr>
<tr>
<td>HBase Shell</td>
<td>HBase的命令行工具，最简单的接口</td>
<td>适合HBase管理使用</td>
</tr>
<tr>
<td>Thrift Gateway</td>
<td>利用Thrift序列化技术，支持C++、PHP、Python等多种语言</td>
<td>适合其他异构系统在线访问HBase表数据</td>
</tr>
<tr>
<td>REST Gateway</td>
<td>解除了语言限制</td>
<td>支持REST风格的Http API访问HBase</td>
</tr>
<tr>
<td>Pig</td>
<td>使用Pig Latin流式编程语言来处理HBase中的数据</td>
<td>适合做数据统计</td>
</tr>
<tr>
<td>Hive</td>
<td>简单</td>
<td>当需要以类似SQL语言方式来访问HBase的时候</td>
</tr>
</tbody></table>
<h1 id="Hbase数据模型"><a href="#Hbase数据模型" class="headerlink" title="Hbase数据模型"></a>Hbase数据模型</h1><h2 id="数据模型概述"><a href="#数据模型概述" class="headerlink" title="数据模型概述"></a>数据模型概述</h2><ul>
<li>HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限定符和时间戳</li>
<li>每个值是一个未经解释的字符串，没有数据类型</li>
<li>用户在表中存储数据，每一行都有一个可排序的行键和任意多的列</li>
<li>表在水平方向由一个或者多个列族组成，一个列族中可以包含任意多个列，同一个列族里面的数据存储在一起</li>
<li>列族支持动态扩展，可以很轻松地添加一个列族或列，无需预先定义列的数量以及类型，所有列均以字符串形式存储，用户需要自行进行据类型转换</li>
<li>HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留（这是和HDFS只允许追加不允许修改的特性相关的）<h2 id="数据模型相关概念"><a href="#数据模型相关概念" class="headerlink" title="数据模型相关概念"></a>数据模型相关概念</h2><img src="https://i.loli.net/2019/08/14/N3DW2LA4kxIYuFa.png" alt="HBase数据模型.png"></li>
<li>表：HBase采用表来组织数据，表由行和列组成，列划分为若干个列族</li>
<li>行：每个HBase表都由若干行组成，每个行由行键（row key）来标识。</li>
<li>列族：一个HBase表被分组成许多“列族”（Column Family）的集合，它是基本的访问控制单元</li>
<li>列限定符：列族里的数据通过列限定符（或列）来定位</li>
<li>单元格：在HBase表中，通过行、列族和列限定符确定一个“单元格”（cell），单元格中存储的数据没有数据类型，总被视为字节数组byte[]</li>
<li>时间戳：每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引</li>
</ul>
<h2 id="数据坐标"><a href="#数据坐标" class="headerlink" title="数据坐标"></a>数据坐标</h2><ul>
<li>HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“四维坐标”，即[行键, 列族, 列限定符, 时间戳]<table>
<thead>
<tr>
<th><strong>键</strong></th>
<th><strong>值</strong></th>
</tr>
</thead>
<tbody><tr>
<td>[“201505003”, “Info”, “email”, 1174184619081]</td>
<td>“xie@qq.com”</td>
</tr>
<tr>
<td>[“201505003”, “Info”, “email”, 1174184620720]</td>
<td>“you@163.com”</td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="概念视图"><a href="#概念视图" class="headerlink" title="概念视图"></a>概念视图</h2><table>
<thead>
<tr>
<th>行键</th>
<th>时间戳</th>
<th>列族contents</th>
<th>列族anchor</th>
</tr>
</thead>
<tbody><tr>
<td>“com.cnn.www”</td>
<td>t5</td>
<td>anchor:cnnsi.com=”CNN”</td>
<td></td>
</tr>
<tr>
<td>t4</td>
<td>anchor:my.look.ca=”CNN.com”</td>
<td></td>
<td></td>
</tr>
<tr>
<td>t3</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
<td></td>
</tr>
<tr>
<td>t2</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
<td></td>
</tr>
<tr>
<td>t1</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="物理视图"><a href="#物理视图" class="headerlink" title="物理视图"></a>物理视图</h2><table>
<thead>
<tr>
<th>行键</th>
<th>时间戳</th>
<th>列族contents</th>
</tr>
</thead>
<tbody><tr>
<td>“com.cnn.www”</td>
<td>t3</td>
<td>contents:html=”<html>...“</html></td>
</tr>
<tr>
<td>t2</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
</tr>
<tr>
<td>t1</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>行键</th>
<th>时间戳</th>
<th>列族anchor</th>
</tr>
</thead>
<tbody><tr>
<td>“com.cnn.www”</td>
<td>t5</td>
<td>anchor:cnnsi.com=”CNN”</td>
</tr>
<tr>
<td>t4</td>
<td>anchor:my.look.ca=”CNN.com”</td>
<td></td>
</tr>
</tbody></table>
<h2 id="面向列的存储"><a href="#面向列的存储" class="headerlink" title="面向列的存储"></a>面向列的存储</h2><p><img src="https://i.loli.net/2019/08/14/CrtHkdTRqnQeKZ3.png" alt="面向列的存储.png"><br><img src="https://i.loli.net/2019/08/14/296eZVrmyGhSgE8.png" alt="列式存储.png"><br><img src="https://i.loli.net/2019/08/14/Pun632tgqSbTJpM.png" alt="行式存储.png"></p>
<h1 id="HBase实现原理"><a href="#HBase实现原理" class="headerlink" title="HBase实现原理"></a>HBase实现原理</h1><h2 id="HBase-功能组件"><a href="#HBase-功能组件" class="headerlink" title="HBase 功能组件"></a>HBase 功能组件</h2><ul>
<li>HBase的实现包括三个主要的功能组件：<ol>
<li>库函数：链接到每个客户端</li>
<li>一个Master主服务器</li>
<li>许多个Region服务器</li>
</ol>
</li>
<li>主服务器Master负责管理和维护HBase表的分区信息，维护Region服务器列表，分配Region，负载均衡</li>
<li>Region服务器负责存储和维护分配给自己的Region，处理来自客户端的读写请求</li>
<li>客户端并不是直接从Master主服务器上读取数据，而是在获得Region的存储位置信息后，直接从Region服务器上读取数据</li>
<li>客户端并不依赖Master，而是通过Zookeeper来获得Region位置信息，大多数客户端甚至从来不和Master通信，这种设计方式使得Master负载很小 </li>
</ul>
<h2 id="表和Region"><a href="#表和Region" class="headerlink" title="表和Region"></a>表和Region</h2><ul>
<li>开始只有一个Region，后来不断分裂</li>
<li>Region拆分操作非常快，接近瞬间，因为拆分之后的Region读取的仍然是原存储文件，直到“合并”过程把存储文件异步地写到独立的文件之后，才会读取新文件<br><img src="https://i.loli.net/2019/08/14/67qygZGCpdfDHY4.jpg" alt="Region表.jpg"><br><img src="https://i.loli.net/2019/08/14/kKYREnvAGqcCP65.jpg" alt="Region表分裂.jpg"></li>
<li>每个Region默认大小是100MB到200MB（2006年以前的硬件配置）<ul>
<li>每个Region的最佳大小取决于单台服务器的有效处理能力</li>
<li>目前每个Region最佳大小建议1GB-2GB（2013年以后的硬件配置）</li>
</ul>
</li>
<li>同一个Region不会被分拆到多个Region服务器</li>
<li>每个Region服务器存储10-1000个Region<br><img src="https://i.loli.net/2019/08/14/kDWwbKAnXqZs1xI.jpg" alt="Region表分布.jpg"></li>
</ul>
<h2 id="Region-定位"><a href="#Region-定位" class="headerlink" title="Region 定位"></a>Region 定位</h2><ul>
<li>元数据表，又名.META.表，存储了Region和Region服务器的映射关系</li>
<li>当HBase表很大时， .META.表也会被分裂成多个Region</li>
<li>根数据表，又名-ROOT-表，记录所有元数据的具体位置</li>
<li>-ROOT-表只有唯一一个Region，名字是在程序中被写死的</li>
<li>Zookeeper文件记录了-ROOT-表的位置<br><img src="https://i.loli.net/2019/08/14/Z3FcJ1iXt7xrKTq.jpg" alt="HBase三层结构1.jpg"></li>
</ul>
<table>
<thead>
<tr>
<th>层次</th>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>第一层</td>
<td>Zookeeper文件</td>
<td>记录了-ROOT-表的位置信息</td>
</tr>
<tr>
<td>第二层</td>
<td>-ROOT-表</td>
<td>记录了.META.表的Region位置信息</td>
</tr>
<tr>
<td>-ROOT-表只能有一个Region。通过-ROOT-表，就可以访问.META.表中的数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>第三层</td>
<td>.META.表</td>
<td>记录了用户数据表的Region位置信息，.META.表可以有多个Region，保存了HBase中所有用户数据表的Region位置信息</td>
</tr>
</tbody></table>
<ul>
<li>为了加快访问速度，.META.表的全部Region都会被保存在内存中</li>
<li>假设.META.表的每行（一个映射条目）在内存中大约占用1KB，并且每个Region限制为128MB，那么，上面的三层结构可以保存的用户数据表的Region数目的计算方法是：</li>
<li>（-ROOT-表能够寻址的.META.表的Region个数）×（每个.META.表的 Region可以寻址的用户数据表的Region个数）</li>
<li>一个-ROOT-表最多只能有一个Region，也就是最多只能有128MB，按照每行（一个映射条目）占用1KB内存计算，128MB空间可以容纳128MB/1KB=217行，也就是说，一个-ROOT-表可以寻址217个.META.表的Region。</li>
<li>同理，每个.META.表的 Region可以寻址的用户数据表的Region个数是128MB/1KB=217。</li>
<li>最终，三层结构可以保存的Region数目是(128MB/1KB) × (128MB/1KB) = 234个Region</li>
</ul>
<h3 id="客户端访问数据时的“三级寻址”"><a href="#客户端访问数据时的“三级寻址”" class="headerlink" title="客户端访问数据时的“三级寻址”"></a>客户端访问数据时的“三级寻址”</h3><ul>
<li>为了加速寻址，客户端会缓存位置信息，同时，需要解决缓存失效问题</li>
<li>寻址过程客户端只需要询问Zookeeper服务器，不需要连接Master服务器</li>
</ul>
<h1 id="HBase运行机制"><a href="#HBase运行机制" class="headerlink" title="HBase运行机制"></a>HBase运行机制</h1><h2 id="HBase系统架构"><a href="#HBase系统架构" class="headerlink" title="HBase系统架构"></a>HBase系统架构</h2><p><img src="https://i.loli.net/2019/08/14/68D2kyjXOWYxwRQ.jpg" alt="HBase系统架构.jpg"></p>
<ol>
<li>客户端</li>
</ol>
<ul>
<li>客户端包含访问HBase的接口，同时在缓存中维护着已经访问过的Region位置信息，用来加快后续数据访问过程</li>
</ul>
<ol start="2">
<li>Zookeeper服务器</li>
</ol>
<ul>
<li>Zookeeper可以帮助选举出一个Master作为集群的总管，并保证在任何时刻总有唯一一个Master在运行，这就避免了Master的“单点失效”问题</li>
<li>Zookeeper是一个很好的集群管理工具，被大量用于分布式计算，提供配置维护、域名服务、分布式同步、组服务等。</li>
</ul>
<p><img src="https://i.loli.net/2019/08/14/nd9wWM5jDcLrSGF.jpg" alt="Zookeeper .jpg"></p>
<ol start="3">
<li>Master</li>
</ol>
<ul>
<li>主服务器Master主要负责表和Region的管理工作：<ul>
<li>管理用户对表的增加、删除、修改、查询等操作</li>
<li>实现不同Region服务器之间的负载均衡</li>
<li>在Region分裂或合并后，负责重新调整Region的分布</li>
<li>对发生故障失效的Region服务器上的Region进行迁移</li>
</ul>
</li>
</ul>
<ol start="4">
<li>Region服务器</li>
</ol>
<ul>
<li>Region服务器是HBase中最核心的模块，负责维护分配给自己的Region，并响应用户的读写请求</li>
</ul>
<h2 id="Region服务器工作原理"><a href="#Region服务器工作原理" class="headerlink" title="Region服务器工作原理"></a>Region服务器工作原理</h2><p><img src="https://i.loli.net/2019/08/14/zRVdymofpnXAkY6.jpg" alt="Region服务器向HDFS文件系统中读写数据 .jpg"></p>
<ol>
<li>用户读写数据过程<ul>
<li>用户写入数据时，被分配到相应Region服务器去执行</li>
<li>用户数据首先被写入到MemStore和Hlog中</li>
<li>只有当操作写入Hlog之后，commit()调用才会将其返回给客户端</li>
<li>当用户读取数据时，Region服务器会首先访问MemStore缓存，如果找不到，再去磁盘上面的StoreFile中寻找</li>
</ul>
</li>
<li>缓存的刷新<ul>
<li>系统会周期性地把MemStore缓存里的内容刷写到磁盘的StoreFile文件中，清空缓存，并在Hlog里面写入一个标记</li>
<li>每次刷写都生成一个新的StoreFile文件，因此，每个Store包含多个StoreFile文件</li>
<li>每个Region服务器都有一个自己的HLog 文件，每次启动都检查该文件，确认最近一次执行缓存刷新操作之后是否发生新的写入操作；如果发现更新，则先写入MemStore，再刷写到StoreFile，最后删除旧的Hlog文件，开始为用户提供服务</li>
</ul>
</li>
<li>StoreFile的合并<ul>
<li>每次刷写都生成一个新的StoreFile，数量太多，影响查找速度</li>
<li>调用Store.compact()把多个合并成一个</li>
<li>合并操作比较耗费资源，只有数量达到一个阈值才启动合并</li>
</ul>
</li>
</ol>
<h2 id="Store工作原理"><a href="#Store工作原理" class="headerlink" title="Store工作原理"></a>Store工作原理</h2><ul>
<li>Store是Region服务器的核心</li>
<li>多个StoreFile合并成一个</li>
<li>单个StoreFile过大时，又触发分裂操作，1个父Region被分裂成两个子Region<br><img src="https://i.loli.net/2019/08/14/8O5SjMrPXwiKYtB.jpg" alt="Store是Region服务器的核心 .jpg"></li>
</ul>
<h2 id="HLog工作原理"><a href="#HLog工作原理" class="headerlink" title="HLog工作原理"></a>HLog工作原理</h2><ul>
<li>分布式环境必须要考虑系统出错。HBase采用HLog保证系统恢复</li>
<li>HBase系统为每个Region服务器配置了一个HLog文件，它是一种预写式日志（Write Ahead Log）</li>
<li>用户更新数据必须首先写入日志后，才能写入MemStore缓存，并且，直到MemStore缓存内容对应的日志已经写入磁盘，该缓存内容才能被刷写到磁盘</li>
<li>Zookeeper会实时监测每个Region服务器的状态，当某个Region服务器发生故障时，Zookeeper会通知Master</li>
<li>Master首先会处理该故障Region服务器上面遗留的HLog文件，这个遗留的HLog文件中包含了来自多个Region对象的日志记录</li>
<li>系统会根据每条日志记录所属的Region对象对HLog数据进行拆分，分别放到相应Region对象的目录下，然后，再将失效的Region重新分配到可用的Region服务器中，并把与该Region对象相关的HLog日志记录也发送给相应的Region服务器</li>
<li>Region服务器领取到分配给自己的Region对象以及与之相关的HLog日志记录以后，会重新做一遍日志记录中的各种操作，把日志记录中的数据写入到MemStore缓存中，然后，刷新到磁盘的StoreFile文件中，完成数据恢复</li>
<li>共用日志优点：提高对表的写操作性能；缺点：恢复时需要分拆日志</li>
</ul>
<h1 id="HBase应用方案"><a href="#HBase应用方案" class="headerlink" title="HBase应用方案"></a>HBase应用方案</h1><h2 id="HBase实际应用中的性能优化方法"><a href="#HBase实际应用中的性能优化方法" class="headerlink" title="HBase实际应用中的性能优化方法"></a>HBase实际应用中的性能优化方法</h2><h3 id="行健（Row-Key）"><a href="#行健（Row-Key）" class="headerlink" title="行健（Row Key）"></a>行健（Row Key）</h3><ul>
<li>行键是按照字典序存储，因此，设计行键时，要充分利用这个排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放在一块。</li>
<li>举个例子：如果最近写入HBase表中的数据是最可能被访问的，可以考虑将时间戳作为行键的一部分，由于是字典序排序，所以可以使用Long.MAX_VALUE - timestamp作为行键，这样能保证新写入的数据在读取时可以被快速命中。<h3 id="Inmemory"><a href="#Inmemory" class="headerlink" title="Inmemory"></a>Inmemory</h3></li>
<li>创建表的时候，可以通过HColumnDescriptor.setInMemory(true)将表放到Region服务器的缓存中，保证在读取的时候被cache命中。<h3 id="Max-Version"><a href="#Max-Version" class="headerlink" title="Max Version"></a>Max Version</h3></li>
<li>创建表的时候，可以通过HColumnDescriptor.setMaxVersions(int maxVersions)设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置setMaxVersions(1)。<h3 id="Time-To-Live"><a href="#Time-To-Live" class="headerlink" title="Time To Live"></a>Time To Live</h3></li>
<li>创建表的时候，可以通过HColumnDescriptor.setTimeToLive(int timeToLive)设置表中数据的存储生命期，过期数据将自动被删除，例如如果只需要存储最近两天的数据，那么可以设置setTimeToLive(2 * 24 * 60 * 60)。<h2 id="HBase性能监视"><a href="#HBase性能监视" class="headerlink" title="HBase性能监视"></a>HBase性能监视</h2></li>
<li>Master-status(自带)</li>
<li>Ambari</li>
<li>OpenTSDB</li>
<li>Ganglia<h2 id="在HBase之上构建SQL引擎"><a href="#在HBase之上构建SQL引擎" class="headerlink" title="在HBase之上构建SQL引擎"></a>在HBase之上构建SQL引擎</h2></li>
<li>Hive整合HBase</li>
<li>Phoenix<h2 id="构建HBase二级索引"><a href="#构建HBase二级索引" class="headerlink" title="构建HBase二级索引"></a>构建HBase二级索引</h2></li>
<li>HBase只有一个针对行健的索引，访问HBase表中的行，只有三种方式：<ul>
<li>通过单个行健访问</li>
<li>通过一个行健的区间来访问</li>
<li>全表扫描</li>
</ul>
</li>
<li>二级索引延展<ul>
<li>Hindex二级索引</li>
<li>HBase+Redis</li>
<li>HBase+solr</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/09/14/YARN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/14/YARN/" itemprop="url">YARN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-14T19:14:41+08:00">
                2018-09-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="MapReduce-1-0-缺陷"><a href="#MapReduce-1-0-缺陷" class="headerlink" title="MapReduce 1.0 缺陷"></a>MapReduce 1.0 缺陷</h2><ol>
<li>存在单点故障</li>
<li>JobTracker“大包大揽”导致任务过重（任务多时内存开销大，上限4000节点）</li>
<li>容易出现内存溢出（分配资源只考虑MapReduce任务数，不考虑CPU、内存）</li>
<li>资源划分不合理（强制划分为slot ，包括Map slot和Reduce slot）<br><img src="https://i.loli.net/2019/08/14/N3suO6efTaCHiRJ.png" alt="MapReduce.png"><h2 id="YARN设计思路"><a href="#YARN设计思路" class="headerlink" title="YARN设计思路"></a>YARN设计思路</h2><img src="https://i.loli.net/2019/08/14/a3U6zutpq842PxB.jpg" alt="YARN思想.jpg"></li>
</ol>
<ul>
<li>MapReduce1.0既是一个计算框架，也是一个资源管理调度框架</li>
<li>到了Hadoop2.0以后，MapReduce1.0中的资源管理调度功能，被单独分离出来形成了YARN，它是一个<strong><font color="red">纯粹的资源管理调度框架</font></strong>，而不是一个计算框架</li>
<li>被剥离了资源管理调度功能的MapReduce 框架就变成了MapReduce2.0，它是运行在YARN之上的一个纯粹的计算框架，不再自己负责资源调度管理服务，而是由YARN为其提供资源管理调度服务<h2 id="YARN体系结构"><a href="#YARN体系结构" class="headerlink" title="YARN体系结构"></a>YARN体系结构</h2></li>
</ul>
<p><img src="https://i.loli.net/2019/08/14/3PfAOUQlqIabNdg.jpg" alt="YARN体系结构.jpg"></p>
<ul>
<li>ResourceManager<ul>
<li>处理客户端请求</li>
<li>启动/监控ApplicationMaster</li>
<li>监控NodeManager</li>
<li>资源分配与调度</li>
</ul>
</li>
<li>ApplicationMaster<ul>
<li>为应用程序申请资源，并分配给内部任务</li>
<li>任务调度、监控与容错</li>
</ul>
</li>
<li>NodeManager<ul>
<li>单个节点上的资源管理</li>
<li>处理来自ResourceManger的命令</li>
<li>处理来自ApplicationMaster的命令</li>
</ul>
</li>
</ul>
<h3 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h3><ul>
<li>ResourceManager（RM）是一个全局的资源管理器，负责整个系统的资源管理和分配，主要包括两个组件，即调度器（Scheduler）和应用程序管理器（Applications Manager）</li>
<li>调度器接收来自ApplicationMaster的应用程序资源请求，把集群中的资源以“容器”的形式分配给提出申请的应用程序，容器的选择通常会考虑应用程序所要处理的数据的位置，进行就近选择，从而实现“计算向数据靠拢”</li>
<li>容器（Container）作为动态资源分配单位，每个容器中都封装了一定数量的CPU、内存、磁盘等资源，从而限定每个应用程序可以使用的资源量</li>
<li>调度器被设计成是一个可插拔的组件，YARN不仅自身提供了许多种直接可用的调度器，也允许用户根据自己的需求重新设计调度器</li>
<li>应用程序管理器（Applications Manager）负责系统中所有应用程序的管理工作，主要包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动等</li>
</ul>
<h3 id="ApplicatonMaster"><a href="#ApplicatonMaster" class="headerlink" title="ApplicatonMaster"></a>ApplicatonMaster</h3><p>ResourceManager接收用户提交的作业，按照作业的上下文信息以及从NodeManager收集来的容器状态信息，启动调度过程，为用户作业启动一个ApplicationMaster</p>
<ol>
<li>当用户作业提交时，ApplicationMaster与ResourceManager协商获取资源，ResourceManager会以容器的形式为ApplicationMaster分配资源；</li>
<li>把获得的资源进一步分配给内部的各个任务（Map任务或Reduce任务），实现资源的“二次分配”；</li>
<li>与NodeManager保持交互通信进行应用程序的启动、运行、监控和停止，监控申请到的资源的使用情况，对所有任务的执行进度和状态进行监控，并在任务发生失败时执行失败恢复（即重新申请资源重启任务）；</li>
<li>定时向ResourceManager发送“心跳”消息，报告资源的使用情况和应用的进度信息；</li>
<li>当作业完成时，ApplicationMaster向ResourceManager注销容器，执行周期完成。</li>
</ol>
<h3 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h3><p>NodeManager是驻留在一个YARN集群中的每个节点上的代理，主要负责：</p>
<ul>
<li>容器生命周期管理</li>
<li>监控每个容器的资源（CPU、内存等）使用情况</li>
<li>跟踪节点健康状况</li>
<li>以“心跳”的方式与ResourceManager保持通信</li>
<li>向ResourceManager汇报作业的资源使用情况和每个容器的运行状态</li>
<li>接收来自ApplicationMaster的启动/停止容器的各种请求<br> 需要说明的是，NodeManager主要负责管理抽象的容器，只处理与容器相关的事情，而不具体负责每个任务（Map任务或Reduce任务）自身状态的管理，因为这些管理工作是由ApplicationMaster完成的，ApplicationMaster会通过不断与NodeManager通信来掌握各个任务的执行状态</li>
</ul>
<h3 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h3><p>在集群部署方面，YARN的各个组件是和Hadoop集群中的其他组件进行统一部署的<br><img src="https://i.loli.net/2019/08/14/e4LE8oCTpHQXWDa.jpg" alt="YARN部署.jpg"></p>
<h2 id="YARN工作流程"><a href="#YARN工作流程" class="headerlink" title="YARN工作流程"></a>YARN工作流程</h2><p><img src="https://i.loli.net/2019/08/14/yrhHzDjPWkf64bZ.jpg" alt="YARN工作流程.jpg"></p>
<ol>
<li>用户编写客户端应用程序，向YARN提交应用程序，提交的内容包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等</li>
<li>YARN中的ResourceManager负责接收和处理来自客户端的请求，为应用程序分配一个容器，在该容器中启动一个ApplicationMaster</li>
<li>ApplicationMaster被创建后会首先向ResourceManager注册</li>
<li>ApplicationMaster采用轮询的方式向ResourceManager申请资源</li>
<li>ResourceManager以“容器”的形式向提出申请的ApplicationMaster分配资源</li>
<li>在容器中启动任务（运行环境、脚本）</li>
<li>各个任务向ApplicationMaster汇报自己的状态和进度</li>
<li>应用程序运行完成后，ApplicationMaster向ResourceManager的应用程序管理器注销并关闭自己</li>
</ol>
<h2 id="YARN框架与MapReduce1-0框架的对比分析"><a href="#YARN框架与MapReduce1-0框架的对比分析" class="headerlink" title="YARN框架与MapReduce1.0框架的对比分析"></a>YARN框架与MapReduce1.0框架的对比分析</h2><ul>
<li>从MapReduce1.0框架发展到YARN框架，客户端并没有发生变化，其大部分调用API及接口都保持兼容，因此，原来针对Hadoop1.0开发的代码不用做大的改动，就可以直接放到Hadoop2.0平台上运行</li>
<li>总体而言，YARN相对于MapReduce1.0来说具有以下优势：<ul>
<li>大大减少了承担中心服务功能的ResourceManager的资源消耗</li>
<li>ApplicationMaster来完成需要大量资源消耗的任务调度和监控</li>
<li>多个作业对应多个ApplicationMaster，实现了监控分布化</li>
</ul>
</li>
<li>MapReduce1.0既是一个计算框架，又是一个资源管理调度框架，但是，只能支持MapReduce编程模型。而YARN则是一个纯粹的资源调度管理框架，在它上面可以运行包括MapReduce在内的不同类型的计算框架，只要编程实现相应的ApplicationMaster</li>
<li>YARN中的资源管理比MapReduce1.0更加高效<ul>
<li>以容器为单位，而不是以slot为单位<h2 id="YARN的发展目标"><a href="#YARN的发展目标" class="headerlink" title="YARN的发展目标"></a>YARN的发展目标</h2><img src="https://i.loli.net/2019/08/14/wzSyC8bfdBp6iMI.jpg" alt="YARN上各种计算框架.jpg"></li>
</ul>
</li>
<li><strong>YARN的目标就是实现“一个集群多个框架”</strong>即在一个集群上部署一个统一的资源调度管理框架YARN，在YARN之上可以部署其他各种计算框架</li>
<li>由YARN为这些计算框架提供统一的资源调度管理服务，并且能够根据各种计算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩</li>
<li>可以实现一个集群上的不同应用负载混搭，有效提高了集群的利用率</li>
<li>不同计算框架可以共享底层存储，避免了数据集跨集群移动</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/08/13/MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/13/MapReduce/" itemprop="url">MapReduce</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-13T19:08:03+08:00">
                2018-08-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="MapReduce模型"><a href="#MapReduce模型" class="headerlink" title="MapReduce模型"></a>MapReduce模型</h2><ul>
<li>MapReduce将复杂的、运行于大规模集群上的并行计算过程高度地抽象到了两个函数：Map和Reduce</li>
<li>编程容易，不需要掌握分布式并行编程细节，也可以很容易把自己的程序运行在分布式系统上，完成海量数据的计算</li>
<li>MapReduce采用<font color="red"><strong>“分而治之”</strong></font>策略，一个存储在分布式文件系统中的大规模数据集，会被切分成许多独立的分片（split），这些分片可以被多个Map任务并行处理</li>
<li>MapReduce设计的一个理念就是<font color="red"><strong>“计算向数据靠拢”</strong></font>，而不是“数据向计算靠拢”，因为，移动数据需要大量的网络传输开销</li>
<li>MapReduce框架采用了Master/Slave架构，包括一个Master和若干个Slave。Master上运行JobTracker，Slave上运行TaskTracker </li>
<li>Hadoop框架是用Java实现的，但是，MapReduce应用程序则不一定要用Java来写 </li>
</ul>
<h2 id="Map和Reduce函数"><a href="#Map和Reduce函数" class="headerlink" title="Map和Reduce函数"></a>Map和Reduce函数</h2><table>
<thead>
<tr>
<th>函数</th>
<th>输入</th>
<th>输出</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td>Map</td>
<td>&lt;k1,v1&gt;如：&lt;行号,”a b c”&gt;</td>
<td>List(&lt;k2,v2&gt;)如：&lt;“a”,1&gt;&lt;“b”,1&gt; &lt;“c”,1&gt;</td>
<td align="left">1.将小数据集进一步解析成一批&lt;key,value&gt;对，输入Map函数中进行处理 2.每一个输入的&lt;k1,v1&gt;会输出一批&lt;k2,v2&gt;。&lt;k2,v2&gt;是计算的中间结果</td>
</tr>
<tr>
<td>Reduce</td>
<td>&lt;k2,List(v2)&gt; 如：&lt;“a”,&lt;1,1,1&gt;&gt;</td>
<td>&lt;k3,v3&gt; &lt;“a”,3&gt;</td>
<td align="left">输入的中间结果&lt;k2,List(v2)&gt;中的List(v2)表示是一批属于同一个k2的value</td>
</tr>
</tbody></table>
<h2 id="MapReduce的体系结构"><a href="#MapReduce的体系结构" class="headerlink" title="MapReduce的体系结构"></a>MapReduce的体系结构</h2><p>MapReduce体系结构主要由四个部分组成，分别是：Client、JobTracker、TaskTracker以及Task<br><img src="https://i.loli.net/2019/08/14/N3suO6efTaCHiRJ.png" alt="MapReduce.png"></p>
<h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><ul>
<li>用户编写的MapReduce程序通过Client提交到JobTracker端</li>
<li>用户可通过Client提供的一些接口查看作业运行状态<h3 id="JobTracker"><a href="#JobTracker" class="headerlink" title="JobTracker"></a>JobTracker</h3></li>
<li>JobTracker负责资源监控和作业调度</li>
<li>JobTracker 监控所有TaskTracker与Job的健康状况，一旦发现失败，就将相应的任务转移到其他节点</li>
<li>JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源<h3 id="TaskTracker"><a href="#TaskTracker" class="headerlink" title="TaskTracker"></a>TaskTracker</h3></li>
<li>TaskTracker 会周期性地通过“心跳”将本节点上资源的使用情况和任务的运行进度汇报给JobTracker，同时接收JobTracker 发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）</li>
<li>TaskTracker 使用“slot”等量划分本节点上的资源量（CPU、内存等）。一个Task 获取到一个slot 后才有机会运行，而Hadoop调度器的作用就是将各个TaskTracker上的空闲slot分配给Task使用。slot 分为Map slot 和Reduce slot 两种，分别供MapTask 和Reduce Task 使用<h3 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h3></li>
<li>Task 分为Map Task 和Reduce Task 两种，均由TaskTracker 启动</li>
</ul>
<h2 id="MapReduce工作流程"><a href="#MapReduce工作流程" class="headerlink" title="MapReduce工作流程"></a>MapReduce工作流程</h2><h3 id="工作流程概述"><a href="#工作流程概述" class="headerlink" title="工作流程概述"></a>工作流程概述</h3><p><img src="https://i.loli.net/2019/08/14/6aMxLNtEWOicV5P.jpg" alt="MapReduce工作流程.jpg"></p>
<ul>
<li>不同的Map任务之间不会进行通信</li>
<li>不同的Reduce任务之间也不会发生任何信息交换</li>
<li>用户不能显式地从一台机器向另一台机器发送消息</li>
<li>所有的数据交换都是通过MapReduce框架自身去实现的<h3 id="MapReduce各个执行阶段"><a href="#MapReduce各个执行阶段" class="headerlink" title="MapReduce各个执行阶段"></a>MapReduce各个执行阶段</h3><img src="https://i.loli.net/2019/08/14/7GtfeaTjuilJyAC.jpg" alt="MapReduce各个阶段.jpg"><h4 id="关于Spilt（分片）"><a href="#关于Spilt（分片）" class="headerlink" title="关于Spilt（分片）"></a>关于Spilt（分片）</h4><img src="https://i.loli.net/2019/08/14/iBMRf2n7VOW5c9U.jpg" alt="Spilt分片.jpg"><br>HDFS 以固定大小的block 为基本单位存储数据，而对于MapReduce 而言，其处理单位是split。split 是一个逻辑概念，它只包含一些元数据信息，比如数据起始位置、数据长度、数据所在节点等。它的划分方法完全由用户自己决定。<h4 id="Map任务数量"><a href="#Map任务数量" class="headerlink" title="Map任务数量"></a>Map任务数量</h4></li>
<li>Hadoop为每个split创建一个Map任务，split 的多少决定了Map任务的数目。大多数情况下，理想的分片大小是一个HDFS块<h4 id="Reduce任务数量"><a href="#Reduce任务数量" class="headerlink" title="Reduce任务数量"></a>Reduce任务数量</h4></li>
<li>最优的Reduce任务个数取决于集群中可用的reduce任务槽(slot)的数目</li>
<li>通常设置比reduce任务槽数目稍微小一些的Reduce任务个数（这样可以预留一些系统资源处理可能发生的错误）<h3 id="Shuffle过程详解"><a href="#Shuffle过程详解" class="headerlink" title="Shuffle过程详解"></a>Shuffle过程详解</h3></li>
</ul>
<ol>
<li>Shuffle过程简介<br><img src="https://i.loli.net/2019/08/14/3NpMWh6L41Dz9IQ.jpg" alt="shuffle.jpg"></li>
<li>Map端的Shuffle过程<br><img src="https://i.loli.net/2019/08/14/5mnoagOvUxbYy19.jpg" alt="Map端shuffle.jpg"></li>
</ol>
<ul>
<li>每个Map任务分配一个缓存</li>
<li>MapReduce默认100MB缓存</li>
<li>设置溢写比例0.8</li>
<li>分区默认采用哈希函数</li>
<li>排序是默认的操作</li>
<li>排序后可以合并（Combine）</li>
<li>合并不能改变最终结果</li>
<li>在Map任务全部结束之前进行归并</li>
<li>归并得到一个大的文件，放在本地磁盘</li>
<li>文件归并时，如果溢写文件数量大于预定值（默认是3）则可以再次启动Combiner，少于3不需要</li>
<li>JobTracker会一直监测Map任务的执行，并通知Reduce任务来领取数据</li>
</ul>
<p>合并（Combine）和归并（Merge）的区别：<br>两个键值对&lt;“a”,1&gt;和&lt;“a”,1&gt;，如果合并，会得到&lt;“a”,2&gt;，如果归并，会得到&lt;“a”,&lt;1,1&gt;&gt;</p>
<ol start="3">
<li>Reduce端的shuffle过程</li>
</ol>
<ul>
<li>Reduce任务通过RPC向JobTracker询问Map任务是否已经完成，若完成，则领取数据</li>
<li>Reduce领取数据先放入缓存，来自不同Map机器，先归并，再合并，写入磁盘</li>
<li>多个溢写文件归并成一个或多个大文件，文件中的键值对是排序的</li>
<li>当数据很少时，不需要溢写到磁盘，直接在缓存中归并，然后输出给Reduce<br><img src="https://i.loli.net/2019/08/14/EkQv7xD5a9YtA4F.jpg" alt="Reduce端shuffle.jpg"><h3 id="MapReduce应用程序执行过程"><a href="#MapReduce应用程序执行过程" class="headerlink" title="MapReduce应用程序执行过程"></a>MapReduce应用程序执行过程</h3><img src="https://i.loli.net/2019/08/14/KUiuB7o6pzYZeLg.jpg" alt="MapReduce执行过程.jpg"></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/08/08/HDFS-分布式文件系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/08/HDFS-分布式文件系统/" itemprop="url">HDFS-分布式文件系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-08T18:55:50+08:00">
                2018-08-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Hadoop-分布式文件系统-HDFS"><a href="#Hadoop-分布式文件系统-HDFS" class="headerlink" title="Hadoop 分布式文件系统-HDFS"></a>Hadoop 分布式文件系统-HDFS</h1><p>分布式文件系统在物理结构上是由计算机集群中的多个节点构成的，这些节点分为两类，一类叫“主节点”(Master Node)或者也被称为“名称结点”(NameNode)，另一类叫“从节点”（Slave Node）或者也被称为“数据节点”(DataNode)<br><img src="https://i.loli.net/2019/08/13/tqh4cEsCudyDOPX.jpg" alt="图片1.jpg"></p>
<h2 id="HDFS要实现的目标如下："><a href="#HDFS要实现的目标如下：" class="headerlink" title="HDFS要实现的目标如下："></a>HDFS要实现的目标如下：</h2><ul>
<li>兼容廉价的硬件设备</li>
<li>流数据读写</li>
<li>大数据集</li>
<li>简单的文件模型</li>
<li>强大的跨平台兼容性<br>HDFS在实现以上特性同时，也使得自身有一些局限性，主要包括如下几个方面：</li>
<li>不适合低延迟数据访问</li>
<li>无法高效存储大量小文件</li>
<li>不支持多用户写入及任意修改文件</li>
</ul>
<h2 id="块"><a href="#块" class="headerlink" title="块"></a>块</h2><ul>
<li>HDFS默认一个块64MB，一个文件被分成多个块，以块作为存储单位块的大小远远大于普通文件系统，可以最小化寻址开销</li>
<li>HDFS采用抽象的块概念可以带来以下几个明显的好处：<ul>
<li>支持大规模文件存储：文件以块为单位进行存储，一个大规模文件可以被分拆成若干个文件块，不同的文件块可以被分发到不同的节点上，因此，一个文件的大小不会受到单个节点的存储容量的限制，可以远远大于网络中任意节点的存储容量</li>
<li>简化系统设计：首先，大大简化了存储管理，因为文件块大小是固定的，这样就可以很容易计算出一个节点可以存储多少文件块；其次，方便了元数据的管理，元数据不需要和文件块一起存储，可以由其他系统负责管理元数据</li>
<li>适合数据备份：每个文件块都可以冗余存储到多个节点上，大大提高了系统的容错性和可用性<h2 id="HDFS主要组件的功能"><a href="#HDFS主要组件的功能" class="headerlink" title="HDFS主要组件的功能"></a>HDFS主要组件的功能</h2></li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left"><strong>NameNode</strong></th>
<th align="left"><strong>DataNode</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">存储元数据</td>
<td align="left">存储文件内容</td>
</tr>
<tr>
<td align="left">元数据保存在内存中</td>
<td align="left">文件内容保存在磁盘上</td>
</tr>
<tr>
<td align="left">保存文件，block，datanode之间的映射关系</td>
<td align="left">维护了block id 到datanode本地文件的映射关系</td>
</tr>
</tbody></table>
<h3 id="NameNode-数据结构"><a href="#NameNode-数据结构" class="headerlink" title="NameNode 数据结构"></a>NameNode 数据结构</h3><ul>
<li>在HDFS中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构，即FsImage和EditLog<ul>
<li>FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据</li>
<li>操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作</li>
</ul>
</li>
<li>名称节点记录了每个文件中各个块所在的数据节点的位置信息<br><img src="https://i.loli.net/2019/08/13/m8GYhtLoaIpbq2d.jpg" alt="图片2.jpg"><h4 id="FsImage文件"><a href="#FsImage文件" class="headerlink" title="FsImage文件"></a>FsImage文件</h4><ul>
<li>FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据</li>
<li>FsImage文件没有记录文件包含哪些块以及每个块存储在哪个数据节点。而是由名称节点把这些映射信息保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的<h4 id="名称节点启动"><a href="#名称节点启动" class="headerlink" title="名称节点启动"></a>名称节点启动</h4></li>
<li>在名称节点启动的时候，它会将FsImage文件中的内容加载到内存中，之后再执行EditLog文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。</li>
<li>一旦在内存中成功建立文件系统元数据的映射，则创建一个新的FsImage文件和一个空的EditLog文件</li>
<li>名称节点起来之后，HDFS中的更新操作会重新写到EditLog文件中，因为FsImage文件一般都很大（GB级别的很常见），如果所有的更新操作都往FsImage文件中添加，这样会导致系统运行的十分缓慢，但是，如果往EditLog文件里面写就不会这样，因为EditLog 要小很多。每次执行写操作之后，且在向客户端发送成功代码之前，edits文件都需要同步更新<h4 id="名称节点运行期间EditLog不断变大问题"><a href="#名称节点运行期间EditLog不断变大问题" class="headerlink" title="名称节点运行期间EditLog不断变大问题"></a>名称节点运行期间EditLog不断变大问题</h4></li>
<li>在名称节点运行期间，HDFS的所有更新操作都是直接写到EditLog中，久而久之， EditLog文件将会变得很大</li>
<li>虽然这对名称节点运行时候是没有什么明显影响的，但是，当名称节点重启的时候，名称节点需要先将FsImage里面的所有内容映像到内存中，然后再一条一条地执行EditLog中的记录，当EditLog文件非常大的时候，会导致名称节点启动操作非常慢，而在这段时间内HDFS系统处于安全模式，一直无法对外提供写操作，影响了用户的使用</li>
</ul>
<strong>答案：SecondaryNameNode第二名称节点</strong><h4 id="Secondary-Namenode-工作情况"><a href="#Secondary-Namenode-工作情况" class="headerlink" title="Secondary Namenode 工作情况"></a>Secondary Namenode 工作情况</h4><img src="https://i.loli.net/2019/08/13/c8lQmqSNioyRFxM.png" alt="图片3.png"><ol>
<li>SecondaryNameNode会定期和NameNode通信，请求其停止使用EditLog文件，暂时将新的写操作写到一个新的文件edit.new上来，这个操作是瞬间完成，上层写日志的函数完全感觉不到差别；</li>
<li>SecondaryNameNode通过HTTP GET方式从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下；</li>
<li>SecondaryNameNode将下载下来的FsImage载入到内存，然后一条一条地执行EditLog文件中的各项更新操作，使得内存中的FsImage保持最新；这个过程就是EditLog和FsImage文件合并；</li>
<li>SecondaryNameNode执行完（3）操作之后，会通过post方式将新的FsImage文件发送到NameNode节点上</li>
<li>NameNode将从SecondaryNameNode接收到的新的FsImage替换旧的FsImage文件，同时将edit.new替换EditLog文件，通过这个过程EditLog就变小了<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3></li>
</ol>
<ul>
<li>数据节点是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客户端或者名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的快的列表</li>
<li>每个数据节点中的数据会被保存在各自节点的本地linux文件系统中<h2 id="FDHS体系结构"><a href="#FDHS体系结构" class="headerlink" title="FDHS体系结构"></a>FDHS体系结构</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3>HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群包括一个名称节点（NameNode）和若干个数据节点（DataNode）（如图3-4所示）。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。每个数据节点的数据实际上是保存在本地Linux文件系统中的<br><img src="https://i.loli.net/2019/08/13/WG3cMdAf8KLiSHe.jpg" alt="图片4.jpg"><h3 id="命名空间管理"><a href="#命名空间管理" class="headerlink" title="命名空间管理"></a>命名空间管理</h3></li>
<li>HDFS的命名空间包含目录、文件和块</li>
<li>在HDFS1.0体系架构中，在整个HDFS集群中只有一个命名空间，并且只有唯一一个名称节点，该节点负责这个命名空间进行管理</li>
<li>HDFS使用传统的分级文件系统，因此用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录间转移文件，重命名文件等<h3 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h3></li>
<li>HDFS是一个部署在集群上的分布式文件系统，因此，很多数据需要通过网络进行传输</li>
<li>所有的HDFS通信协议都是构建在TCP/IP协议基础之上的</li>
<li>客户端通过一个可配置的端口向名称节点主动发起TCP连接，并使用客户端协议与名称节点进行交互</li>
<li>名称节点和数据节点之间则使用数据节点协议进行交互</li>
<li>客户端与数据节点的交互是通过RPC（Remote Procedure Call）来实现的。在设计上，名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求<h3 id="client"><a href="#client" class="headerlink" title="client"></a>client</h3></li>
<li>客户端是用户操作HDFS最常用的方式，HDFS在部署时都提供了客户端</li>
<li>HDFS客户端是一个库，暴露了HDFS文件系统接口，这些接口隐藏了HDFS实现中的大部分复杂性</li>
<li>严格来说，客户端并不算是HDFS的一部分</li>
<li>客户端可以支持打开、读取、写入等常见的操作，并且提供了类似Shell的命令行方式来访问HDFS中的数据</li>
<li>此外，HDFS也提供了Java API，作为应用程序访问文件系统的客户端编程接口<h3 id="HDFS体系结构的局限性"><a href="#HDFS体系结构的局限性" class="headerlink" title="HDFS体系结构的局限性"></a>HDFS体系结构的局限性</h3></li>
</ul>
</li>
</ul>
<ol>
<li>命名空间的限制：名称节点是保存在内存中的，因此，名称节点能够容纳的对象（文件、块）的个数会受到内存空间大小的限制。</li>
<li>性能的瓶颈：整个分布式文件系统的吞吐量，受限于单个名称节点的吞吐量。</li>
<li>隔离问题：由于集群中只有一个名称节点，只有一个命名空间，因此，无法对不同应用程序进行隔离。</li>
<li>集群的可用性：一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用<h2 id="HDFS存储原理"><a href="#HDFS存储原理" class="headerlink" title="HDFS存储原理"></a>HDFS存储原理</h2><h3 id="冗余数据保存"><a href="#冗余数据保存" class="headerlink" title="冗余数据保存"></a>冗余数据保存</h3>作为一个分布式文件系统，为了保证系统的容错性和可用性，HDFS采用了多副本方式对数据进行冗余存储，通常一个数据块的多个副本会被分布到不同的数据节点上，如图所示，数据块1被分别存放到数据节点A和C上，数据块2被存放在数据节点A和B上。这种多副本方式具有以下几个优点：<br><img src="https://i.loli.net/2019/08/14/o2ztn561hLSlrKw.jpg" alt="数据块副本.jpg"><ol>
<li>加快数据传输速度</li>
<li>容易检查数据错误</li>
<li>保证数据可靠性<h3 id="数据存取策略"><a href="#数据存取策略" class="headerlink" title="数据存取策略"></a>数据存取策略</h3><h4 id="数据存放"><a href="#数据存放" class="headerlink" title="数据存放"></a>数据存放</h4><img src="https://i.loli.net/2019/08/14/aehmCizsqG9dM38.jpg" alt="数据副本放置策略.jpg"></li>
</ol>
<ul>
<li>第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点</li>
<li>第二个副本：放置在与第一个副本不同的机架的节点上</li>
<li>第三个副本：与第一个副本相同机架的其他节点上</li>
<li>更多副本：随机节点<h4 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h4></li>
<li>HDFS提供了一个API可以确定一个数据节点所属的机架ID，客户端也可以调用API获取自己所属的机架ID</li>
<li>当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含了副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID，当发现某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择该副本读取数据，如果没有发现，就随机选择一个副本读取数据<h3 id="数据错误与恢复"><a href="#数据错误与恢复" class="headerlink" title="数据错误与恢复"></a>数据错误与恢复</h3>HDFS具有较高的容错性，可以兼容廉价的硬件，它把硬件出错看作一种常态，而不是异常，并设计了相应的机制检测数据错误和进行自动恢复，主要包括以下几种情形：名称节点出错、数据节点出错和数据出错。<h4 id="名称节点出错"><a href="#名称节点出错" class="headerlink" title="名称节点出错"></a>名称节点出错</h4>名称节点保存了所有的元数据信息，其中，最核心的两大数据结构是FsImage和Editlog，如果这两个文件发生损坏，那么整个HDFS实例将失效。因此，HDFS设置了备份机制，把这些核心文件同步复制到备份服务器SecondaryNameNode上。当名称节点出错时，就可以根据备份服务器SecondaryNameNode中的FsImage和Editlog数据进行恢复。<h4 id="数据节点出错"><a href="#数据节点出错" class="headerlink" title="数据节点出错"></a>数据节点出错</h4></li>
<li>每个数据节点会定期向名称节点发送“心跳”信息，向名称节点报告自己的状态</li>
<li>当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节点的心跳信息，这时，这些数据节点就会被标记为“机”，节点上面的所有数据都会被标记为“不可读”，名称节点不会再给它们发送任何I/O请求</li>
<li>这时，有可能出现一种情形，即由于一些数据节点的不可用，会导致一些数据块的副本数量小于冗余因子</li>
<li>名称节点会定期检查这种情况，一旦发现某个数据块的副本数量小于冗余因子，就会启动数据冗余复制，为它生成新的副本</li>
<li><strong>HDFS和其它分布式文件系统的最大区别就是可以调整冗余数据的位置</strong><h4 id="数据出错"><a href="#数据出错" class="headerlink" title="数据出错"></a>数据出错</h4></li>
<li>网络传输和磁盘错误等因素，都会造成数据错误</li>
<li>客户端在读取到数据后，会采用md5和sha1对数据块进行校验，以确定读取到正确的数据</li>
<li>在文件被创建时，客户端就会对每一个文件块进行信息摘录，并把这些信息写入到同一个路径的隐藏文件里面</li>
<li>当客户端读取文件的时候，会先读取该信息文件，然后，利用该信息文件对每个读取的数据块进行校验，如果校验出错，客户端就会请求到另外一个数据节点读取该文件块，并且向名称节点报告这个文件块有错误，名称节点会定期检查并且重新复制这个块<h1 id="Hadoop-HDFS-2-0"><a href="#Hadoop-HDFS-2-0" class="headerlink" title="Hadoop HDFS 2.0"></a>Hadoop HDFS 2.0</h1></li>
</ul>
</li>
</ol>
<h2 id="Hadoop-1-0-局限与不足"><a href="#Hadoop-1-0-局限与不足" class="headerlink" title="Hadoop 1.0 局限与不足"></a>Hadoop 1.0 局限与不足</h2><p>Hadoop1.0的核心组件（仅指MapReduce和HDFS，不包括Hadoop生态系统内的Pig、Hive、HBase等其他组件），主要存在以下不足：</p>
<ul>
<li>抽象层次低，需人工编码</li>
<li>表达能力有限</li>
<li>开发者自己管理作业（Job）之间的依赖关系</li>
<li>难以看到程序整体逻辑</li>
<li>执行迭代操作效率低</li>
<li>资源浪费（Map和Reduce分两阶段执行）</li>
<li>实时性差（适合批处理，不支持实时交互式）</li>
</ul>
<h2 id="自身框架改进与提升"><a href="#自身框架改进与提升" class="headerlink" title="自身框架改进与提升"></a>自身框架改进与提升</h2><table>
<thead>
<tr>
<th>组件</th>
<th>Hadoop1.0的问题</th>
<th>Hadoop2.0的改进</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>单一名称节点，存在单点失效问题</td>
<td>设计了HDFS HA，提供名称节点热备机制</td>
</tr>
<tr>
<td>HDFS</td>
<td>单一命名空间，无法实现资源隔离</td>
<td>设计了HDFS Federation，管理多个命名空间</td>
</tr>
<tr>
<td>MapReduce</td>
<td>资源管理效率低</td>
<td>设计了新的资源管理框架YARN</td>
</tr>
</tbody></table>
<h2 id="HDFS2-0的新特性"><a href="#HDFS2-0的新特性" class="headerlink" title="HDFS2.0的新特性"></a>HDFS2.0的新特性</h2><h3 id="HDFS-HA"><a href="#HDFS-HA" class="headerlink" title="HDFS HA"></a>HDFS HA</h3><ul>
<li>第二名称节点（SecondaryNameNode）无法解决单点故障问题<ul>
<li>不是热备份</li>
<li>要是防止日志文件EditLog过大，导致名称节点失败恢复时消耗过多时间</li>
<li>附带起到冷备份功能</li>
</ul>
</li>
<li>HDFS HA（High Availability）是为了解决单点故障问题</li>
<li>HA集群设置两个名称节点，“活跃（Active）”和“待命（Standby）”</li>
<li>两种名称节点的状态同步，可以借助于一个<strong>共享存储系统</strong>来实现</li>
<li>一旦活跃名称节点出现故障，就可以立即切换到待命名称节点</li>
<li>Zookeeper确保一个名称节点在对外服务</li>
<li>名称节点维护映射信息，数据节点同时向两个名称节点汇报信息<br><img src="https://i.loli.net/2019/08/14/PAzmeqEVokFUHgG.jpg" alt="HDFS HA.jpg"></li>
</ul>
<h3 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h3><h4 id="HDFS1-0中存在的问题"><a href="#HDFS1-0中存在的问题" class="headerlink" title="HDFS1.0中存在的问题"></a>HDFS1.0中存在的问题</h4><ul>
<li>单点故障问题</li>
<li>不可以水平扩展（是否可以通过纵向扩展来解决？）</li>
<li>系统整体性能受限于单个名称节点的吞吐量</li>
<li>单个名称节点难以提供不同程序之间的隔离性</li>
<li>HDFS HA是热备份，提供高可用性，但是无法解决可扩展性、系统性能和隔离性<h4 id="HDFS-Federation-设计"><a href="#HDFS-Federation-设计" class="headerlink" title="HDFS Federation 设计"></a>HDFS Federation 设计</h4></li>
<li>在HDFS Federation中，设计了多个相互独立的名称节点，使得HDFS的命名服务能够水平扩展，这些名称节点分别进行各自命名空间和块的管理，相互之间是联盟（Federation）关系，不需要彼此协调。并且向后兼容</li>
<li>HDFS Federation中，所有名称节点会共享底层的数据节点存储资源，数据节点向所有名称节点汇报</li>
<li>属于同一个命名空间的块构成一个“块池”<br><img src="https://i.loli.net/2019/08/14/WsQN43FHywPftOu.jpg" alt="HDFS Federation架构.jpg"></li>
</ul>
<h4 id="HDFS-Federation访问方式"><a href="#HDFS-Federation访问方式" class="headerlink" title="HDFS Federation访问方式"></a>HDFS Federation访问方式</h4><ul>
<li>对于Federation中的多个命名空间，可以采用客户端挂载表（Client Side Mount Table）方式进行数据共享和访问</li>
<li>客户可以访问不同的挂载点来访问不同的子命名空间</li>
<li>把各个命名空间挂载到全局“挂载表”（mount-table）中，实现数据全局共享</li>
<li>同样的命名空间挂载到个人的挂载表中，就成为应用程序可见的命名空间<h4 id="HDFS-Federation相对于HDFS1-0的优势"><a href="#HDFS-Federation相对于HDFS1-0的优势" class="headerlink" title="HDFS Federation相对于HDFS1.0的优势"></a>HDFS Federation相对于HDFS1.0的优势</h4></li>
</ul>
<ol>
<li>HDFS集群扩展性。多个名称节点各自分管一部分目录，使得一个集群可以扩展到更多节点，不再像HDFS1.0中那样由于内存的限制制约文件存储数目</li>
<li>性能更高效。多个名称节点管理不同的数据，且同时对外提供服务，将为用户提供更高的读写吞吐率</li>
<li>良好的隔离性。用户可根据需要将不同业务数据交由不同名称节点管理，这样不同业务之间影响很小</li>
</ol>
<p>需要注意的，HDFS Federation并不能解决单点故障问题，也就是说，每个名称节点都存在在单点故障问题，需要为每个名称节点部署一个后备名称节点，以应对名称节点挂掉对业务产生的影响</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/08/03/大数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/03/大数据/" itemprop="url">大数据概述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-03T22:00:08+08:00">
                2018-08-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="大数据概述"><a href="#大数据概述" class="headerlink" title="大数据概述"></a>大数据概述</h1><p>大数据思维导图(点击链可以展开详细)<br><img src="https://i.loli.net/2019/08/13/n7zpOUBKujb4tr1.png" alt="大数据 (1).png"><br>(<a href="https://www.processon.com/view/link/5b9b6867e4b06fc64af4b823" target="_blank" rel="noopener">https://www.processon.com/view/link/5b9b6867e4b06fc64af4b823</a>)</p>
<ul>
<li>数据产生方式变革<ul>
<li>运营式阶段：数据库使得数据管理复杂度降低，数据往往伴随着一定的运营活动产生记录，生产方式是被动的</li>
<li>用户原创内容阶段：Web2.0时代，用户原创成为标志，智能手机加速内容产生，数据产生方式是主动的</li>
<li>感知式系统阶段：感知系统广泛使用</li>
</ul>
</li>
<li>大数据发展历程</li>
</ul>
<table>
<thead>
<tr>
<th><strong>阶段</strong></th>
<th><strong>时间</strong></th>
<th><strong>内容</strong></th>
</tr>
</thead>
<tbody><tr>
<td>第一阶段：萌芽期</td>
<td>上世纪90年代至本世纪初</td>
<td>随着数据挖掘理论和数据库技术的逐步成熟，一批商业智能工具和知识管理技术开始被应用，如数据仓库、专家系统、知识管理系统等。</td>
</tr>
<tr>
<td>第二阶段：成熟期</td>
<td>本世纪前十年</td>
<td>Web2.0应用迅猛发展，非结构化数据大量产生，传统处理方法难以应对，带动了大数据技术的快速突破，大数据解决方案逐渐走向成熟，形成了并行计算与分布式系统两大核心技术，谷歌的GFS和MapReduce等大数据技术受到追捧，Hadoop平台开始大行其道</td>
</tr>
<tr>
<td>第三阶段：大规模应用期</td>
<td>2010年以后</td>
<td>大数据应用渗透各行各业，数据驱动决策，信息社会智能化程度大幅提高</td>
</tr>
</tbody></table>
<ul>
<li>大数据概念<ul>
<li>大量化 Volume</li>
<li>快速化 Velocity （1秒定律）</li>
<li>多样化 Variety</li>
<li>价值化  Value  价值密度低，商业价值高</li>
</ul>
</li>
<li>大数据影响<ul>
<li>科学研究：先后经历了实验、理论、计算和数据四中范式<br><img src="https://i.loli.net/2019/08/13/aFXqhifzbmRLVGK.png" alt="图片1.png"></li>
<li>思维方面（摘自《大数据时代》）<ul>
<li>全样儿非抽样</li>
<li>效率而非精确</li>
<li>相关而非因果   </li>
</ul>
</li>
</ul>
</li>
<li>大数据应用<ul>
<li>智能医疗研发</li>
<li>监控身体情况</li>
<li>研发智能汽车</li>
<li>实时掌控交通情况，改善日常生活</li>
<li>金融交易</li>
<li>业务流程优化</li>
</ul>
</li>
<li>大数据关键技术</li>
</ul>
<table>
<thead>
<tr>
<th><strong>技术层面</strong></th>
<th align="left"><strong>功能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>数据采集</td>
<td align="left">利用ETL工具将分布的、异构数据源中的数据如关系数据、平面数据文件等，抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础；或者也可以把实时采集的数据作为流计算系统的输入，进行实时处理分析</td>
</tr>
<tr>
<td>数据存储和管理</td>
<td align="left">利用分布式文件系统、数据仓库、关系数据库、NoSQL数据库、云数据库等，实现对结构化、半结构化和非结构化海量数据的存储和管理</td>
</tr>
<tr>
<td>数据处理与分析</td>
<td align="left">利用分布式并行编程模型和计算框架，结合机器学习和数据挖掘算法，实现对海量数据的处理和分析；对分析结果进行可视化呈现，帮助人们更好地理解数据、分析数据</td>
</tr>
<tr>
<td>数据隐私和安全</td>
<td align="left">在从大数据中挖掘潜在的巨大商业价值和学术价值的同时，构建隐私数据保护体系和数据安全体系，有效保护个人隐私和数据安全</td>
</tr>
</tbody></table>
<ul>
<li><p>两大核心技术<br><img src="https://i.loli.net/2019/08/13/OYDRiAm1vBK2cjw.png" alt="图片2.png"></p>
</li>
<li><p>大数据计算模式</p>
</li>
</ul>
<table>
<thead>
<tr>
<th><strong>大数据计算模式</strong></th>
<th><strong>解决问题</strong></th>
<th><strong>代表产品</strong></th>
</tr>
</thead>
<tbody><tr>
<td>批处理计算</td>
<td>针对大规模数据的批量处理</td>
<td>MapReduce、Spark等</td>
</tr>
<tr>
<td>流计算</td>
<td>针对流数据的实时计算</td>
<td>Storm、S4、Flume、Streams、Puma、DStream、Super Mario、银河流数据处理平台等</td>
</tr>
<tr>
<td>图计算</td>
<td>针对大规模图结构数据的处理</td>
<td>Pregel、GraphX、Giraph、PowerGraph、Hama、GoldenOrb等</td>
</tr>
<tr>
<td>查询分析计算</td>
<td>大规模数据的存储管理和查询分析</td>
<td>Dremel、Hive、Cassandra、Impala等</td>
</tr>
</tbody></table>
<ul>
<li>大数据产业</li>
</ul>
<table>
<thead>
<tr>
<th align="center"><strong>产业链环节</strong></th>
<th><strong>包含内容</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">IT基础设施层</td>
<td>包括提供硬件、软件、网络等基础设施以及提供咨询、规划和系统集成服务的企业，比如，提供数据中心解决方案的IBM、惠普和戴尔等，提供存储解决方案的EMC，提供虚拟化管理软件的微软、思杰、SUN、Redhat等</td>
</tr>
<tr>
<td align="center">数据源层</td>
<td>大数据生态圈里的数据提供者，是生物大数据（生物信息学领域的各类研究机构）、交通大数据（交通主管部门）、医疗大数据（各大医院、体检机构）、政务大数据（政府部门）、电商大数据（淘宝、天猫、苏宁云商、京东等电商）、社交网络大数据（微博、微信、人人网等）、搜索引擎大数据（百度、谷歌等）等各种数据的来源</td>
</tr>
<tr>
<td align="center">数据管理层</td>
<td>包括数据抽取、转换、存储和管理等服务的各类企业或产品，比如分布式文件系统（如Hadoop的HDFS和谷歌的GFS）、ETL工具（Informatica、Datastage、Kettle等）、数据库和数据仓库（Oracle、MySQL、SQL Server、HBase、GreenPlum等）</td>
</tr>
<tr>
<td align="center">数据分析层</td>
<td>包括提供分布式计算、数据挖掘、统计分析等服务的各类企业或产品，比如，分布式计算框架MapReduce、统计分析软件SPSS和SAS、数据挖掘工具Weka、数据可视化工具Tableau、BI工具（MicroStrategy、Cognos、BO）等等</td>
</tr>
<tr>
<td align="center">数据平台层</td>
<td>包括提供数据分享平台、数据分析平台、数据租售平台等服务的企业或产品，比如阿里巴巴、谷歌、中国电信、百度等</td>
</tr>
<tr>
<td align="center">数据应用层</td>
<td>提供智能交通、智慧医疗、智能物流、智能电网等行业应用的企业、机构或政府部门，比如交通主管部门、各大医疗机构、菜鸟网络、国家电网等</td>
</tr>
</tbody></table>
<ul>
<li>大数据、云计算、物联网关系</li>
</ul>
<p><img src="https://i.loli.net/2019/08/13/LNPauHj28IFpZn6.jpg" alt="图片3.jpg"></p>
<h1 id="Hadoop-概述（Hadoop-2-0）"><a href="#Hadoop-概述（Hadoop-2-0）" class="headerlink" title="Hadoop 概述（Hadoop 2.0）"></a>Hadoop 概述（Hadoop 2.0）</h1><p> Hadoop 是 Apache 基金会下的一个开源分布式计算平台，以 <strong><font color="red">HDFS 分布式文件系统</font></strong> 和 <strong><font color="red">MapReduce</font></strong> 分布式计算框架为核心，为用户提供底层细节透明的分布式基础设施。目前，Hadoop 是分析海量数据的首选工具。Hadoop 是一个可以更容易开发和并行处理大规模数据的分布式计算平台，它的主要特点是扩展能力强、成本低、高效率和可靠。目前，Hadoop 的用户已经从传统的互联网公司，扩展到了各个行业，并且得到越来越广泛的应用。它的优势包括：</p>
<ol>
<li>方便：Hadoop 可以运行在商业机器集群上，或者Amazon EC2 等云计算服务商</li>
<li>弹性：Hadoop 可以方便增加和减少集群节点</li>
<li>健壮：Hadoop 可以从容处理常见的硬件失效情况</li>
<li>简单：Hadoop 允许用户快速高效编写并行分布代码<h2 id="Hadoop-项目结构"><a href="#Hadoop-项目结构" class="headerlink" title="Hadoop 项目结构"></a>Hadoop 项目结构</h2><img src="https://i.loli.net/2019/08/13/LEQbCB2q53mphVo.png" alt="hadoop项目结构.png"></li>
</ol>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>功能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>分布式文件系统</td>
</tr>
<tr>
<td>MapReduce</td>
<td>分布式并行编程模型</td>
</tr>
<tr>
<td>YARN</td>
<td>资源管理和调度器</td>
</tr>
<tr>
<td>Tez</td>
<td>运行在YARN之上的下一代Hadoop查询处理框架</td>
</tr>
<tr>
<td>Hive</td>
<td>Hadoop上的数据仓库</td>
</tr>
<tr>
<td>HBase</td>
<td>Hadoop上的非关系型的分布式数据库</td>
</tr>
<tr>
<td>Pig</td>
<td>一个基于Hadoop的大规模数据分析平台，提供类似SQL的查询语言Pig Latin</td>
</tr>
<tr>
<td>Sqoop</td>
<td>用于在Hadoop与传统数据库之间进行数据传递</td>
</tr>
<tr>
<td>Oozie</td>
<td>Hadoop上的工作流管理系统</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>提供分布式协调一致性服务</td>
</tr>
<tr>
<td>Storm</td>
<td>流计算框架</td>
</tr>
<tr>
<td>Flume</td>
<td>一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统</td>
</tr>
<tr>
<td>Ambari</td>
<td>Hadoop快速部署工具，支持Apache Hadoop集群的供应、管理和监控</td>
</tr>
<tr>
<td>Kafka</td>
<td>一种高吞吐量的分布式发布订阅消息系统，可以处理消费者规模的网站中的所有动作流数据</td>
</tr>
<tr>
<td>Spark</td>
<td>类似于Hadoop MapReduce的通用并行框架</td>
</tr>
</tbody></table>
<ul>
<li>HDFS有着高容错特点，并且设计用来部署在低廉的硬件之上，适合有着超量大数据集的应用程序</li>
<li>MapReduce：Hadoop编程模型，用于大规模数据及（大于1TB）的并行计算。MR是离线处理框架，由编程模型、运行时环境（JobTracker和TaskTracker）和数据处理引擎（MapTask和ReduceTask）三部分组成</li>
<li>HBase:基于列存储模型的分布式数据库，专用用于Hadoop档案系统上的资料库系统，采用Column-Oriented设计，不同于传统关系型数据库，没有资料表、Schema等规范，而是采用Key-Value形式的架构，采用多维度的对应关系建立类似于表格效果的资料架构。如此采用分布式存储方式，可以扩充到前台服务器，应付PB级资料处理</li>
<li>Hive：可用SQL语法存储Hadoop资料的工具。<ul>
<li>Hive是建置在HDFS上的一套分散式资料仓储系统，可让使用者以惯用的SQL语法，来存取Hadoop档案中的大型资料集，例如可以使用Join、Group by、Order by等，而这个语法称为Hive QL。Hive 提供完整的 SQL 查询功能，可以将 SQL 语句转换为 MR 任务进行运行。不过，Hive QL和SQL并非完全相同，例如Hive就不支援Store Procedure、Trigger等功能。</li>
<li>Hive会将使用者输入的Hive QL指令编译成Java程序，再来存取HDFS档案系统上的资料，所以，执行效率依指令复杂度和处理的资料量而异，可能有数秒鐘，甚至是数分鐘的延迟。和HBase相比，Hive容易使用且弹性高，但执行速度较慢。不少资料库系统，都是透过先连结到Hive，才能与Hadoop整合。例如微软就是透过Hive ODBC驱动程序，将SQL指令转换成Hive QL，让Excel可以存取Hadoop上的资料。</li>
<li>在同一个Hadoop集群中，Hive可以存取HBase上的资料，将HBase上的资料对应成Hive内的一个表格</li>
</ul>
</li>
<li>Pig：基于Hadoop分析组件，Pig 为复杂的海量数据并行计算提供一个简易的操作和编程接口。它提供了一个Script语言Pig Latin，语法简单，类似可读性高的高阶Basic语言，可用来撰写MapReduce程序。Pig会自动将这些脚本程序转换，成为能在Hadoop中执行的MapReduce Java程序。因此，使用者即使不懂Java也能撰写出MapReduce。<br>Zookeeper：是一个高效的可扩展的资源协调系统，存储和协调关键共享状态。它监控和协调 Hadoop 分散式运作的集中式服务，可提供各个服务器的配置和运作状态资讯，用於提供不同Hadoop系统角色之间的工作协调。<ul>
<li>以HBase资料库为例，其中有两种服务器角色：Region服务器角色和Master服务器角色，系统会自动透过ZooKeeper监看Master服务器的状态，一旦Master的运作资讯消失，代表当机或网路断线，HBase就会选出另一台Region服务器成为Mater角色来负责管理工作。<ul>
<li>可等同于etcd功能</li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">seven</p>
              <p class="site-description motion-element" itemprop="description">seven 的精神家园，学习笔记</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="1988xuegang@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">seven</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
