<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="seven 的精神家园，学习笔记">
<meta name="keywords" content="云计算,大数据，kuberntes">
<meta property="og:type" content="website">
<meta property="og:title" content="岳阳北寒">
<meta property="og:url" content="http://sevengarden.club/page/2/index.html">
<meta property="og:site_name" content="岳阳北寒">
<meta property="og:description" content="seven 的精神家园，学习笔记">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="岳阳北寒">
<meta name="twitter:description" content="seven 的精神家园，学习笔记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://sevengarden.club/page/2/">





  <title>岳阳北寒</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">岳阳北寒</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">要有最朴素的生活和最遥远的梦想，即使明日天寒地冻，路远马亡.......</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-somrthing">
          <a href="/有料" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            somrthing
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/10/26/图计算/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/26/图计算/" itemprop="url">图计算</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-26T19:13:10+08:00">
                2018-10-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="图计算简介"><a href="#图计算简介" class="headerlink" title="图计算简介"></a>图计算简介</h1><h2 id="图结构数据"><a href="#图结构数据" class="headerlink" title="图结构数据"></a>图结构数据</h2><ul>
<li>许多大数据都是以大规模图或网络的形式呈现，如社交网络、传染病传播途径、交通事故对路网的影响</li>
<li>许多非图结构的大数据，也常常会被转换为图模型后进行分析</li>
<li>图数据结构很好地表达了数据之间的关联性</li>
<li>关联性计算是大数据计算的核心——通过获得数据的关联性，可以从噪音很多的海量数据中抽取有用的信息<ul>
<li>比如，通过为购物者之间的关系建模，就能很快找到口味相似的用户，并为之推荐商品</li>
<li>或者在社交网络中，通过传播关系发现意见领袖<h2 id="传统图计算解决方案的不足之处"><a href="#传统图计算解决方案的不足之处" class="headerlink" title="传统图计算解决方案的不足之处"></a>传统图计算解决方案的不足之处</h2></li>
</ul>
</li>
</ul>
<ol>
<li>常常表现出比较差的内存访问局部性</li>
<li>针对单个顶点的处理工作过少</li>
<li>计算过程中伴随着并行度的改变<h2 id="图计算通用软件"><a href="#图计算通用软件" class="headerlink" title="图计算通用软件"></a>图计算通用软件</h2></li>
</ol>
<ul>
<li>第一种主要是基于遍历算法的、实时的图数据库，如Neo4j、OrientDB、DEX和 Infinite Graph</li>
<li>第二种则是以图顶点为中心的、基于消息传递批处理的并行引擎，如GoldenOrb、Giraph、Pregel和Hama，这些图处理软件主要是基于BSP模型实现的并行图处理系统<blockquote>
<ul>
<li>一次BSP(Bulk Synchronous Parallel Computing Model，又称“大同步”模型)计算过程包括一系列全局超步（所谓的超步就是计算中的一次迭代），每个超步主要包括三个组件：</li>
</ul>
</blockquote>
</li>
<li><strong>局部计算</strong>：每个参与的处理器都有自身的计算任务，它们只读取存储在本地内存中的值，不同处理器的计算任务都是异步并且独立的</li>
<li><strong>通讯</strong>：处理器群相互交换数据，交换的形式是，由一方发起推送(put)和获取(get)操作</li>
<li><strong>栅栏同步(Barrier Synchronization)</strong>：当一个处理器遇到“路障”（或栅栏），会等到其他所有处理器完成它们的计算步骤；每一次同步也是一个超步的完成和下一个超步的开始<br><img src="https://i.loli.net/2019/08/16/CbFHOziDv5lRt3f.png" alt="一个超步的垂直结构图 .png"><br><img src="https://i.loli.net/2019/08/16/xJ7QVRDH8P1dMCY.png" alt="超同步.png"><h1 id="Pregel简介"><a href="#Pregel简介" class="headerlink" title="Pregel简介"></a>Pregel简介</h1></li>
<li>Pregel是一种基于BSP模型实现的并行图处理系统</li>
<li>为了解决大型图的分布式计算问题，Pregel搭建了一套可扩展的、有容错机制的平台，该平台提供了一套非常灵活的API，可以描述各种各样的图计算</li>
<li>Pregel作为分布式图计算的计算框架，主要用于图遍历、最短路径、PageRank计算等等<h1 id="Pregel图计算模型"><a href="#Pregel图计算模型" class="headerlink" title="Pregel图计算模型"></a>Pregel图计算模型</h1><h2 id="有向图和顶点"><a href="#有向图和顶点" class="headerlink" title="有向图和顶点"></a>有向图和顶点</h2></li>
<li>Pregel计算模型以有向图作为输入</li>
<li>有向图的每个顶点都有一个String类型的顶点ID</li>
<li>每个顶点都有一个可修改的用户自定义值与之关联</li>
<li>每条有向边都和其源顶点关联，并记录了其目标顶点ID<br><img src="https://i.loli.net/2019/08/16/gLxEuf8voYjP6Qs.png" alt="有向图和顶点.png"></li>
<li>边上有一个可修改的用户自定义值与之关联</li>
<li>在每个超步S中，图中的所有顶点都会并行执行相同的用户自定义函数</li>
<li>每个顶点可以接收前一个超步(S-1)中发送给它的消息，修改其自身及其出射边的状态，并发送消息给其他顶点，甚至是修改整个图的拓扑结构</li>
<li>在这种计算模式中，“边”并不是核心对象，在边上面不会运行相应的计算，只有顶点才会执行用户自定义函数进行相应计算<br><img src="https://i.loli.net/2019/08/16/xJ7QVRDH8P1dMCY.png" alt="超同步.png"><h2 id="顶点之间的消息传递"><a href="#顶点之间的消息传递" class="headerlink" title="顶点之间的消息传递"></a>顶点之间的消息传递</h2></li>
</ul>
<blockquote>
<ul>
<li>采用消息传递模型主要基于以下两个原因：</li>
</ul>
<ol>
<li>消息传递具有足够的表达能力，没有必要使用远程读取或共享内存的方式</li>
<li>有助于提升系统整体性能。大型图计算通常是由一个集群完成的，集群环境中执行远程数据读取会有较高的延迟；Pregel的消息模式采用异步和批量的方式传递消息，因此可以缓解远程读取的延迟<br><img src="https://i.loli.net/2019/08/16/bmZ8JU2CrKexPVa.png" alt="纯消息传递模型图 .png"></li>
</ol>
</blockquote>
<h2 id="Pregel的计算过程"><a href="#Pregel的计算过程" class="headerlink" title="Pregel的计算过程"></a>Pregel的计算过程</h2><ul>
<li>Pregel的计算过程是由一系列被称为“超步”的迭代组成的</li>
<li>在每个超步中，每个顶点上面都会并行执行用户自定义的函数，该函数描述了一个顶点V在一个超步S中需要执行的操作</li>
<li>该函数可以读取前一个超步(S-1)中其他顶点发送给顶点V的消息，执行相应计算后，修改顶点V及其出射边的状态，然后沿着顶点V的出射边发送消息给其他顶点，而且，一个消息可能经过多条边的传递后被发送到任意已知ID的目标顶点上去</li>
<li>这些消息将会在下一个超步(S+1)中被目标顶点接收，然后象上述过程一样开始下一个超步(S+1)的迭代过程<br><img src="https://i.loli.net/2019/08/16/eUrodhXamDiVS1Y.png" alt="Ptrgel计算过程.png"></li>
<li>在Pregel计算过程中，一个算法什么时候可以结束，是由所有顶点的状态决定的</li>
<li>在第0个超步，所有顶点处于活跃状态，都会参与该超步的计算过程</li>
<li>当一个顶点不需要继续执行进一步的计算时，就会把自己的状态设置为“停机”，进入非活跃状态</li>
<li>一旦一个顶点进入非活跃状态，后续超步中就不会再在该顶点上执行计算，除非其他顶点给该顶点发送消息把它再次激活</li>
<li>当一个处于非活跃状态的顶点收到来自其他顶点的消息时，Pregel计算框架必须根据条件判断来决定是否将其显式唤醒进入活跃状态</li>
<li>当图中所有的顶点都已经标识其自身达到“非活跃（inactive）”状态，并且没有消息在传送的时候，算法就可以停止运行<br><img src="https://i.loli.net/2019/08/16/Bfl9CYyFdSunm7i.png" alt="一个简单的状态机图.png"><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><img src="https://i.loli.net/2019/08/16/YzldRLfNjiSUwM3.png" alt="一个求最大值的Pregel计算过程图 .png"><h1 id="Pregel的C-API"><a href="#Pregel的C-API" class="headerlink" title="Pregel的C++ API"></a>Pregel的C++ API</h1></li>
<li>Pregel已经预先定义好一个基类——Vertex类：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename VertexValue, typename EdgeValue, typename MessageValue&gt;</span><br><span class="line">class Vertex &#123;</span><br><span class="line">  public:</span><br><span class="line">	virtual void Compute(MessageIterator* msgs) = 0;</span><br><span class="line">	const string&amp; vertex_id() const;</span><br><span class="line">	int64 superstep() const;</span><br><span class="line">	const VertexValue&amp; GetValue();</span><br><span class="line">	VertexValue* MutableValue();</span><br><span class="line">	OutEdgeIterator GetOutEdgeIterator();	</span><br><span class="line">	void SendMessageTo(const string&amp; dest_vertex,	const MessageValue&amp; message);</span><br><span class="line">	void VoteToHalt();</span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure>

<ul>
<li>在Vetex类中，定义了三个值类型参数，分别表示顶点、边和消息。每一个顶点都有一个给定类型的值与之对应</li>
<li>编写Pregel程序时，需要继承Vertex类，并且覆写Vertex类的虚函数Compute() </li>
<li>在Pregel执行计算过程时，在每个超步中都会并行调用每个顶点上定义的Compute()函数</li>
<li>允许Compute()方法查询当前顶点及其边的信息，以及发送消息到其他的顶点<ul>
<li>Compute()方法可以调用GetValue()方法来获取当前顶点的值</li>
<li>调用MutableValue()方法来修改当前顶点的值</li>
<li>通过由出射边的迭代器提供的方法来查看、修改出射边对应的值</li>
</ul>
</li>
<li>对状态的修改，对于被修改的顶点而言是可以立即被看见的，但是，对于其他顶点而言是不可见的，因此，不同顶点并发进行的数据访问是不存在竞争关系的<blockquote>
<ul>
<li>整个过程中，唯一需要在超步之间持久化的顶点级状态，是顶点和其对应的边所关联的值，因而，Pregel计算框架所需要管理的图状态就只包括顶点和边所关联的值，这种做法大大简化了计算流程，同时，也有利于图的分布和故障恢复</li>
</ul>
</blockquote>
<h2 id="消息传递机制"><a href="#消息传递机制" class="headerlink" title="消息传递机制"></a>消息传递机制</h2></li>
<li>顶点之间的通讯是借助于消息传递机制来实现的，每条消息都包含了消息值和需要到达的目标顶点ID。用户可以通过Vertex类的模板参数来设定消息值的数据类型</li>
<li>在一个超步S中，一个顶点可以发送任意数量的消息，这些消息将在下一个超步（S+1）中被其他顶点接收</li>
<li>也就是说，在超步（S+1）中，当Pregel计算框架在顶点V上执行用户自定义的Compute()方法时，所有在前一个超步S中发送给顶点V的消息，都可以通过一个迭代器来访问到。迭代器不能保证消息的顺序，不过可以保证消息一定会被传送并且不会被重复传送</li>
<li>一个顶点V通过与之关联的出射边向外发送消息，并且，消息要到达的目标顶点并不一定是与顶点V相邻的顶点，一个消息可以连续经过多条连通的边到达某个与顶点V不相邻的顶点U，U可以从接收的消息中获取到与其不相邻的顶点V的ID<br><img src="https://i.loli.net/2019/08/16/xJ7QVRDH8P1dMCY.png" alt="超同步.png"><h2 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h2></li>
<li>Pregel计算框架在消息发出去之前，Combiner可以将发往同一个顶点的多个整型值进行求和得到一个值，只需向外发送这个“求和结果”，从而实现了由多个消息合并成一个消息，大大减少了传输和缓存的开销</li>
<li>在默认情况下，Pregel计算框架并不会开启Combiner功能，因为，通常很难找到一种对所有顶点的Compute()函数都合适的Combiner</li>
<li>当用户打算开启Combiner功能时，可以继承Combiner类并覆写虚函数Combine()<br>此外，通常只对那些满足交换律和结合律的操作才可以去开启Combiner功能，因为，Pregel计算框架无法保证哪些消息会被合并，也无法保证消息传递给 Combine()的顺序和合并操作执行的顺序<br><img src="https://i.loli.net/2019/08/16/5LgTwuXAxR4lHJS.png" alt="Combiner应用的例子.png"><h2 id="Aggregator"><a href="#Aggregator" class="headerlink" title="Aggregator"></a>Aggregator</h2></li>
<li>Aggregator提供了一种全局通信、监控和数据查看的机制</li>
<li>在一个超步S中，每一个顶点都可以向一个Aggregator提供一个数据，Pregel计算框架会对这些值进行聚合操作产生一个值，在下一个超步（S+1）中，图中的所有顶点都可以看见这个值</li>
<li>Aggregator的聚合功能，允许在整型和字符串类型上执行最大值、最小值、求和操作，比如，可以定义一个“Sum”Aggregator来统计每个顶点的出射边数量，最后相加可以得到整个图的边的数量</li>
<li>Aggregator还可以实现全局协同的功能，比如，可以设计“and” Aggregator来决定在某个超步中Compute()函数是否执行某些逻辑分支，只有当“and” Aggregator显示所有顶点都满足了某条件时，才去执行这些逻辑分支<h2 id="拓扑改变"><a href="#拓扑改变" class="headerlink" title="拓扑改变"></a>拓扑改变</h2></li>
<li>Pregel计算框架允许用户在自定义函数Compute()中定义操作，修改图的拓扑结构，比如在图中增加（或删除）边或顶点</li>
<li>对于全局拓扑改变，Pregel采用了惰性协调机制，在改变请求发出时，Pregel不会对这些操作进行协调，只有当这些改变请求的消息到达目标顶点并被执行时，Pregel才会对这些操作进行协调，这样，所有针对某个顶点V的拓扑修改操作所引发的冲突，都会由V自己来处理</li>
<li>对于本地的局部拓扑改变，是不会引发冲突的，顶点或边的本地增减能够立即生效，很大程度上简化了分布式编程<h2 id="输入和输出"><a href="#输入和输出" class="headerlink" title="输入和输出"></a>输入和输出</h2></li>
<li>在Pregel计算框架中，图的保存格式多种多样，包括文本文件、关系数据库或键值数据库等</li>
<li>在Pregel中，“从输入文件生成得到图结构”和“执行图计算”这两个过程是分离的，从而不会限制输入文件的格式</li>
<li>对于输出，Pregel也采用了灵活的方式，可以以多种方式进行输出<h1 id="Pregel的体系结构"><a href="#Pregel的体系结构" class="headerlink" title="Pregel的体系结构"></a>Pregel的体系结构</h1><h2 id="Pregel的执行过程"><a href="#Pregel的执行过程" class="headerlink" title="Pregel的执行过程"></a>Pregel的执行过程</h2></li>
<li>在Pregel计算框架中，一个大型图会被划分成许多个分区，每个分区都包含了一部分顶点以及以其为起点的边</li>
<li>一个顶点应该被分配到哪个分区上，是由一个函数决定的，系统默认函数为hash(ID) mod N，其中，N为所有分区总数，ID是这个顶点的标识符；当然，用户也可以自己定义这个函数</li>
<li>这样，无论在哪台机器上，都可以简单根据顶点ID判断出该顶点属于哪个分区，即使该顶点可能已经不存在了</li>
</ul>
<p><img src="https://i.loli.net/2019/08/16/tl1LIS5QxwoK3vf.png" alt="图的划分图.png"></p>
<blockquote>
<ul>
<li>在理想的情况下（不发生任何错误），一个Pregel用户程序的执行过程如下：</li>
</ul>
<ol>
<li>选择集群中的多台机器执行图计算任务，每台机器上运行用户程序的一个副本，其中，有一台机器会被选为Master，其他机器作为Worker。Master只负责协调多个Worker执行任务，系统不会把图的任何分区分配给它。Worker借助于名称服务系统可以定位到Master的位置，并向Master发送自己的注册信息。</li>
<li>Master把一个图分成多个分区，并把分区分配到多个Worker。一个Worker会领到一个或多个分区，每个Worker知道所有其他Worker所分配到的分区情况。每个Worker负责维护分配给自己的那些分区的状态(顶点及边的增删)，对分配给自己的分区中的顶点执行Compute()函数，向外发送消息，并管理接收到的消息。<br><img src="https://i.loli.net/2019/08/16/8vGSQVM9zCxF5Ab.png" alt="Pregel的执行过程图 .png"></li>
<li>Master会把用户输入划分成多个部分，通常是基于文件边界进行划分。划分后，每个部分都是一系列记录的集合，每条记录都包含一定数量的顶点和边。然后，Master会为每个Worker分配用户输入的一部分。如果一个Worker从输入内容中加载到的顶点，刚好是自己所分配到的分区中的顶点，就会立即更新相应的数据结构。否则，该Worker会根据加载到的顶点的ID，把它发送到其所属的分区所在的Worker上。当所有的输入都被加载后，图中的所有顶点都会被标记为“活跃”状态。</li>
<li>Master向每个Worker发送指令，Worker收到指令后，开始运行一个超步。Worker会为自己管辖的每个分区分配一个线程，对于分区中的每个顶点，Worker会把来自上一个超步的、发给该顶点的消息传递给它，并调用处于“活跃”状态的顶点上的Compute()函数，在执行计算过程中，顶点可以对外发送消息，但是，所有消息的发送工作必须在本超步结束之前完成。当所有这些工作都完成以后，Worker会通知Master，并把自己在下一个超步还处于“活跃”状态的顶点的数量报告给Master。上述步骤会被不断重复，直到所有顶点都不再活跃并且系统中不会有任何消息在传输，这时，执行过程才会结束。</li>
<li>计算过程结束后，Master会给所有的Worker发送指令，通知每个Worker对自己的计算结果进行持久化存储。</li>
</ol>
</blockquote>
<h2 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h2><ul>
<li>Pregel采用检查点机制来实现容错。在每个超步的开始，Master会通知所有的Worker把自己管辖的分区的状态（包括顶点值、边值以及接收到的消息），写入到持久化存储设备</li>
<li>Master会周期性地向每个Worker发送ping消息，Worker收到ping消息后会给Master发送反馈消息。如果Master在指定时间间隔内没有收到某个Worker的反馈消息，就会把该Worker标记为“失效”。同样地，如果一个Worker在指定的时间间隔内没有收到来自Master的ping消息，该Worker也会停止工作</li>
<li>每个Worker上都保存了一个或多个分区的状态信息，当一个Worker发生故障时，它所负责维护的分区的当前状态信息就会丢失。Master监测到一个Worker发生故障“失效”后，会把失效Worker所分配到的分区，重新分配到其他处于正常工作状态的Worker集合上，然后，所有这些分区会从最近的某超步S开始时写出的检查点中，重新加载状态信息<h2 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h2></li>
<li>在一个Worker中，它所管辖的分区的状态信息是保存在内存中的。分区中的顶点的状态信息包括：<ul>
<li>顶点的当前值</li>
<li>以该顶点为起点的出射边列表，每条出射边包含了目标顶点ID和边的值</li>
<li>消息队列，包含了所有接收到的、发送给该顶点的消息</li>
<li>标志位，用来标记顶点是否处于活跃状态</li>
</ul>
</li>
<li>在每个超步中，Worker会对自己所管辖的分区中的每个顶点进行遍历，并调用顶点上的Compute()函数，在调用时，会把以下三个参数传递进去：<ul>
<li>该顶点的当前值</li>
<li>一个接收到的消息的迭代器 </li>
<li>一个出射边的迭代器 </li>
</ul>
</li>
<li>在Pregel中，为了获得更好的性能，“标志位”和输入消息队列是分开保存的</li>
<li>对于每个顶点而言，Pregel只保存一份顶点值和边值，但是，会保存两份“标志位”和输入消息队列，分别用于当前超步和下一个超步</li>
<li>在超步S中，当一个Worker在进行顶点处理时，用于当前超步的消息会被处理，同时，它在处理过程中还会接收到来自其他Worker的消息，这些消息会在下一个超步S+1中被处理，因此，需要两个消息队列用于存放作用于当前超步S的消息和作用于下一个超步S+1的消息</li>
<li>如果一个顶点V在超步S接收到消息，那么，它表示V将会在下一个超步S+1中（而不是当前超步S中）处于“活跃”状态</li>
<li>当一个Worker上的一个顶点V需要发送消息到其他顶点U时，该Worker会首先判断目标顶点U是否位于自己机器上</li>
<li>如果目标顶点U在自己的机器上，就直接把消息放入到与目标顶点U对应的输入消息队列中</li>
<li>如果发现目标顶点U在远程机器上，这个消息就会被暂时缓存到本地，当缓存中的消息数目达到一个事先设定的阈值时，这些缓存消息会被批量异步发送出去，传输到目标顶点所在的Worker上</li>
<li>如果存在用户自定义的Combiner操作，那么，当消息被加入到输出队列或者到达输入队列时，就可以对消息执行合并操作，这样可以节省存储空间和网络传输开销<h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2></li>
<li>Master主要负责协调各个Worker执行任务，每个Worker会借助于名称服务系统定位到Master的位置，并向Master发送自己的注册信息，Master会为每个Worker分配一个唯一的ID</li>
<li>Master维护着关于当前处于“有效”状态的所有Worker的各种信息，包括每个Worker的ID和地址信息，以及每个Worker被分配到的分区信息</li>
<li>虽然在集群中只有一个Master，但是，它仍然能够承担起一个大规模图计算的协调任务，这是因为Master中保存这些信息的数据结构的大小，只与分区的数量有关，而与顶点和边的数量无关</li>
<li>一个大规模图计算任务会被Master分解到多个Worker去执行，在每个超步开始时，Master都会向所有处于“有效”状态的Worker发送相同的指令，然后等待这些Worker的回应</li>
<li>如果在指定时间内收不到某个Worker的反馈，Master就认为这个Worker失效</li>
<li>如果参与任务执行的多个Worker中的任意一个发生了故障失效，Master就会进入恢复模式</li>
<li>在每个超步中，图计算的各种工作，比如输入、输出、计算、保存和从检查点中恢复，都会在“路障（barrier）”之前结束</li>
<li>如果路障同步成功，说明一个超步顺利结束，Master就会进入下一个处理阶段，图计算进入下一个超步的执行</li>
<li>Master在内部运行了一个HTTP服务器来显示图计算过程的各种信息</li>
<li>用户可以通过网页随时监控图计算执行过程各个细节<ul>
<li>图的大小</li>
<li>关于出度分布的柱状图</li>
<li>处于活跃状态的顶点数量</li>
<li>在当前超步的时间信息和消息流量</li>
<li>所有用户自定义Aggregator的值</li>
</ul>
</li>
</ul>
<h2 id="Aggregator-1"><a href="#Aggregator-1" class="headerlink" title="Aggregator"></a>Aggregator</h2><ul>
<li>每个用户自定义的Aggregator都会采用聚合函数对一个值集合进行聚合计算得到一个全局值</li>
<li>每个Worker都保存了一个Aggregator的实例集，其中的每个实例都是由类型名称和实例名称来标识的</li>
<li>在执行图计算过程的某个超步S中，每个Worker会利用一个Aggregator对当前本地分区中包含的所有顶点的值进行归约，得到一个本地的局部归约值</li>
<li>在超步S结束时，所有Worker会将所有包含局部归约值的Aggregator的值进行最后的汇总，得到全局值，然后提交给Master</li>
<li>在下一个超步S+1开始时，Master就会将Aggregator的全局值发送给每个Worker</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/10/16/流计算/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/16/流计算/" itemprop="url">流计算</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-16T19:02:37+08:00">
                2018-10-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="流计算概述"><a href="#流计算概述" class="headerlink" title="流计算概述"></a>流计算概述</h1><h2 id="静态数据和流数据"><a href="#静态数据和流数据" class="headerlink" title="静态数据和流数据"></a>静态数据和流数据</h2><ul>
<li>很多企业为了支持决策分析而构建的数据仓库系统，其中存放的大量历史数据就是静态数据。技术人员可以利用数据挖掘和OLAP（On-Line Analytical Processing）分析工具从静态数据中找到对企业有价值的信息<br><img src="https://i.loli.net/2019/08/15/CMX6Q7n4UceDJi8.png" alt="静态数据.png"></li>
</ul>
<ul>
<li>近年来，在Web应用、网络监控、传感监测等领域，兴起了一种新的数据密集型应用——流数据，即数据以大量、快速、时变的流形式持续到达</li>
<li>实例：PM2.5检测、电子商务网站用户点击流</li>
<li>流数据具有如下特征：<ul>
<li>数据快速持续到达，潜在大小也许是无穷无尽的</li>
<li>数据来源众多，格式复杂</li>
<li>数据量大，但是不十分关注存储，一旦经过处理，要么被丢弃，要么被归档存储</li>
<li>注重数据的整体价值，不过分关注个别数据</li>
<li>数据顺序颠倒，或者不完整，系统无法控制将要处理的新到达的数据元素的顺序</li>
</ul>
</li>
</ul>
<h2 id="批量计算和实时计算"><a href="#批量计算和实时计算" class="headerlink" title="批量计算和实时计算"></a>批量计算和实时计算</h2><ul>
<li>对静态数据和流数据的处理，对应着两种截然不同的计算模式：批量计算和实时计算</li>
<li>批量计算：充裕时间处理静态数据，如Hadoop</li>
<li>流数据不适合采用批量计算，因为流数据不适合用传统的关系模型建模</li>
<li>流数据必须采用实时计算，响应时间为秒级</li>
<li>数据量少时，不是问题，但是，在大数据时代，数据格式复杂、来源众多、数据量巨大，对实时计算提出了很大的挑战。因此，针对流数据的实时计算——流计算，应运而生<br><img src="https://i.loli.net/2019/08/15/nC72xfOSIHaXW6J.png" alt="数据的两种处理模型.png"></li>
</ul>
<h2 id="流计算概念"><a href="#流计算概念" class="headerlink" title="流计算概念"></a>流计算概念</h2><ul>
<li>流计算：实时获取来自不同数据源的海量数据，经过实时分析处理，获得有价值的信息<br><img src="https://i.loli.net/2019/08/15/ryRDeMPvW2kVFZ8.png" alt="流计算示意图.png"></li>
<li>流计算秉承一个基本理念，即<strong>数据的价值随着时间的流逝而降低</strong>，如用户点击流。因此，当事件出现时就应该立即进行处理，而不是缓存起来进行批量处理。为了及时处理流数据，就需要一个低延迟、可扩展、高可靠的处理引擎</li>
<li>对于一个流计算系统来说，它应达到如下需求：<ul>
<li>高性能：处理大数据的基本要求，如每秒处理几十万条数据</li>
<li>海量式：支持TB级甚至是PB级的数据规模</li>
<li>实时性：保证较低的延迟时间，达到秒级别，甚至是毫秒级别</li>
<li>分布式：支持大数据的基本架构，必须能够平滑扩展</li>
<li>易用性：能够快速进行开发和部署</li>
<li>可靠性：能可靠地处理流数据</li>
</ul>
</li>
</ul>
<h2 id="流计算与Hadoop"><a href="#流计算与Hadoop" class="headerlink" title="流计算与Hadoop"></a>流计算与Hadoop</h2><ul>
<li>Hadoop设计的初衷是面向大规模数据的批量处理，每台机器并行运行MapReduce任务，最后对结果进行汇总输出</li>
<li>MapReduce是专门面向静态数据的批量处理的，内部各种实现机制都为批处理做了高度优化，不适合用于处理持续到达的动态数据</li>
<li>可能会想到一种“变通”的方案来降低批处理的时间延迟——将基于MapReduce的批量处理转为小批量处理，将输入数据切成小的片段，每隔一个周期就启动一次MapReduce作业。但这种方式也无法有效处理流数据<ul>
<li>切分成小片段，可以降低延迟，但是也增加了附加开销，还要处理片段之间依赖关系</li>
<li>需要改造MapReduce以支持流式处理<br><font color="red"><strong>结论：鱼和熊掌不可兼得，Hadoop擅长批处理，不适合流计算</strong></font></li>
</ul>
</li>
</ul>
<h2 id="流计算框架"><a href="#流计算框架" class="headerlink" title="流计算框架"></a>流计算框架</h2><ul>
<li>目前有三类常见的流计算框架和平台：商业级的流计算平台、开源流计算框架、公司为支持自身业务开发的流计算框架</li>
<li>商业级：IBM InfoSphere Streams和IBM StreamBase</li>
<li>较为常见的是开源流计算框架，代表如下：<ul>
<li>Twitter Storm：免费、开源的分布式实时计算系统，可简单、高效、可靠地处理大量的流数据</li>
<li>Yahoo! S4（Simple Scalable Streaming System）：开源流计算平台，是通用的、分布式的、可扩展的、分区容错的、可插拔的流式系统</li>
</ul>
</li>
<li>公司为支持自身业务开发的流计算框架：<ul>
<li>Facebook Puma</li>
<li>Dstream（百度）</li>
<li>银河流数据处理平台（淘宝）</li>
</ul>
</li>
</ul>
<h1 id="流计算处理流程"><a href="#流计算处理流程" class="headerlink" title="流计算处理流程"></a>流计算处理流程</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li>传统的数据处理流程，需要先采集数据并存储在关系数据库等数据管理系统中，之后由用户通过查询操作和数据管理系统进行交互</li>
<li>传统的数据处理流程隐含了两个前提：<ul>
<li><strong>存储的数据是旧的</strong>。存储的静态数据是过去某一时刻的快照，这些数据在查询时可能已不具备时效性了</li>
<li><strong>需要用户主动发出查询来获取结果</strong></li>
</ul>
</li>
</ul>
<h2 id="数据实时采集"><a href="#数据实时采集" class="headerlink" title="数据实时采集"></a>数据实时采集</h2><ul>
<li>数据实时采集阶段通常采集多个数据源的海量数据，需要保证实时性、低延迟与稳定可靠</li>
<li>以日志数据为例，由于分布式集群的广泛应用，数据分散存储在不同的机器上，因此需要实时汇总来自不同机器上的日志数据</li>
<li>目前有许多互联网公司发布的开源分布式日志采集系统均可满足每秒数百MB的数据采集和传输需求，如：<ul>
<li>Facebook的Scribe</li>
<li>LinkedIn的Kafka</li>
<li>淘宝的Time Tunnel</li>
<li>基于Hadoop的Chukwa和Flume<br><img src="https://i.loli.net/2019/08/16/uPW8HjeiowtgRVF.png" alt="数据实时采集.png"></li>
</ul>
</li>
</ul>
<h2 id="数据实时计算"><a href="#数据实时计算" class="headerlink" title="数据实时计算"></a>数据实时计算</h2><ul>
<li>数据采集系统的基本架构一般有以下三个部分：<ul>
<li>Agent：主动采集数据，并把数据推送到Collector部分</li>
<li>Collector：接收多个Agent的数据，并实现有序、可靠、高性能的转发</li>
<li>Store：存储Collector转发过来的数据（对于流计算不存储数据</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/16/U3KCNEJhtjHvkPZ.png" alt="数据采集系统基本架构.png"></p>
<ul>
<li>数据实时计算阶段对采集的数据进行实时的分析和计算，并反馈实时结果</li>
<li>经流处理系统处理后的数据，可视情况进行存储，以便之后再进行分析计算。在时效性要求较高的场景中，处理之后的数据也可以直接丢弃</li>
</ul>
<h2 id="实时查询服务"><a href="#实时查询服务" class="headerlink" title="实时查询服务"></a>实时查询服务</h2><ul>
<li>实时查询服务：经由流计算框架得出的结果可供用户进行实时查询、展示或储存</li>
<li>传统的数据处理流程，用户需要主动发出查询才能获得想要的结果。而在流处理流程中，实时查询服务可以不断更新结果，并将用户所需的结果实时推送给用户</li>
<li>虽然通过对传统的数据处理系统进行定时查询，也可以实现不断地更新结果和结果推送，但通过这样的方式获取的结果，仍然是根据过去某一时刻的数据得到的结果，与实时结果有着本质的区别<blockquote>
<ul>
<li>可见，流处理系统与传统的数据处理系统有如下不同：</li>
</ul>
</blockquote>
</li>
<li>流处理系统处理的是实时的数据，而传统的数据处理系统处理的是预先存储好的静态数据</li>
<li>用户通过流处理系统获取的是实时结果，而通过传统的数据处理系统，获取的是过去某一时刻的结果</li>
<li>流处理系统无需用户主动发出查询，实时查询服务可以主动将实时结果推送给用户</li>
</ul>
<h1 id="流计算应用"><a href="#流计算应用" class="headerlink" title="流计算应用"></a>流计算应用</h1><ul>
<li>流计算是针对流数据的实时计算，可以应用在多种场景中，如Web服务、机器翻译、广告投放、自然语言处理、气候模拟预测等</li>
<li>如百度、淘宝等大型网站中，每天都会产生大量流数据，包括用户的搜索内容、用户的浏览记录等数据。采用流计算进行实时数据分析，可以了解每个时刻的流量变化情况，甚至可以分析用户的实时浏览轨迹，从而进行实时个性化内容推荐</li>
<li>但是，并不是每个应用场景都需要用到流计算的。流计算适合于需要处理持续到达的流数据、对数据处理有较高实时性要求的场景</li>
</ul>
<h1 id="流计算开源框架-–-Storm"><a href="#流计算开源框架-–-Storm" class="headerlink" title="流计算开源框架 – Storm"></a>流计算开源框架 – Storm</h1><h2 id="Storm简介"><a href="#Storm简介" class="headerlink" title="Storm简介"></a>Storm简介</h2><ul>
<li>Twitter Storm是一个免费、开源的分布式实时计算系统，Storm对于实时计算的意义类似于Hadoop对于批处理的意义，Storm可以简单、高效、可靠地处理流数据，并支持多种编程语言</li>
<li>Storm框架可以方便地与数据库系统进行整合，从而开发出强大的实时计算系统</li>
</ul>
<p><img src="https://i.loli.net/2019/08/16/2OAfhoyKXdsYmjV.png" alt="Twitter的分层数据处理架构.png"></p>
<h2 id="Storm的特点"><a href="#Storm的特点" class="headerlink" title="Storm的特点"></a>Storm的特点</h2><ul>
<li>Storm可用于许多领域中，如实时分析、在线机器学习、持续计算、远程RPC、数据提取加载转换等</li>
<li>Storm具有以下主要特点：<ul>
<li>整合性：Storm可方便地与队列系统和数据库系统进行整合</li>
<li>简易的API：Storm的API在使用上即简单又方便</li>
<li>可扩展性：Storm的并行特性使其可以运行在分布式集群中</li>
<li>容错性：Storm可自动进行故障节点的重启、任务的重新分配</li>
<li>可靠的消息处理：Storm保证每个消息都能完整处理 </li>
<li>支持各种编程语言：Storm支持使用各种编程语言来定义任务</li>
<li>快速部署：Storm可以快速进行部署和使用</li>
<li>免费、开源：Storm是一款开源框架，可以免费使用</li>
</ul>
</li>
</ul>
<h2 id="Storm设计思想"><a href="#Storm设计思想" class="headerlink" title="Storm设计思想"></a>Storm设计思想</h2><ul>
<li>Storm主要术语包括Streams、Spouts、Bolts、Topology和Stream Groupings</li>
<li>Streams：Storm将流数据Stream描述成一个无限的Tuple序列，这些Tuple序列会以分布式的方式并行地创建和处理<br><img src="https://i.loli.net/2019/08/16/pyhWGTaef9SscdM.png" alt="Stream.png"></li>
<li>每个tuple是一堆值，每个值有一个名字，并且每个值可以是任何类型</li>
<li>Tuple本来应该是一个Key-Value的Map，由于各个组件间传递的tuple的字段名称已经事先定义好了，所以Tuple只需要按序填入各个Value，所以就是一个Value List（值列表）</li>
<li>Spout：Storm认为每个Stream都有一个源头，并把这个源头抽象为Spout</li>
<li>通常Spout会从外部数据源（队列、数据库等）读取数据，然后封装成Tuple形式，发送到Stream中。Spout是一个主动的角色，在接口内部有个nextTuple函数，Storm框架会不停的调用该函数<br><img src="https://i.loli.net/2019/08/16/uO6giCcEQ81NrBX.png" alt="Spout.png"></li>
<li>Bolt：Storm将Streams的状态转换过程抽象为Bolt。Bolt即可以处理Tuple，也可以将处理后的Tuple作为新的Streams发送给其他Bolt</li>
<li>Bolt可以执行过滤、函数操作、Join、操作数据库等任何操作</li>
<li>Bolt是一个被动的角色，其接口中有一个execute(Tuple input)方法，在接收到消息之后会调用此函数，用户可以在此方法中执行自己的处理逻辑<br><img src="https://i.loli.net/2019/08/16/TVfov9rABmMWx8D.png" alt="bboult.png"></li>
<li>Topology：Storm将Spouts和Bolts组成的网络抽象成Topology，它可以被提交到Storm集群执行。Topology可视为流转换图，图中节点是一个Spout或Bolt，边则表示Bolt订阅了哪个Stream。当Spout或者Bolt发送元组时，它会把元组发送到每个订阅了该Stream的Bolt上进行处理</li>
<li>Topology里面的每个处理组件（Spout或Bolt）都包含处理逻辑， 而组件之间的连接则表示数据流动的方向</li>
<li>Topology里面的每一个组件都是并行运行的</li>
<li>在Topology里面可以指定每个组件的并行度， Storm会在集群里面分配那么多的线程来同时计算</li>
<li>在Topology的具体实现上，Storm中的Topology定义仅仅是一些Thrift结构体（二进制高性能的通信中间件），支持各种编程语言进行定义<br><img src="https://i.loli.net/2019/08/16/sWUh84QkrPGbjdL.png" alt="Toploly.png"></li>
<li>Stream Groupings：Storm中的Stream Groupings用于告知Topology如何在两个组件间（如Spout和Bolt之间，或者不同的Bolt之间）进行Tuple的传送。每一个Spout和Bolt都可以有多个分布式任务，一个任务在什么时候、以什么方式发送Tuple就是由Stream Groupings来决定的<br><img src="https://i.loli.net/2019/08/16/IHnpzWscD8PEBmJ.png" alt="StramGrouping .png"><blockquote>
<ul>
<li>目前，Storm中的Stream Groupings有如下几种方式：</li>
</ul>
</blockquote>
</li>
</ul>
<ol>
<li>ShuffleGrouping：随机分组，随机分发Stream中的Tuple，保证每个Bolt的Task接收Tuple数量大致一致</li>
<li>FieldsGrouping：按照字段分组，保证相同字段的Tuple分配到同一个Task中</li>
<li>AllGrouping：广播发送，每一个Task都会收到所有的Tuple</li>
<li>GlobalGrouping：全局分组，所有的Tuple都发送到同一个Task中</li>
<li>NonGrouping：不分组，和ShuffleGrouping类似，当前Task的执行会和它的被订阅者在同一个线程中执行</li>
<li>DirectGrouping：直接分组，直接指定由某个Task来执行Tuple的处理</li>
</ol>
<h2 id="Storm框架设计"><a href="#Storm框架设计" class="headerlink" title="Storm框架设计"></a>Storm框架设计</h2><ul>
<li>Storm运行任务的方式与Hadoop类似：Hadoop运行的是MapReduce作业，而Storm运行的是“Topology”</li>
<li>但两者的任务大不相同，主要的不同是：MapReduce作业最终会完成计算并结束运行，而Topology将持续处理消息（直到人为终止）<table>
<thead>
<tr>
<th>Hadoop</th>
<th>Storm</th>
</tr>
</thead>
<tbody><tr>
<td>应用名称</td>
<td>Job</td>
</tr>
<tr>
<td>系统角色</td>
<td>JobTracker</td>
</tr>
<tr>
<td>系统角色</td>
<td>TaskTracker</td>
</tr>
<tr>
<td>组件接口</td>
<td>Map/Reduce</td>
</tr>
</tbody></table>
</li>
<li>Storm集群采用“Master—Worker”的节点方式：<ul>
<li>Master节点运行名为“Nimbus”的后台程序（类似Hadoop中的“JobTracker”），负责在集群范围内分发代码、为Worker分配任务和监测故障</li>
<li>Worker节点运行名为“Supervisor”的后台程序，负责监听分配给它所在机器的工作，即根据Nimbus分配的任务来决定启动或停止Worker进程，一个Worker节点上同时运行若干个Worker进程</li>
</ul>
</li>
<li>Storm使用Zookeeper来作为分布式协调组件，负责Nimbus和多个Supervisor之间的所有协调工作。借助于Zookeeper，若Nimbus进程或Supervisor进程意外终止，重启时也能读取、恢复之前的状态并继续工作，使得Storm极其稳定<br><img src="https://i.loli.net/2019/08/16/OxlvwgL9Juq8Zam.png" alt="Storm集群架构示意图.png"></li>
</ul>
<ol>
<li>worker:每个worker进程都属于一个特定的Topology，每个Supervisor节点的worker可以有多个，每个worker对Topology中的每个组件（Spout或 Bolt）运行一个或者多个executor线程来提供task的运行服务</li>
<li>executor：executor是产生于worker进程内部的线程，会执行同一个组件的一个或者多个task。</li>
<li>task:实际的数据处理由task完成，在Topology的生命周期中，每个组件的task数目是不会发生变化的，而executor的数目却不一定。executor数目小于等于task的数目，默认情况下，二者是相等的<br><img src="https://i.loli.net/2019/08/16/ivGbezZRMup6jDh.png" alt="worker excuter和task关系.png"><blockquote>
<ul>
<li>基于这样的架构设计，Storm的工作流程如下图所示：</li>
</ul>
</blockquote>
</li>
</ol>
<ul>
<li>所有Topology任务的提交必须在Storm客户端节点上进行，提交后，由Nimbus节点分配给其他Supervisor节点进行处理</li>
<li>Nimbus节点首先将提交的Topology进行分片，分成一个个Task，分配给相应的Supervisor，并将Task和Supervisor相关的信息提交到Zookeeper集群上</li>
<li>Supervisor会去Zookeeper集群上认领自己的Task，通知自己的Worker进程进行Task的处理</li>
<li>说明：在提交了一个Topology之后，Storm就会创建Spout/Bolt实例并进行序列化。之后，将序列化的组件发送给所有的任务所在的机器(即Supervisor节点)，在每一个任务上反序列化组件<br><img src="https://i.loli.net/2019/08/16/GHqlOyPUjadZnzF.png" alt="Storm工作流程示意图.png"><h1 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h1><h2 id="Spark-Streaming设计"><a href="#Spark-Streaming设计" class="headerlink" title="Spark Streaming设计"></a>Spark Streaming设计</h2></li>
<li>Spark Streaming可整合多种输入数据源，如Kafka、Flume、HDFS，甚至是普通的TCP套接字。经处理后的数据可存储至文件系统、数据库，或显示在仪表盘里<br><img src="https://i.loli.net/2019/08/16/KvQyUpZ9Rs1c8uH.png" alt="Spark Streaming支持的输入、输出数据源.png"></li>
<li>Spark Streaming的基本原理是将实时输入数据流以时间片（秒级）为单位进行拆分，然后经Spark引擎以类似批处理的方式处理每个时间片数据<br><img src="https://i.loli.net/2019/08/16/wYuM6RTUAn9B5vi.png" alt="Spark Streaming执行流程.png"></li>
<li>Spark Streaming最主要的抽象是DStream（Discretized Stream，离散化数据流），表示连续不断的数据流。在内部实现上，Spark Streaming的输入数据按照时间片（如1秒）分成一段一段的DStream，每一段数据转换为Spark中的RDD，并且对DStream的操作都最终转变为对相应的RDD的操作<br><img src="https://i.loli.net/2019/08/16/7uiej3OvUBofWPp.png" alt="DStream操作示意图.png"></li>
</ul>
<h2 id="Spark-Streaming与Storm的对比"><a href="#Spark-Streaming与Storm的对比" class="headerlink" title="Spark Streaming与Storm的对比"></a>Spark Streaming与Storm的对比</h2><ul>
<li>Spark Streaming和Storm最大的区别在于，Spark Streaming无法实现毫秒级的流计算，而Storm可以实现毫秒级响应</li>
<li>Spark Streaming构建在Spark上，一方面是因为Spark的低延迟执行引擎（100ms+）可以用于实时计算，另一方面，相比于Storm，RDD数据集更容易做高效的容错处理</li>
<li>Spark Streaming采用的小批量处理的方式使得它可以同时兼容批量和实时数据处理的逻辑和算法，因此，方便了一些需要历史数据和实时数据联合分析的特定应用场合</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/10/06/Spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/06/Spark/" itemprop="url">Spark</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-06T18:53:15+08:00">
                2018-10-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Spark概述"><a href="#Spark概述" class="headerlink" title="Spark概述"></a>Spark概述</h1><h2 id="Spark简介"><a href="#Spark简介" class="headerlink" title="Spark简介"></a>Spark简介</h2><ul>
<li>Spark最初由美国加州伯克利大学（UCBerkeley）的AMP实验室于2009年开发，是基于内存计算的大数据并行计算框架，可用于构建大型的、低延迟的数据分析应用程序</li>
<li>2013年Spark加入Apache孵化器项目后发展迅猛，如今已成为Apache软件基金会最重要的三大分布式计算系统开源项目之一（Hadoop、Spark、Storm）</li>
<li>Spark具有如下几个主要特点：<ul>
<li>运行速度快：使用DAG执行引擎以支持循环数据流与内存计算</li>
<li>容易使用：支持使用Scala、Java、Python和R语言进行编程，可以通过Spark Shell进行交互式编程   </li>
<li>通用性：Spark提供了完整而强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件</li>
<li>运行模式多样：可运行于独立的集群模式中，可运行于Hadoop中，也可运行于Amazon EC2等云环境中，并且可以访问HDFS、Cassandra、HBase、Hive等多种数据源</li>
</ul>
</li>
</ul>
<h2 id="Scala简介"><a href="#Scala简介" class="headerlink" title="Scala简介"></a>Scala简介</h2><ul>
<li>Scala是一门现代的多范式编程语言，运行于Java平台（JVM，Java 虚拟机），并兼容现有的Java程序</li>
<li>Scala的特性：<ul>
<li>Scala具备强大的并发性，支持函数式编程，可以更好地支持分布式系统</li>
<li>Scala语法简洁，能提供优雅的API</li>
<li>Scala兼容Java，运行速度快，且能融合到Hadoop生态圈中 </li>
</ul>
</li>
<li>Scala是Spark的主要编程语言，但Spark还支持Java、Python、R作为编程语言</li>
<li>Scala的优势是提供了REPL（Read-Eval-Print Loop，交互式解释器），提高程序开发效率</li>
</ul>
<h2 id="Spark与Hadoop的比较"><a href="#Spark与Hadoop的比较" class="headerlink" title="Spark与Hadoop的比较"></a>Spark与Hadoop的比较</h2><ul>
<li>Hadoop存在如下一些缺点：<ul>
<li>表达能力有限</li>
<li>磁盘IO开销大</li>
<li>延迟高</li>
<li>任务之间的衔接涉及IO开销，在前一个任务执行完成之前，其他任务就无法开始，难以胜任复杂、多阶段的计算任务 </li>
</ul>
</li>
<li>相比于Hadoop MapReduce，Spark主要具有如下优点：<ul>
<li>Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比Hadoop MapReduce更灵活</li>
<li>Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率更高</li>
<li>Spark基于<strong>DAG</strong>的任务调度执行机制，要优于Hadoop MapReduce的迭代执行机制 </li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/15/vr9S5IBqmax1MFf.png" alt="Spark执行流程.png"></p>
<ul>
<li>使用Hadoop进行迭代计算非常耗资源</li>
<li>Spark将数据载入内存后，之后的迭代计算都可以直接使用内存中的中间结果作运算，避免了从磁盘中频繁读取数据</li>
</ul>
<p><img src="https://i.loli.net/2019/08/15/TVUy9Nz7DWkqpZ5.png" alt="Hadoop与Spark执行逻辑回归时间对比.png"></p>
<h1 id="Spark生态系统"><a href="#Spark生态系统" class="headerlink" title="Spark生态系统"></a>Spark生态系统</h1><blockquote>
<p>在实际应用中，大数据处理主要包括以下三个类型：</p>
<ul>
<li>复杂的批量数据处理：通常时间跨度在数十分钟到数小时之间</li>
<li>基于历史数据的交互式查询：通常时间跨度在数十秒到数分钟之间</li>
<li>基于实时数据流的数据处理：通常时间跨度在数百毫秒到数秒之间<br>当同时存在以上三种场景时，就需要同时部署三种不同的软件<br>比如: MapReduce  /  Impala  /  Storm</li>
</ul>
</blockquote>
<blockquote>
<p>这样做难免会带来一些问题： </p>
<ul>
<li>不同场景之间输入输出数据无法做到无缝共享，通常需要进行数据格式的转换</li>
<li>不同的软件需要不同的开发和维护团队，带来了较高的使用成本</li>
<li>比较难以对同一个集群中的各个系统进行统一的资源协调和分配</li>
</ul>
</blockquote>
<ul>
<li><p>Spark的设计遵循<strong>“一个软件栈满足不同应用场景”</strong>的理念，逐渐形成了一套完整的生态系统</p>
</li>
<li><p>既能够提供内存计算框架，也可以支持SQL即席查询、实时流式计算、机器学习和图计算等</p>
</li>
<li><p>Spark可以部署在资源管理器YARN之上，提供一站式的大数据解决方案</p>
</li>
<li><p>因此，Spark所提供的生态系统足以应对上述三种场景，即同时支持批处理、交互式查询和流数据处理</p>
</li>
<li><p>Spark的生态系统主要包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX 等组件</p>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/15/eGqLAQjrxYDIiB4.png" alt="BDAS架构.png"></p>
<table>
<thead>
<tr>
<th>应用场景</th>
<th>时间跨度</th>
<th>其他框架</th>
<th>Spark生态系统中的组件</th>
</tr>
</thead>
<tbody><tr>
<td>复杂的批量数据处理</td>
<td>小时级</td>
<td>MapReduce、Hive</td>
<td>Spark</td>
</tr>
<tr>
<td>基于历史数据的交互式查询</td>
<td>分钟级、秒级</td>
<td>Impala、Dremel、Drill</td>
<td>Spark SQL</td>
</tr>
<tr>
<td>基于实时数据流的数据处理</td>
<td>毫秒、秒级</td>
<td>Storm、S4</td>
<td>Spark Streaming</td>
</tr>
<tr>
<td>基于历史数据的数据挖掘</td>
<td>-</td>
<td>Mahout</td>
<td>MLlib</td>
</tr>
<tr>
<td>图结构数据的处理</td>
<td>-</td>
<td>Pregel、Hama</td>
<td>GraphX</td>
</tr>
</tbody></table>
<h1 id="Spark运行架构"><a href="#Spark运行架构" class="headerlink" title="Spark运行架构"></a>Spark运行架构</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li>RDD：是Resillient Distributed Dataset（弹性分布式数据集）的简称，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型</li>
<li>DAG：是Directed Acyclic Graph（有向无环图）的简称，反映RDD之间的依赖关系</li>
<li>Executor：是运行在工作节点（WorkerNode）的一个进程，负责运行Task</li>
<li>Application：用户编写的Spark应用程序</li>
<li>Task：运行在Executor上的工作单元 </li>
<li>Job：一个Job包含多个RDD及作用于相应RDD上的各种操作</li>
<li>Stage：是Job的基本调度单位，一个Job会分为多组Task，每组Task被称为Stage，或者也被称为TaskSet，代表了一组关联的、相互之间没有Shuffle依赖关系的任务组成的任务集</li>
</ul>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><ul>
<li>Spark运行架构包括集群资源管理器（Cluster Manager）、运行作业任务的工作节点（Worker Node）、每个应用的任务控制节点（Driver）和每个工作节点上负责具体任务的执行进程（Executor）</li>
<li>资源管理器可以自带或Mesos或YARN<blockquote>
<p>与Hadoop MapReduce计算框架相比，Spark所采用的Executor有两个优点：</p>
</blockquote>
</li>
<li>一是利用多线程来执行具体的任务，减少任务的启动开销</li>
<li>二是Executor中有一个BlockManager存储模块，会将内存和磁盘共同作为存储设备，有效减少IO开销<br><img src="https://i.loli.net/2019/08/15/ayNnsW1oELcmMrV.png" alt="Spark运行架构.png"></li>
<li>一个Application由一个Driver和若干个Job构成，一个Job由多个Stage构成，一个Stage由多个没有Shuffle关系的Task组成</li>
<li>当执行一个Application时，Driver会向集群管理器申请资源，启动Executor，并向Executor发送应用程序代码和文件，然后在Executor上执行Task，运行结束后，执行结果会返回给Driver，或者写到HDFS或者其他数据库中<br><img src="https://i.loli.net/2019/08/15/TcBFl2LCj9PdIGM.png" alt="Spark中各种概念之间的相互关系.png"></li>
</ul>
<h2 id="Spark运行基本流程"><a href="#Spark运行基本流程" class="headerlink" title="Spark运行基本流程"></a>Spark运行基本流程</h2><p><img src="https://i.loli.net/2019/08/15/gHdGTBRl4L8Ekhy.png" alt="Spark运行基本流程图.png"></p>
<ol>
<li>运行环境，即由Driver创建一个SparkContext，进行资源的申请、任务的分配和监控</li>
<li>资源管理器为Executor分配资源，并启动Executor进程</li>
<li>SparkContext根据RDD的依赖关系构建DAG图，DAG图提交给DAGScheduler解析成Stage，然后把一个个TaskSet提交给底层调度器TaskScheduler处理；Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行，并提供应用程序代码</li>
<li>Task在Executor上运行，把执行结果反馈给TaskScheduler，然后反馈给DAGScheduler，运行完毕后写入数据并释放所有资源 <blockquote>
<p><em>总体而言，Spark运行架构具有以下特点：</em></p>
</blockquote>
</li>
<li>每个Application都有自己专属的Executor进程，并且该进程在Application运行期间一直驻留。Executor进程以多线程的方式运行Task</li>
<li>Spark运行过程与资源管理器无关，只要能够获取Executor进程并保持通信即可</li>
<li>Task采用了数据本地性和推测执行等优化机制</li>
</ol>
<h2 id="RDD-运行原理"><a href="#RDD-运行原理" class="headerlink" title="RDD 运行原理"></a>RDD 运行原理</h2><ol>
<li>设计背景</li>
</ol>
<ul>
<li>许多迭代式算法（比如机器学习、图算法等）和交互式数据挖掘工具，共同之处是，不同计算阶段之间会重用中间结果</li>
<li>目前的MapReduce框架都是把中间结果写入到HDFS中，带来了大量的数据复制、磁盘IO和序列化开销</li>
<li>RDD就是为了满足这种需求而出现的，它提供了一个抽象的数据架构，我们不必担心底层数据的分布式特性，只需将具体的应用逻辑表达为一系列转换处理，不同RDD之间的转换操作形成依赖关系，可以实现管道化，避免中间数据存储</li>
</ul>
<ol start="2">
<li>RDD概念</li>
</ol>
<ul>
<li>一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算</li>
<li>RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，不能直接修改，只能基于稳定的物理存储中的数据集创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和group by）而创建得到新的RDD</li>
<li>RDD提供了一组丰富的操作以支持常见的数据运算，分为“动作”（Action）和“转换”（Transformation）两种类型</li>
<li>RDD提供的转换接口都非常简单，都是类似map、filter、groupBy、join等粗粒度的数据转换操作，而不是针对某个数据项的细粒度修改（不适合网页爬虫）</li>
<li>表面上RDD的功能很受限、不够强大，实际上RDD已经被实践证明可以高效地表达许多框架的编程模型（比如MapReduce、SQL、Pregel）</li>
<li>Spark用Scala语言实现了RDD的API，程序员可以通过调用API实现对RDD的各种操作</li>
<li>RDD典型的执行过程如下：<ul>
<li>RDD读入外部数据源进行创建</li>
<li>RDD经过一系列的转换（Transformation）操作，每一次都会产生不同的RDD，供给下一个转换操作使用</li>
<li>最后一个RDD经过“动作”操作进行转换，并输出到外部数据源 <blockquote>
<ul>
<li>这一系列处理称为一个Lineage（血缘关系），即DAG拓扑排序的结果<br>优点：惰性调用、管道化、避免同步等待、不需要保存中间结果、每次操作变得简单<br><img src="https://i.loli.net/2019/08/15/a1Y9sXAxECQTD6I.png" alt="RDD执行过程的一个实例.png"></li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
<ol start="3">
<li>RDD特性<br>Spark采用RDD以后能够实现高效计算的原因主要在于：</li>
<li>高效的容错性<ul>
<li>现有容错机制：数据复制或者记录日志</li>
<li>RDD：血缘关系、重新计算丢失分区、无需回滚系统、重算过程在不同节点之间并行、只记录粗粒度的操作</li>
</ul>
</li>
<li>中间结果持久化到内存，数据在内存中的多个RDD操作之间进行传递，避免了不必要的读写磁盘开销</li>
<li>存放的数据可以是Java对象，避免了不必要的对象序列化和反序列化</li>
<li>RDD之间的依赖关系<br><img src="https://i.loli.net/2019/08/15/v71RxrEqTLsDjNI.png" alt="窄依赖与宽依赖的区别.png"></li>
</ol>
<ul>
<li>窄依赖表现为一个父RDD的分区对应于一个子RDD的分区或多个父RDD的分区对应于一个子RDD的分区</li>
<li>宽依赖则表现为存在一个父RDD的一个分区对应一个子RDD的多个分区</li>
</ul>
<ol start="5">
<li>Stage的划分<blockquote>
<ul>
<li>Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分Stage，具体划分方法是：</li>
</ul>
</blockquote>
</li>
</ol>
<ul>
<li>在DAG中进行反向解析，遇到宽依赖就断开</li>
<li>遇到窄依赖就把当前的RDD加入到Stage中</li>
<li>　将窄依赖尽量划分在同一个Stage中，可以实现流水线计算<blockquote>
<ul>
<li>被分成三个Stage，在Stage2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作<br><img src="https://i.loli.net/2019/08/15/iEwLC2qAhSlpY6M.png" alt="根据RDD分区的依赖关系划分Stage.png"></li>
</ul>
</blockquote>
</li>
<li>流水线操作实例<ul>
<li>分区7通过map操作生成的分区9，可以不用等待分区8到分区10这个map操作的计算结束，而是继续进行union操作，得到分区13，这样流水线执行大大提高了计算的效率</li>
</ul>
</li>
<li>Stage的类型包括两种：ShuffleMapStage和ResultStage，具体如下：<ul>
<li>ShuffleMapStage：不是最终的Stage，在它之后还有其他Stage，所以，它的输出一定需要经过Shuffle过程，并作为后续Stage的输入；这种Stage是以Shuffle为输出边界，其输入边界可以是从外部获取数据，也可以是另一个ShuffleMapStage的输出，其输出可以是另一个Stage的开始；在一个Job里可能有该类型的Stage，也可能没有该类型Stage；</li>
<li>ResultStage：最终的Stage，没有输出，而是直接产生结果或存储。这种Stage是直接输出结果，其输入边界可以是从外部获取数据，也可以是另一个ShuffleMapStage的输出。在一个Job里必定有该类型Stage。<br>因此，一个Job含有一个或多个Stage，其中至少含有一个ResultStage</li>
</ul>
</li>
</ul>
<ol start="6">
<li>RDD运行过程<blockquote>
<ul>
<li>通过上述对RDD概念、依赖关系和Stage划分的介绍，结合之前介绍的Spark运行基本流程，再总结一下RDD在Spark架构中的运行过程：</li>
</ul>
</blockquote>
</li>
<li>创建RDD对象；</li>
<li>SparkContext负责计算RDD之间的依赖关系，构建DAG；</li>
<li>DAGScheduler负责把DAG图分解成多个Stage，每个Stage中包含了多个Task，每个Task会被TaskScheduler分发给各个WorkerNode上的Executor去执行。<br><img src="https://i.loli.net/2019/08/15/N6DdUuQT8E5MXRn.png" alt="RDD在Spark中的运行过程.png"></li>
</ol>
<h1 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h1><ul>
<li>Spark SQL在Hive兼容层面仅依赖HiveQL解析、Hive元数据，也就是说，从HQL被解析成抽象语法树（AST）起，就全部由Spark SQL接管了。Spark SQL执行计划生成和优化都由Catalyst（函数式关系查询优化框架）负责<br><img src="https://i.loli.net/2019/08/15/B4gFD6Nnx75dblL.png" alt="Spark SQL架构.png"><ul>
<li>Spark SQL增加了SchemaRDD（即带有Schema信息的RDD），使用户可以在Spark SQL中执行SQL语句，数据既可以来自RDD，也可以是Hive、HDFS、Cassandra等外部数据源，还可以是JSON格式的数据</li>
<li>Spark SQL目前支持Scala、Java、Python三种语言，支持SQL-92规范<br><img src="https://i.loli.net/2019/08/15/irYBgfjqWhAZCpx.png" alt="Spark SQL支持的数据格式和编程语言.png"></li>
</ul>
</li>
</ul>
<h1 id="Spark的部署和应用方式"><a href="#Spark的部署和应用方式" class="headerlink" title="Spark的部署和应用方式"></a>Spark的部署和应用方式</h1><h2 id="Spark三种部署方式"><a href="#Spark三种部署方式" class="headerlink" title="Spark三种部署方式"></a>Spark三种部署方式</h2><ul>
<li>Standalone（类似于MapReduce1.0，slot为资源分配单位）</li>
<li>Spark on Mesos（和Spark有血缘关系，更好支持Mesos）</li>
<li>Spark on YARN<br><img src="https://i.loli.net/2019/08/15/IXHGPSlbvZxKoBa.png" alt="Spark on Yarn.png"></li>
</ul>
<h2 id="从Hadoop-Storm架构转向Spark架构"><a href="#从Hadoop-Storm架构转向Spark架构" class="headerlink" title="从Hadoop+Storm架构转向Spark架构"></a>从Hadoop+Storm架构转向Spark架构</h2><p><img src="https://i.loli.net/2019/08/15/Fnlm51KXpfL6NjB.png" alt="采用Hadoop+Storm部署方式的一个案例.png"></p>
<blockquote>
<ul>
<li>用Spark架构具有如下优点：</li>
</ul>
<ul>
<li>实现一键式安装和配置、线程级别的任务监控和告警</li>
<li>降低硬件集群、软件维护、任务监控和应用开发的难度</li>
<li>便于做成统一的硬件、计算平台资源池</li>
</ul>
<ul>
<li>需要说明的是，Spark Streaming无法实现毫秒级的流计算，因此，对于需要毫秒级实时响应的企业应用而言，仍然需要采用流计算框架（如Storm）<br><img src="https://i.loli.net/2019/08/15/vfjaYQR8shSqDJt.png" alt="用Spark架构满足批处理和流处理需求.png"></li>
</ul>
</blockquote>
<h2 id="Hadoop和Spark的统一部署"><a href="#Hadoop和Spark的统一部署" class="headerlink" title="Hadoop和Spark的统一部署"></a>Hadoop和Spark的统一部署</h2><ul>
<li>由于Hadoop生态系统中的一些组件所实现的功能，目前还是无法由Spark取代的，比如，Storm</li>
<li>现有的Hadoop组件开发的应用，完全转移到Spark上需要一定的成本<blockquote>
<ul>
<li>不同的计算框架统一运行在YARN中，可以带来如下好处：</li>
</ul>
</blockquote>
</li>
<li>计算资源按需伸缩</li>
<li>不用负载应用混搭，集群利用率高</li>
<li>共享底层存储，避免数据跨集群迁移<br><img src="https://i.loli.net/2019/08/15/RPfTV8uejXhgvlw.png" alt="Hadoop和Spark的统一部署.png"></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/09/27/NoSQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/27/NoSQL/" itemprop="url">NoSQL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-27T19:28:50+08:00">
                2018-09-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="NoSQL兴起原因"><a href="#NoSQL兴起原因" class="headerlink" title="NoSQL兴起原因"></a>NoSQL兴起原因</h1><ol>
<li>关系数据库已经无法满足Web2.0的需求。主要表现在以下几个方面：<ul>
<li>无法满足海量数据的管理需求</li>
<li>无法满足数据高并发的需求</li>
<li>无法满足高可扩展性和高可用性的需求</li>
</ul>
</li>
<li>One size fits all”模式很难适用于截然不同的业务场景<ul>
<li>关系模型作为统一的数据模型既被用于数据分析，也被用于在线业务。但这两者一个强调高吞吐，一个强调低延时，已经演化出完全不同的架构。用同一套模型来抽象显然是不合适的</li>
<li>Hadoop就是针对数据分析</li>
<li>MongoDB、Redis等是针对在线业务，两者都抛弃了关系模型</li>
</ul>
</li>
<li>关系数据库的关键特性包括完善的事务机制和高效的查询机制。但是，关系数据库引以为傲的两个关键特性，到了Web2.0时代却成了鸡肋，主要表现在以下几个方面：<ul>
<li>Web2.0网站系统通常不要求严格的数据库事务</li>
<li>Web2.0并不要求严格的读写实时性</li>
<li>Web2.0通常不包含大量复杂的SQL查询（去结构化，存储空间换取更好的查询性能）</li>
</ul>
</li>
</ol>
<h1 id="NoSQL与关系型数据库的比较"><a href="#NoSQL与关系型数据库的比较" class="headerlink" title="NoSQL与关系型数据库的比较"></a>NoSQL与关系型数据库的比较</h1><table>
<thead>
<tr>
<th align="left">比较标准</th>
<th align="left">RDBMS</th>
<th align="left">NoSQL</th>
<th align="left">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="left">数据库原理</td>
<td align="left">完全支持</td>
<td align="left">部分支持</td>
<td align="left">RDBMS有关系代数理论作为基础,NoSQL没有统一的理论基础</td>
</tr>
<tr>
<td align="left">数据规模</td>
<td align="left">大</td>
<td align="left">超大</td>
<td align="left">RDBMS很难实现横向扩展，纵向扩展的空间也比较有限，性能会随着数据规模的增大而降低,NoSQL可以很容易通过添加更多设备来支持更大规模的数据</td>
</tr>
<tr>
<td align="left">数据库模式</td>
<td align="left">固定</td>
<td align="left">灵活</td>
<td align="left">RDBMS需要定义数据库模式，严格遵守数据定义和相关约束条件,NoSQL不存在数据库模式，可以自由灵活定义并存储各种不同类型的数据</td>
</tr>
<tr>
<td align="left">查询效率</td>
<td align="left">快</td>
<td align="left">可以实现高效的简单查询，但是不具备高度结构化查询等特性，复杂查询的性能不尽人意</td>
<td align="left">RDBMS借助于索引机制可以实现快速查询（包括记录查询和范围查询）NoSQL数据库没有面向复杂查询的索引，虽然NoSQL可以使用MapReduce来加速查询，但是，在复杂查询方面的性能仍然不如RDBMS</td>
</tr>
<tr>
<td align="left">一致性</td>
<td align="left">强一致性</td>
<td align="left">弱一致性</td>
<td align="left">RDBMS严格遵守事务ACID模型，可以保证事务强一致性,很多NoSQL数据库放松了对事务ACID四性的要求，而是遵守BASE模型，只能保证最终一致性</td>
</tr>
<tr>
<td align="left">数据完整性</td>
<td align="left">容易实现</td>
<td align="left">很难实现</td>
<td align="left">任何一个RDBMS都可以很容易实现数据完整性，比如通过主键或者非空约束来实现实体完整性，通过主键、外键来实现参照完整性，通过约束或者触发器来实现用户自定义完整性,但是，在NoSQL数据库却无法实现</td>
</tr>
<tr>
<td align="left">扩展性</td>
<td align="left">一般</td>
<td align="left">好</td>
<td align="left">RDBMS很难实现横向扩展，纵向扩展的空间也比较有限,NoSQL在设计之初就充分考虑了横向扩展的需求，可以很容易通过添加廉价设备实现扩展</td>
</tr>
<tr>
<td align="left">可用性</td>
<td align="left">好</td>
<td align="left">很好</td>
<td align="left">RDBMS在任何时候都以保证数据一致性为优先目标，其次才是优化系统性能，随着数据规模的增大，RDBMS为了保证严格的一致性，只能提供相对较弱的可用性,大多数NoSQL都能提供较高的可用性</td>
</tr>
<tr>
<td align="left">标准化</td>
<td align="left">是</td>
<td align="left">否</td>
<td align="left">RDBMS已经标准化（SQL）,NoSQL还没有行业标准，不同的NoSQL数据库都有自己的查询语言，很难规范应用程序接口,StoneBraker认为：NoSQL缺乏统一查询语言，将会拖慢NoSQL发展</td>
</tr>
<tr>
<td align="left">技术支持</td>
<td align="left">高</td>
<td align="left">低</td>
<td align="left">RDBMS经过几十年的发展，已经非常成熟，Oracle等大型厂商都可以提供很好的技术支持,NoSQL在技术支持方面仍然处于起步阶段，还不成熟，缺乏有力的技术支持</td>
</tr>
<tr>
<td align="left">可维护性</td>
<td align="left">复杂</td>
<td align="left">复杂</td>
<td align="left">RDBMS需要专门的数据库管理员(DBA)维护 ,NoSQL数据库虽然没有DBMS复杂，也难以维护</td>
</tr>
</tbody></table>
<p><strong>总结</strong></p>
<ol>
<li>关系数据库<br>优势：以完善的关系代数理论作为基础，有严格的标准，支持事务ACID四性，借助索引机制可以实现高效的查询，技术成熟，有专业公司的技术支持<br>劣势：可扩展性较差，无法较好支持海量数据存储，数据模型过于死板、无法较好支持Web2.0应用，事务机制影响了系统的整体性能等</li>
<li>NoSQL数据库<br>优势：可以支持超大规模数据存储，灵活的数据模型可以很好地支持Web2.0应用，具有强大的横向扩展能力等<br>劣势：缺乏数学理论基础，复杂查询性能不高，大都不能实现事务强一致性，很难实现数据完整性，技术尚不成熟，缺乏专业团队的技术支持，维护较困难等</li>
</ol>
<ul>
<li>关系数据库应用场景：电信、银行等领域的关键业务系统，需要保证强事务一致性</li>
<li>NoSQL数据库应用场景：互联网企业、传统企业的非关键业务（比如数据分析）</li>
<li>采用混合架构</li>
<li>案例：亚马逊公司就使用不同类型的数据库来支撑它的电子商务应用<ul>
<li>对于“购物篮”这种临时性数据，采用键值存储会更加高效</li>
<li>当前的产品和订单信息则适合存放在关系数据库中</li>
<li>大量的历史订单信息则适合保存在类似MongoDB的文档数据库中</li>
</ul>
</li>
</ul>
<h1 id="NoSQL的四大类型"><a href="#NoSQL的四大类型" class="headerlink" title="NoSQL的四大类型"></a>NoSQL的四大类型</h1><blockquote>
<p>NoSQL数据库虽然数量众多，但是，归结起来，典型的NoSQL数据库通常包括键值数据库、列族数据库、文档数据库和图形数据库.</p>
</blockquote>
<p><img src="https://i.loli.net/2019/08/14/kMvYIWtdT8xOosR.png" alt="NoSQL-1.png"><br><img src="https://i.loli.net/2019/08/14/p5rvDxPIwzKhVAa.png" alt="NoSQL-2.png"><br><img src="https://i.loli.net/2019/08/14/OseyBMhXY2QZjl9.jpg" alt="四类数据库.jpg"></p>
<h2 id="键值数据库"><a href="#键值数据库" class="headerlink" title="键值数据库"></a>键值数据库</h2><table>
<thead>
<tr>
<th>相关产品</th>
<th>Redis、Riak、SimpleDB、Chordless、Scalaris、Memcached</th>
</tr>
</thead>
<tbody><tr>
<td>数据模型</td>
<td>键/值对,键是一个字符串对象,值可以是任意类型的数据，比如整型、字符型、数组、列表、集合等</td>
</tr>
<tr>
<td>典型应用</td>
<td>涉及频繁读写、拥有简单数据模型的应用 ,内容缓存，比如会话、配置文件、参数、购物车等,存储配置和用户数据信息的移动应用</td>
</tr>
<tr>
<td>优点</td>
<td>扩展性好，灵活性好，大量写操作时性能高</td>
</tr>
<tr>
<td>缺点</td>
<td>无法存储结构化信息，条件查询效率较低</td>
</tr>
<tr>
<td>不适用情形</td>
<td>不是通过键而是通过值来查：键值数据库根本没有通过值查询的途径 ,要存储数据之间的关系：在键值数据库中，不能通过两个或两个以上的键来关联数据 需要事务的支持,在一些键值数据库中，产生故障时，不可以回滚</td>
</tr>
<tr>
<td>使用者</td>
<td>(Redis）、GitHub（Riak）、BestBuy（Riak）、Twitter（Redis和Memcached）、StackOverFlow（Redis）、Instagram （Redis）、Youtube（Memcached）、Wikipedia（Memcached）</td>
</tr>
</tbody></table>
<p><img src="https://i.loli.net/2019/08/14/MFu8kUZoDWVYthr.png" alt="键值数据库成为理想的缓冲层解决方案.png"><br>Redis有时候会被人们称为“强化版的Memcached” 支持持久化、数据恢复、更多数据类型</p>
<h2 id="列族数据库"><a href="#列族数据库" class="headerlink" title="列族数据库"></a>列族数据库</h2><table>
<thead>
<tr>
<th>相关产品</th>
<th>BigTable、HBase、Cassandra、HadoopDB、GreenPlum、PNUTS</th>
</tr>
</thead>
<tbody><tr>
<td>数据模型</td>
<td>列族</td>
</tr>
<tr>
<td>典型应用</td>
<td>“分布式数据存储与管理,数据在地理上分布于多个数据中心的应用程序,可以容忍副本中存在短期不一致情况的应用程序,拥有动态字段的应用程序 拥有潜在大量数据的应用程序，大到几百TB的数据</td>
</tr>
<tr>
<td>优点</td>
<td>查找速度快，可扩展性强，容易进行分布式扩展，复杂性低</td>
</tr>
<tr>
<td>缺点</td>
<td>功能较少，大都不支持强事务一致性</td>
</tr>
<tr>
<td>不适用情形</td>
<td>需要ACID事务支持的情形，Cassandra等产品就不适用</td>
</tr>
<tr>
<td>使用者</td>
<td>Ebay（Cassandra）、Instagram（Cassandra）、NASA（Cassandra）、Twitter（Cassandra and HBase）、Facebook（HBase）、Yahoo!（HBase）</td>
</tr>
</tbody></table>
<h2 id="文档数据库"><a href="#文档数据库" class="headerlink" title="文档数据库"></a>文档数据库</h2><blockquote>
<p>“文档”其实是一个数据记录，这个记录能够对包含的数据类型和内容进行“自我描述”。XML文档、HTML文档和JSON 文档就属于这一类。SequoiaDB就是使用JSON格式的文档数据库，它的存储的数据是这样的：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;ID&quot;:1,</span><br><span class="line"> &quot;NAME&quot;:&quot;SequiaDB&quot;,</span><br><span class="line"> &quot;Tel&quot;: &#123;</span><br><span class="line">      &quot;Office&quot;:&quot;123456&quot;,&quot;Tel&quot;：“1273928”</span><br><span class="line">        &#125;</span><br><span class="line">   &quot;Addr&quot;: &quot;China,GZ&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>关系数据库：<br>必须有schema信息才能理解数据的含义，如学生（学号，姓名，性别，年龄，系，年级）<br>（1001，张三，男，20，计算机，2002）</p>
</li>
<li><p>一个XML文档：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>数据是不规则的，每一条记录包含了所有的有关“SequoiaDB”的信息而没有任何外部的引用，这条记录就是“自包含”的</p>
</li>
<li><p>这使得记录很容易完全移动到其他服务器，因为这条记录的所有信息都包含在里面了，不需要考虑还有信息在别的表没有一起迁移走</p>
</li>
<li><p>同时，因为在移动过程中，只有被移动的那一条记录（文档）需要操作，而不像关系型中每个有关联的表都需要锁住来保证一致性，这样一来ACID的保证就会变得更快速，读写的速度也会有很大的提升</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>相关产品</th>
<th>MongoDB、CouchDB、Terrastore、ThruDB、RavenDB、SisoDB、RaptorDB、CloudKit、Perservere、Jackrabbit</th>
</tr>
</thead>
<tbody><tr>
<td>数据模型</td>
<td>键/值,值（value）是版本化的文档</td>
</tr>
<tr>
<td>典型应用</td>
<td>存储、索引并管理面向文档的数据或者类似的半结构化数据,比如，用于后台具有大量读写操作的网站、使用JSON数据结构的应用、使用嵌套结构等非规范化数据的应用程序</td>
</tr>
<tr>
<td>优点</td>
<td>性能好（高并发），灵活性高，复杂性低，数据结构灵活,提供嵌入式文档功能，将经常查询的数据存储在同一个文档中,既可以根据键来构建索引，也可以根据内容构建索引</td>
</tr>
<tr>
<td>缺点</td>
<td>缺乏统一的查询语法</td>
</tr>
<tr>
<td>不适用情形</td>
<td>在不同的文档上添加事务。文档数据库并不支持文档间的事务，如果对这方面有需求则不应该选用这个解决方案</td>
</tr>
<tr>
<td>使用者</td>
<td>（MongoDB）、SAP （MongoDB）、Codecademy （MongoDB）、Foursquare （MongoDB）、NBC News （RavenDB）</td>
</tr>
</tbody></table>
<h2 id="图数据库"><a href="#图数据库" class="headerlink" title="图数据库"></a>图数据库</h2><table>
<thead>
<tr>
<th>相关产品</th>
<th>Neo4J、OrientDB、InfoGrid、Infinite Graph、GraphDB</th>
</tr>
</thead>
<tbody><tr>
<td>数据模型</td>
<td>图结构</td>
</tr>
<tr>
<td>典型应用</td>
<td>专门用于处理具有高度相互关联关系的数据，比较适合于社交网络、模式识别、依赖分析、推荐系统以及路径寻找等问题</td>
</tr>
<tr>
<td>优点</td>
<td>灵活性高，支持复杂的图形算法，可用于构建复杂的关系图谱</td>
</tr>
<tr>
<td>缺点</td>
<td>复杂性高，只能支持一定的数据规模</td>
</tr>
<tr>
<td>使用者</td>
<td>Adobe（Neo4J）、Cisco（Neo4J）、T-Mobile（Neo4J）</td>
</tr>
</tbody></table>
<h1 id="NoSQL的三大基石"><a href="#NoSQL的三大基石" class="headerlink" title="NoSQL的三大基石"></a>NoSQL的三大基石</h1><p><img src="https://i.loli.net/2019/08/14/3PKEurnWJwMZlqf.png" alt="NoSQL三大基石.png"></p>
<h2 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h2><ul>
<li><strong>C（Consistency）</strong>：一致性，是指任何一个读操作总是能够读到之前完成的写操作的结果，也就是在分布式环境中，多点的数据是一致的，或者说，所有节点在同一时间具有相同的数据</li>
<li><strong>A:（Availability）</strong>：可用性，是指快速获取数据，可以在确定的时间内返回操作结果，保证每个请求不管成功或者失败都有响应；</li>
<li><strong>P（Tolerance of Network Partition）</strong>：分区容忍性，是指当出现网络分区的情况时（即系统中的一部分节点无法和其他节点进行通信），分离的系统也能够正常运行，也就是说，系统中任意信息的丢失或失败不会影响系统的继续运作。</li>
</ul>
<blockquote>
<p>CAP理论告诉我们，一个分布式系统不可能同时满足一致性、可用性和分区容忍性这三个需求，最多只能同时满足其中两个，正所谓“鱼和熊掌不可兼得”。</p>
</blockquote>
<p><img src="https://i.loli.net/2019/08/14/xeFK2I74shtjcyA.png" alt="CAP.png"></p>
<ol>
<li>CA：也就是强调一致性（C）和可用性（A），放弃分区容忍性（P），最简单的做法是把所有与事务相关的内容都放到同一台机器上。很显然，这种做法会严重影响系统的可扩展性。传统的关系数据库（MySQL、SQL Server和PostgreSQL），都采用了这种设计原则，因此，扩展性都比较差</li>
<li>CP：也就是强调一致性（C）和分区容忍性（P），放弃可用性（A），当出现网络分区的情况时，受影响的服务需要等待数据一致，因此在等待期间就无法对外提供服务</li>
<li>AP：也就是强调可用性（A）和分区容忍性（P），放弃一致性（C），允许系统返回不一致的数据<br><img src="https://i.loli.net/2019/08/14/nJDRbsSMBaPUmhX.png" alt="不同产品在CAP理论下的不同设计原则 .png"></li>
</ol>
<h2 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h2><blockquote>
<p>说起BASE（Basically Availble, Soft-state, Eventual consistency），不得不谈到ACID。</p>
</blockquote>
<table>
<thead>
<tr>
<th>ACID</th>
<th>BASE</th>
</tr>
</thead>
<tbody><tr>
<td>原子性(Atomicity)</td>
<td>基本可用(Basically Available)</td>
</tr>
<tr>
<td>一致性(Consistency)</td>
<td>软状态/柔性事务(Soft state)</td>
</tr>
<tr>
<td>隔离性(Isolation)</td>
<td>最终一致性 (Eventual consistency)</td>
</tr>
<tr>
<td>持久性 (Durable)</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><p>一个数据库事务具有ACID四性：</p>
<ul>
<li>A（Atomicity）：原子性，是指事务必须是原子工作单元，对于其数据修改，要么全都执行，要么全都不执行</li>
<li>C（Consistency）：一致性，是指事务在完成时，必须使所有的数据都保持一致状态</li>
<li>I（Isolation）：隔离性，是指由并发事务所做的修改必须与任何其它并发事务所做的修改隔离</li>
<li>D（Durability）：持久性，是指事务完成之后，它对于系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持</li>
</ul>
</li>
<li><p>BASE的基本含义是基本可用（Basically Availble）、软状态（Soft-state）和最终一致性（Eventual consistency）：</p>
<ul>
<li>基本可用<ul>
<li>基本可用，是指一个分布式系统的一部分发生问题变得不可用时，其他部分仍然可以正常使用，也就是允许分区失败的情形出现</li>
</ul>
</li>
<li>软状态<ul>
<li>“软状态（soft-state）”是与“硬状态（hard-state）”相对应的一种提法。数据库保存的数据是“硬状态”时，可以保证数据一致性，即保证数据一直是正确的。“软状态”是指状态可以有一段时间不同步，具有一定的滞后性</li>
</ul>
</li>
<li>最终一致性<ul>
<li>一致性的类型包括强一致性和弱一致性，二者的主要区别在于高并发的数据访问操作下，后续操作是否能够获取最新的数据。对于强一致性而言，当执行完一次更新操作后，后续的其他读操作就可以保证读到更新后的最新数据；反之，如果不能保证后续访问读到的都是更新后的最新数据，那么就是弱一致性。而最终一致性只不过是弱一致性的一种特例，允许后续的访问操作可以暂时读不到更新后的数据，但是经过一段时间之后，必须最终读到更新后的数据。</li>
<li>最常见的实现最终一致性的系统是DNS（域名系统）。一个域名更新操作根据配置的形式被分发出去，并结合有过期机制的缓存；最终所有的客户端可以看到最新的值。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h2><blockquote>
<p>最终一致性根据更新数据后各进程访问到数据的时间和方式的不同，又可以区分为：</p>
</blockquote>
<ul>
<li>因果一致性：如果进程A通知进程B它已更新了一个数据项，那么进程B的后续访问将获得A写入的最新值。而与进程A无因果关系的进程C的访问，仍然遵守一般的最终一致性规则</li>
<li>“读己之所写”一致性：可以视为因果一致性的一个特例。当进程A自己执行一个更新操作之后，它自己总是可以访问到更新过的值，绝不会看到旧值</li>
<li>单调读一致性：如果进程已经看到过数据对象的某个值，那么任何后续访问都不会返回在那个值之前的值</li>
<li>会话一致性：它把访问存储系统的进程放到会话（session）的上下文中，只要会话还存在，系统就保证“读己之所写”一致性。如果由于某些失败情形令会话终止，就要建立新的会话，而且系统保证不会延续到新的会话</li>
<li>单调写一致性：系统保证来自同一个进程的写操作顺序执行。系统必须保证这种程度的一致性，否则就非常难以编程了</li>
</ul>
<h3 id="对于分布式数据系统："><a href="#对于分布式数据系统：" class="headerlink" title="对于分布式数据系统："></a>对于分布式数据系统：</h3><ul>
<li>N — 数据复制的份数</li>
<li>W — 更新数据是需要保证写完成的节点数</li>
<li>R — 读取数据的时候需要读取的节点数<ul>
<li>如果W+R&gt;N，写的节点和读的节点重叠，则是强一致性。例如对于典型的一主一备同步复制的关系型数据库，N=2,W=2,R=1，则不管读的是主库还是备库的数据，都是一致的。一般设定是R＋W = N+1，这是保证强一致性的最小设定</li>
<li>如果W+R&lt;=N，则是弱一致性。例如对于一主一备异步复制的关系型数据库，N=2,W=1,R=1，则如果读的是备库，就可能无法读取主库已经更新过的数据，所以是弱一致性。</li>
</ul>
</li>
<li>对于分布式系统，为了保证高可用性，一般设置N&gt;=3。不同的N,W,R组合，是在可用性和一致性之间取一个平衡，以适应不同的应用场景。</li>
<li>如果N=W,R=1，任何一个写节点失效，都会导致写失败，因此可用性会降低，但是由于数据分布的N个节点是同步写入的，因此可以保证强一致性。</li>
<li>实例：HBase是借助其底层的HDFS来实现其数据冗余备份的。HDFS采用的就是强一致性保证。在数据没有完全同步到N个节点前，写操作是不会返回成功的。也就是说它的W＝N，而读操作只需要读到一个值即可，也就是说它R＝1。</li>
<li>像Voldemort，Cassandra和Riak这些类Dynamo的系统，通常都允许用户按需要设置N，R，W三个值，即使是设置成W＋R&lt;= N也是可以的。也就是说他允许用户在强一致性和最终一致性之间自由选择。而在用户选择了最终一致性，或者是W&lt;N的强一致性时，则总会出现一段“各个节点数据不同步导致系统处理不一致的时间”。为了提供最终一致性的支持，这些系统会提供一些工具来使数据更新被最终同步到所有相关节点。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/09/23/HBase/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/23/HBase/" itemprop="url">HBase</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-23T19:19:04+08:00">
                2018-09-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote>
<p>HBase是一个高可靠、高性能、面向列、可伸缩的分布式数据库，是谷歌BigTable的开源实现，主要用来存储非结构化和半结构化的松散数据。HBase的目标是处理非常庞大的表，可以通过水平扩展的方式，利用廉价计算机集群处理由超过10亿行数据和数百万列元素组成的数据表 </p>
<ul>
<li>Hadoop可以很好地解决大规模数据的离线批量处理问题，但是，受限于Hadoop MapReduce编程框架的高延迟数据处理机制，使得Hadoop无法满足大规模数据实时处理应用的需求</li>
<li>HDFS面向批量访问模式，不是随机访问模式</li>
<li>传统的通用关系型数据库无法应对在数据规模剧增时导致的系统扩展性和性能问题（分库分表也不能很好解决）</li>
<li>传统关系数据库在数据结构变化时一般需要停机维护；空列浪费存储空间</li>
<li>因此，业界出现了一类面向半结构化数据存储和处理的高可扩展、低写入/查询延迟的系统，例如，键值数据库、文档数据库和列族数据库（如BigTable和HBase等）</li>
<li>HBase已经成功应用于互联网服务领域和传统行业的众多在线式数据分析处理系统中</li>
</ul>
</blockquote>
<h2 id="HBase与传统关系数据库的对比分析"><a href="#HBase与传统关系数据库的对比分析" class="headerlink" title="HBase与传统关系数据库的对比分析"></a>HBase与传统关系数据库的对比分析</h2><ol>
<li>数据类型：关系数据库采用关系模型，具有丰富的数据类型和存储方式，HBase则采用了更加简单的数据模型，它把数据存储为未经解释的字符串</li>
<li>数据操作：关系数据库中包含了丰富的操作，其中会涉及复杂的多表连接。HBase操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、清空等，因为HBase在设计上就避免了复杂的表和表之间的关系</li>
<li>存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的，每个列族都由几个文件保存，不同列族的文件是分离的</li>
<li>数据索引：关系数据库通常可以针对不同列构建复杂的多个索引，以提高数据访问性能。HBase只有一个索引——行键，通过巧妙的设计，HBase中的所有访问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来</li>
<li>数据维护：在关系数据库中，更新操作会用最新的当前值去替换记录中原来的旧值，旧值被覆盖后就不会存在。而在HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留</li>
<li>可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。相反，HBase和BigTable这些分布式数据库就是为了实现灵活的水平扩展而开发的，能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩</li>
</ol>
<h1 id="HBase访问接口"><a href="#HBase访问接口" class="headerlink" title="HBase访问接口"></a>HBase访问接口</h1><table>
<thead>
<tr>
<th>类型</th>
<th>特点</th>
<th>场合</th>
</tr>
</thead>
<tbody><tr>
<td>Native Java API</td>
<td>最常规和高效的访问方式</td>
<td>适合Hadoop MapReduce作业并行批处理HBase表数据</td>
</tr>
<tr>
<td>HBase Shell</td>
<td>HBase的命令行工具，最简单的接口</td>
<td>适合HBase管理使用</td>
</tr>
<tr>
<td>Thrift Gateway</td>
<td>利用Thrift序列化技术，支持C++、PHP、Python等多种语言</td>
<td>适合其他异构系统在线访问HBase表数据</td>
</tr>
<tr>
<td>REST Gateway</td>
<td>解除了语言限制</td>
<td>支持REST风格的Http API访问HBase</td>
</tr>
<tr>
<td>Pig</td>
<td>使用Pig Latin流式编程语言来处理HBase中的数据</td>
<td>适合做数据统计</td>
</tr>
<tr>
<td>Hive</td>
<td>简单</td>
<td>当需要以类似SQL语言方式来访问HBase的时候</td>
</tr>
</tbody></table>
<h1 id="Hbase数据模型"><a href="#Hbase数据模型" class="headerlink" title="Hbase数据模型"></a>Hbase数据模型</h1><h2 id="数据模型概述"><a href="#数据模型概述" class="headerlink" title="数据模型概述"></a>数据模型概述</h2><ul>
<li>HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限定符和时间戳</li>
<li>每个值是一个未经解释的字符串，没有数据类型</li>
<li>用户在表中存储数据，每一行都有一个可排序的行键和任意多的列</li>
<li>表在水平方向由一个或者多个列族组成，一个列族中可以包含任意多个列，同一个列族里面的数据存储在一起</li>
<li>列族支持动态扩展，可以很轻松地添加一个列族或列，无需预先定义列的数量以及类型，所有列均以字符串形式存储，用户需要自行进行据类型转换</li>
<li>HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留（这是和HDFS只允许追加不允许修改的特性相关的）<h2 id="数据模型相关概念"><a href="#数据模型相关概念" class="headerlink" title="数据模型相关概念"></a>数据模型相关概念</h2><img src="https://i.loli.net/2019/08/14/N3DW2LA4kxIYuFa.png" alt="HBase数据模型.png"></li>
<li>表：HBase采用表来组织数据，表由行和列组成，列划分为若干个列族</li>
<li>行：每个HBase表都由若干行组成，每个行由行键（row key）来标识。</li>
<li>列族：一个HBase表被分组成许多“列族”（Column Family）的集合，它是基本的访问控制单元</li>
<li>列限定符：列族里的数据通过列限定符（或列）来定位</li>
<li>单元格：在HBase表中，通过行、列族和列限定符确定一个“单元格”（cell），单元格中存储的数据没有数据类型，总被视为字节数组byte[]</li>
<li>时间戳：每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引</li>
</ul>
<h2 id="数据坐标"><a href="#数据坐标" class="headerlink" title="数据坐标"></a>数据坐标</h2><ul>
<li>HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“四维坐标”，即[行键, 列族, 列限定符, 时间戳]<table>
<thead>
<tr>
<th><strong>键</strong></th>
<th><strong>值</strong></th>
</tr>
</thead>
<tbody><tr>
<td>[“201505003”, “Info”, “email”, 1174184619081]</td>
<td>“xie@qq.com”</td>
</tr>
<tr>
<td>[“201505003”, “Info”, “email”, 1174184620720]</td>
<td>“you@163.com”</td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="概念视图"><a href="#概念视图" class="headerlink" title="概念视图"></a>概念视图</h2><table>
<thead>
<tr>
<th>行键</th>
<th>时间戳</th>
<th>列族contents</th>
<th>列族anchor</th>
</tr>
</thead>
<tbody><tr>
<td>“com.cnn.www”</td>
<td>t5</td>
<td>anchor:cnnsi.com=”CNN”</td>
<td></td>
</tr>
<tr>
<td>t4</td>
<td>anchor:my.look.ca=”CNN.com”</td>
<td></td>
<td></td>
</tr>
<tr>
<td>t3</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
<td></td>
</tr>
<tr>
<td>t2</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
<td></td>
</tr>
<tr>
<td>t1</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="物理视图"><a href="#物理视图" class="headerlink" title="物理视图"></a>物理视图</h2><table>
<thead>
<tr>
<th>行键</th>
<th>时间戳</th>
<th>列族contents</th>
</tr>
</thead>
<tbody><tr>
<td>“com.cnn.www”</td>
<td>t3</td>
<td>contents:html=”<html>...“</html></td>
</tr>
<tr>
<td>t2</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
</tr>
<tr>
<td>t1</td>
<td>contents:html=”<html>...“</html></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>行键</th>
<th>时间戳</th>
<th>列族anchor</th>
</tr>
</thead>
<tbody><tr>
<td>“com.cnn.www”</td>
<td>t5</td>
<td>anchor:cnnsi.com=”CNN”</td>
</tr>
<tr>
<td>t4</td>
<td>anchor:my.look.ca=”CNN.com”</td>
<td></td>
</tr>
</tbody></table>
<h2 id="面向列的存储"><a href="#面向列的存储" class="headerlink" title="面向列的存储"></a>面向列的存储</h2><p><img src="https://i.loli.net/2019/08/14/CrtHkdTRqnQeKZ3.png" alt="面向列的存储.png"><br><img src="https://i.loli.net/2019/08/14/296eZVrmyGhSgE8.png" alt="列式存储.png"><br><img src="https://i.loli.net/2019/08/14/Pun632tgqSbTJpM.png" alt="行式存储.png"></p>
<h1 id="HBase实现原理"><a href="#HBase实现原理" class="headerlink" title="HBase实现原理"></a>HBase实现原理</h1><h2 id="HBase-功能组件"><a href="#HBase-功能组件" class="headerlink" title="HBase 功能组件"></a>HBase 功能组件</h2><ul>
<li>HBase的实现包括三个主要的功能组件：<ol>
<li>库函数：链接到每个客户端</li>
<li>一个Master主服务器</li>
<li>许多个Region服务器</li>
</ol>
</li>
<li>主服务器Master负责管理和维护HBase表的分区信息，维护Region服务器列表，分配Region，负载均衡</li>
<li>Region服务器负责存储和维护分配给自己的Region，处理来自客户端的读写请求</li>
<li>客户端并不是直接从Master主服务器上读取数据，而是在获得Region的存储位置信息后，直接从Region服务器上读取数据</li>
<li>客户端并不依赖Master，而是通过Zookeeper来获得Region位置信息，大多数客户端甚至从来不和Master通信，这种设计方式使得Master负载很小 </li>
</ul>
<h2 id="表和Region"><a href="#表和Region" class="headerlink" title="表和Region"></a>表和Region</h2><ul>
<li>开始只有一个Region，后来不断分裂</li>
<li>Region拆分操作非常快，接近瞬间，因为拆分之后的Region读取的仍然是原存储文件，直到“合并”过程把存储文件异步地写到独立的文件之后，才会读取新文件<br><img src="https://i.loli.net/2019/08/14/67qygZGCpdfDHY4.jpg" alt="Region表.jpg"><br><img src="https://i.loli.net/2019/08/14/kKYREnvAGqcCP65.jpg" alt="Region表分裂.jpg"></li>
<li>每个Region默认大小是100MB到200MB（2006年以前的硬件配置）<ul>
<li>每个Region的最佳大小取决于单台服务器的有效处理能力</li>
<li>目前每个Region最佳大小建议1GB-2GB（2013年以后的硬件配置）</li>
</ul>
</li>
<li>同一个Region不会被分拆到多个Region服务器</li>
<li>每个Region服务器存储10-1000个Region<br><img src="https://i.loli.net/2019/08/14/kDWwbKAnXqZs1xI.jpg" alt="Region表分布.jpg"></li>
</ul>
<h2 id="Region-定位"><a href="#Region-定位" class="headerlink" title="Region 定位"></a>Region 定位</h2><ul>
<li>元数据表，又名.META.表，存储了Region和Region服务器的映射关系</li>
<li>当HBase表很大时， .META.表也会被分裂成多个Region</li>
<li>根数据表，又名-ROOT-表，记录所有元数据的具体位置</li>
<li>-ROOT-表只有唯一一个Region，名字是在程序中被写死的</li>
<li>Zookeeper文件记录了-ROOT-表的位置<br><img src="https://i.loli.net/2019/08/14/Z3FcJ1iXt7xrKTq.jpg" alt="HBase三层结构1.jpg"></li>
</ul>
<table>
<thead>
<tr>
<th>层次</th>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>第一层</td>
<td>Zookeeper文件</td>
<td>记录了-ROOT-表的位置信息</td>
</tr>
<tr>
<td>第二层</td>
<td>-ROOT-表</td>
<td>记录了.META.表的Region位置信息</td>
</tr>
<tr>
<td>-ROOT-表只能有一个Region。通过-ROOT-表，就可以访问.META.表中的数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>第三层</td>
<td>.META.表</td>
<td>记录了用户数据表的Region位置信息，.META.表可以有多个Region，保存了HBase中所有用户数据表的Region位置信息</td>
</tr>
</tbody></table>
<ul>
<li>为了加快访问速度，.META.表的全部Region都会被保存在内存中</li>
<li>假设.META.表的每行（一个映射条目）在内存中大约占用1KB，并且每个Region限制为128MB，那么，上面的三层结构可以保存的用户数据表的Region数目的计算方法是：</li>
<li>（-ROOT-表能够寻址的.META.表的Region个数）×（每个.META.表的 Region可以寻址的用户数据表的Region个数）</li>
<li>一个-ROOT-表最多只能有一个Region，也就是最多只能有128MB，按照每行（一个映射条目）占用1KB内存计算，128MB空间可以容纳128MB/1KB=217行，也就是说，一个-ROOT-表可以寻址217个.META.表的Region。</li>
<li>同理，每个.META.表的 Region可以寻址的用户数据表的Region个数是128MB/1KB=217。</li>
<li>最终，三层结构可以保存的Region数目是(128MB/1KB) × (128MB/1KB) = 234个Region</li>
</ul>
<h3 id="客户端访问数据时的“三级寻址”"><a href="#客户端访问数据时的“三级寻址”" class="headerlink" title="客户端访问数据时的“三级寻址”"></a>客户端访问数据时的“三级寻址”</h3><ul>
<li>为了加速寻址，客户端会缓存位置信息，同时，需要解决缓存失效问题</li>
<li>寻址过程客户端只需要询问Zookeeper服务器，不需要连接Master服务器</li>
</ul>
<h1 id="HBase运行机制"><a href="#HBase运行机制" class="headerlink" title="HBase运行机制"></a>HBase运行机制</h1><h2 id="HBase系统架构"><a href="#HBase系统架构" class="headerlink" title="HBase系统架构"></a>HBase系统架构</h2><p><img src="https://i.loli.net/2019/08/14/68D2kyjXOWYxwRQ.jpg" alt="HBase系统架构.jpg"></p>
<ol>
<li>客户端</li>
</ol>
<ul>
<li>客户端包含访问HBase的接口，同时在缓存中维护着已经访问过的Region位置信息，用来加快后续数据访问过程</li>
</ul>
<ol start="2">
<li>Zookeeper服务器</li>
</ol>
<ul>
<li>Zookeeper可以帮助选举出一个Master作为集群的总管，并保证在任何时刻总有唯一一个Master在运行，这就避免了Master的“单点失效”问题</li>
<li>Zookeeper是一个很好的集群管理工具，被大量用于分布式计算，提供配置维护、域名服务、分布式同步、组服务等。</li>
</ul>
<p><img src="https://i.loli.net/2019/08/14/nd9wWM5jDcLrSGF.jpg" alt="Zookeeper .jpg"></p>
<ol start="3">
<li>Master</li>
</ol>
<ul>
<li>主服务器Master主要负责表和Region的管理工作：<ul>
<li>管理用户对表的增加、删除、修改、查询等操作</li>
<li>实现不同Region服务器之间的负载均衡</li>
<li>在Region分裂或合并后，负责重新调整Region的分布</li>
<li>对发生故障失效的Region服务器上的Region进行迁移</li>
</ul>
</li>
</ul>
<ol start="4">
<li>Region服务器</li>
</ol>
<ul>
<li>Region服务器是HBase中最核心的模块，负责维护分配给自己的Region，并响应用户的读写请求</li>
</ul>
<h2 id="Region服务器工作原理"><a href="#Region服务器工作原理" class="headerlink" title="Region服务器工作原理"></a>Region服务器工作原理</h2><p><img src="https://i.loli.net/2019/08/14/zRVdymofpnXAkY6.jpg" alt="Region服务器向HDFS文件系统中读写数据 .jpg"></p>
<ol>
<li>用户读写数据过程<ul>
<li>用户写入数据时，被分配到相应Region服务器去执行</li>
<li>用户数据首先被写入到MemStore和Hlog中</li>
<li>只有当操作写入Hlog之后，commit()调用才会将其返回给客户端</li>
<li>当用户读取数据时，Region服务器会首先访问MemStore缓存，如果找不到，再去磁盘上面的StoreFile中寻找</li>
</ul>
</li>
<li>缓存的刷新<ul>
<li>系统会周期性地把MemStore缓存里的内容刷写到磁盘的StoreFile文件中，清空缓存，并在Hlog里面写入一个标记</li>
<li>每次刷写都生成一个新的StoreFile文件，因此，每个Store包含多个StoreFile文件</li>
<li>每个Region服务器都有一个自己的HLog 文件，每次启动都检查该文件，确认最近一次执行缓存刷新操作之后是否发生新的写入操作；如果发现更新，则先写入MemStore，再刷写到StoreFile，最后删除旧的Hlog文件，开始为用户提供服务</li>
</ul>
</li>
<li>StoreFile的合并<ul>
<li>每次刷写都生成一个新的StoreFile，数量太多，影响查找速度</li>
<li>调用Store.compact()把多个合并成一个</li>
<li>合并操作比较耗费资源，只有数量达到一个阈值才启动合并</li>
</ul>
</li>
</ol>
<h2 id="Store工作原理"><a href="#Store工作原理" class="headerlink" title="Store工作原理"></a>Store工作原理</h2><ul>
<li>Store是Region服务器的核心</li>
<li>多个StoreFile合并成一个</li>
<li>单个StoreFile过大时，又触发分裂操作，1个父Region被分裂成两个子Region<br><img src="https://i.loli.net/2019/08/14/8O5SjMrPXwiKYtB.jpg" alt="Store是Region服务器的核心 .jpg"></li>
</ul>
<h2 id="HLog工作原理"><a href="#HLog工作原理" class="headerlink" title="HLog工作原理"></a>HLog工作原理</h2><ul>
<li>分布式环境必须要考虑系统出错。HBase采用HLog保证系统恢复</li>
<li>HBase系统为每个Region服务器配置了一个HLog文件，它是一种预写式日志（Write Ahead Log）</li>
<li>用户更新数据必须首先写入日志后，才能写入MemStore缓存，并且，直到MemStore缓存内容对应的日志已经写入磁盘，该缓存内容才能被刷写到磁盘</li>
<li>Zookeeper会实时监测每个Region服务器的状态，当某个Region服务器发生故障时，Zookeeper会通知Master</li>
<li>Master首先会处理该故障Region服务器上面遗留的HLog文件，这个遗留的HLog文件中包含了来自多个Region对象的日志记录</li>
<li>系统会根据每条日志记录所属的Region对象对HLog数据进行拆分，分别放到相应Region对象的目录下，然后，再将失效的Region重新分配到可用的Region服务器中，并把与该Region对象相关的HLog日志记录也发送给相应的Region服务器</li>
<li>Region服务器领取到分配给自己的Region对象以及与之相关的HLog日志记录以后，会重新做一遍日志记录中的各种操作，把日志记录中的数据写入到MemStore缓存中，然后，刷新到磁盘的StoreFile文件中，完成数据恢复</li>
<li>共用日志优点：提高对表的写操作性能；缺点：恢复时需要分拆日志</li>
</ul>
<h1 id="HBase应用方案"><a href="#HBase应用方案" class="headerlink" title="HBase应用方案"></a>HBase应用方案</h1><h2 id="HBase实际应用中的性能优化方法"><a href="#HBase实际应用中的性能优化方法" class="headerlink" title="HBase实际应用中的性能优化方法"></a>HBase实际应用中的性能优化方法</h2><h3 id="行健（Row-Key）"><a href="#行健（Row-Key）" class="headerlink" title="行健（Row Key）"></a>行健（Row Key）</h3><ul>
<li>行键是按照字典序存储，因此，设计行键时，要充分利用这个排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放在一块。</li>
<li>举个例子：如果最近写入HBase表中的数据是最可能被访问的，可以考虑将时间戳作为行键的一部分，由于是字典序排序，所以可以使用Long.MAX_VALUE - timestamp作为行键，这样能保证新写入的数据在读取时可以被快速命中。<h3 id="Inmemory"><a href="#Inmemory" class="headerlink" title="Inmemory"></a>Inmemory</h3></li>
<li>创建表的时候，可以通过HColumnDescriptor.setInMemory(true)将表放到Region服务器的缓存中，保证在读取的时候被cache命中。<h3 id="Max-Version"><a href="#Max-Version" class="headerlink" title="Max Version"></a>Max Version</h3></li>
<li>创建表的时候，可以通过HColumnDescriptor.setMaxVersions(int maxVersions)设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置setMaxVersions(1)。<h3 id="Time-To-Live"><a href="#Time-To-Live" class="headerlink" title="Time To Live"></a>Time To Live</h3></li>
<li>创建表的时候，可以通过HColumnDescriptor.setTimeToLive(int timeToLive)设置表中数据的存储生命期，过期数据将自动被删除，例如如果只需要存储最近两天的数据，那么可以设置setTimeToLive(2 * 24 * 60 * 60)。<h2 id="HBase性能监视"><a href="#HBase性能监视" class="headerlink" title="HBase性能监视"></a>HBase性能监视</h2></li>
<li>Master-status(自带)</li>
<li>Ambari</li>
<li>OpenTSDB</li>
<li>Ganglia<h2 id="在HBase之上构建SQL引擎"><a href="#在HBase之上构建SQL引擎" class="headerlink" title="在HBase之上构建SQL引擎"></a>在HBase之上构建SQL引擎</h2></li>
<li>Hive整合HBase</li>
<li>Phoenix<h2 id="构建HBase二级索引"><a href="#构建HBase二级索引" class="headerlink" title="构建HBase二级索引"></a>构建HBase二级索引</h2></li>
<li>HBase只有一个针对行健的索引，访问HBase表中的行，只有三种方式：<ul>
<li>通过单个行健访问</li>
<li>通过一个行健的区间来访问</li>
<li>全表扫描</li>
</ul>
</li>
<li>二级索引延展<ul>
<li>Hindex二级索引</li>
<li>HBase+Redis</li>
<li>HBase+solr</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/09/14/YARN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/14/YARN/" itemprop="url">YARN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-14T19:14:41+08:00">
                2018-09-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="MapReduce-1-0-缺陷"><a href="#MapReduce-1-0-缺陷" class="headerlink" title="MapReduce 1.0 缺陷"></a>MapReduce 1.0 缺陷</h2><ol>
<li>存在单点故障</li>
<li>JobTracker“大包大揽”导致任务过重（任务多时内存开销大，上限4000节点）</li>
<li>容易出现内存溢出（分配资源只考虑MapReduce任务数，不考虑CPU、内存）</li>
<li>资源划分不合理（强制划分为slot ，包括Map slot和Reduce slot）<br><img src="https://i.loli.net/2019/08/14/N3suO6efTaCHiRJ.png" alt="MapReduce.png"><h2 id="YARN设计思路"><a href="#YARN设计思路" class="headerlink" title="YARN设计思路"></a>YARN设计思路</h2><img src="https://i.loli.net/2019/08/14/a3U6zutpq842PxB.jpg" alt="YARN思想.jpg"></li>
</ol>
<ul>
<li>MapReduce1.0既是一个计算框架，也是一个资源管理调度框架</li>
<li>到了Hadoop2.0以后，MapReduce1.0中的资源管理调度功能，被单独分离出来形成了YARN，它是一个<strong><font color="red">纯粹的资源管理调度框架</font></strong>，而不是一个计算框架</li>
<li>被剥离了资源管理调度功能的MapReduce 框架就变成了MapReduce2.0，它是运行在YARN之上的一个纯粹的计算框架，不再自己负责资源调度管理服务，而是由YARN为其提供资源管理调度服务<h2 id="YARN体系结构"><a href="#YARN体系结构" class="headerlink" title="YARN体系结构"></a>YARN体系结构</h2></li>
</ul>
<p><img src="https://i.loli.net/2019/08/14/3PfAOUQlqIabNdg.jpg" alt="YARN体系结构.jpg"></p>
<ul>
<li>ResourceManager<ul>
<li>处理客户端请求</li>
<li>启动/监控ApplicationMaster</li>
<li>监控NodeManager</li>
<li>资源分配与调度</li>
</ul>
</li>
<li>ApplicationMaster<ul>
<li>为应用程序申请资源，并分配给内部任务</li>
<li>任务调度、监控与容错</li>
</ul>
</li>
<li>NodeManager<ul>
<li>单个节点上的资源管理</li>
<li>处理来自ResourceManger的命令</li>
<li>处理来自ApplicationMaster的命令</li>
</ul>
</li>
</ul>
<h3 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h3><ul>
<li>ResourceManager（RM）是一个全局的资源管理器，负责整个系统的资源管理和分配，主要包括两个组件，即调度器（Scheduler）和应用程序管理器（Applications Manager）</li>
<li>调度器接收来自ApplicationMaster的应用程序资源请求，把集群中的资源以“容器”的形式分配给提出申请的应用程序，容器的选择通常会考虑应用程序所要处理的数据的位置，进行就近选择，从而实现“计算向数据靠拢”</li>
<li>容器（Container）作为动态资源分配单位，每个容器中都封装了一定数量的CPU、内存、磁盘等资源，从而限定每个应用程序可以使用的资源量</li>
<li>调度器被设计成是一个可插拔的组件，YARN不仅自身提供了许多种直接可用的调度器，也允许用户根据自己的需求重新设计调度器</li>
<li>应用程序管理器（Applications Manager）负责系统中所有应用程序的管理工作，主要包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动等</li>
</ul>
<h3 id="ApplicatonMaster"><a href="#ApplicatonMaster" class="headerlink" title="ApplicatonMaster"></a>ApplicatonMaster</h3><p>ResourceManager接收用户提交的作业，按照作业的上下文信息以及从NodeManager收集来的容器状态信息，启动调度过程，为用户作业启动一个ApplicationMaster</p>
<ol>
<li>当用户作业提交时，ApplicationMaster与ResourceManager协商获取资源，ResourceManager会以容器的形式为ApplicationMaster分配资源；</li>
<li>把获得的资源进一步分配给内部的各个任务（Map任务或Reduce任务），实现资源的“二次分配”；</li>
<li>与NodeManager保持交互通信进行应用程序的启动、运行、监控和停止，监控申请到的资源的使用情况，对所有任务的执行进度和状态进行监控，并在任务发生失败时执行失败恢复（即重新申请资源重启任务）；</li>
<li>定时向ResourceManager发送“心跳”消息，报告资源的使用情况和应用的进度信息；</li>
<li>当作业完成时，ApplicationMaster向ResourceManager注销容器，执行周期完成。</li>
</ol>
<h3 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h3><p>NodeManager是驻留在一个YARN集群中的每个节点上的代理，主要负责：</p>
<ul>
<li>容器生命周期管理</li>
<li>监控每个容器的资源（CPU、内存等）使用情况</li>
<li>跟踪节点健康状况</li>
<li>以“心跳”的方式与ResourceManager保持通信</li>
<li>向ResourceManager汇报作业的资源使用情况和每个容器的运行状态</li>
<li>接收来自ApplicationMaster的启动/停止容器的各种请求<br> 需要说明的是，NodeManager主要负责管理抽象的容器，只处理与容器相关的事情，而不具体负责每个任务（Map任务或Reduce任务）自身状态的管理，因为这些管理工作是由ApplicationMaster完成的，ApplicationMaster会通过不断与NodeManager通信来掌握各个任务的执行状态</li>
</ul>
<h3 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h3><p>在集群部署方面，YARN的各个组件是和Hadoop集群中的其他组件进行统一部署的<br><img src="https://i.loli.net/2019/08/14/e4LE8oCTpHQXWDa.jpg" alt="YARN部署.jpg"></p>
<h2 id="YARN工作流程"><a href="#YARN工作流程" class="headerlink" title="YARN工作流程"></a>YARN工作流程</h2><p><img src="https://i.loli.net/2019/08/14/yrhHzDjPWkf64bZ.jpg" alt="YARN工作流程.jpg"></p>
<ol>
<li>用户编写客户端应用程序，向YARN提交应用程序，提交的内容包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等</li>
<li>YARN中的ResourceManager负责接收和处理来自客户端的请求，为应用程序分配一个容器，在该容器中启动一个ApplicationMaster</li>
<li>ApplicationMaster被创建后会首先向ResourceManager注册</li>
<li>ApplicationMaster采用轮询的方式向ResourceManager申请资源</li>
<li>ResourceManager以“容器”的形式向提出申请的ApplicationMaster分配资源</li>
<li>在容器中启动任务（运行环境、脚本）</li>
<li>各个任务向ApplicationMaster汇报自己的状态和进度</li>
<li>应用程序运行完成后，ApplicationMaster向ResourceManager的应用程序管理器注销并关闭自己</li>
</ol>
<h2 id="YARN框架与MapReduce1-0框架的对比分析"><a href="#YARN框架与MapReduce1-0框架的对比分析" class="headerlink" title="YARN框架与MapReduce1.0框架的对比分析"></a>YARN框架与MapReduce1.0框架的对比分析</h2><ul>
<li>从MapReduce1.0框架发展到YARN框架，客户端并没有发生变化，其大部分调用API及接口都保持兼容，因此，原来针对Hadoop1.0开发的代码不用做大的改动，就可以直接放到Hadoop2.0平台上运行</li>
<li>总体而言，YARN相对于MapReduce1.0来说具有以下优势：<ul>
<li>大大减少了承担中心服务功能的ResourceManager的资源消耗</li>
<li>ApplicationMaster来完成需要大量资源消耗的任务调度和监控</li>
<li>多个作业对应多个ApplicationMaster，实现了监控分布化</li>
</ul>
</li>
<li>MapReduce1.0既是一个计算框架，又是一个资源管理调度框架，但是，只能支持MapReduce编程模型。而YARN则是一个纯粹的资源调度管理框架，在它上面可以运行包括MapReduce在内的不同类型的计算框架，只要编程实现相应的ApplicationMaster</li>
<li>YARN中的资源管理比MapReduce1.0更加高效<ul>
<li>以容器为单位，而不是以slot为单位<h2 id="YARN的发展目标"><a href="#YARN的发展目标" class="headerlink" title="YARN的发展目标"></a>YARN的发展目标</h2><img src="https://i.loli.net/2019/08/14/wzSyC8bfdBp6iMI.jpg" alt="YARN上各种计算框架.jpg"></li>
</ul>
</li>
<li><strong>YARN的目标就是实现“一个集群多个框架”</strong>即在一个集群上部署一个统一的资源调度管理框架YARN，在YARN之上可以部署其他各种计算框架</li>
<li>由YARN为这些计算框架提供统一的资源调度管理服务，并且能够根据各种计算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩</li>
<li>可以实现一个集群上的不同应用负载混搭，有效提高了集群的利用率</li>
<li>不同计算框架可以共享底层存储，避免了数据集跨集群移动</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/08/13/MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/13/MapReduce/" itemprop="url">MapReduce</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-13T19:08:03+08:00">
                2018-08-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="MapReduce模型"><a href="#MapReduce模型" class="headerlink" title="MapReduce模型"></a>MapReduce模型</h2><ul>
<li>MapReduce将复杂的、运行于大规模集群上的并行计算过程高度地抽象到了两个函数：Map和Reduce</li>
<li>编程容易，不需要掌握分布式并行编程细节，也可以很容易把自己的程序运行在分布式系统上，完成海量数据的计算</li>
<li>MapReduce采用<font color="red"><strong>“分而治之”</strong></font>策略，一个存储在分布式文件系统中的大规模数据集，会被切分成许多独立的分片（split），这些分片可以被多个Map任务并行处理</li>
<li>MapReduce设计的一个理念就是<font color="red"><strong>“计算向数据靠拢”</strong></font>，而不是“数据向计算靠拢”，因为，移动数据需要大量的网络传输开销</li>
<li>MapReduce框架采用了Master/Slave架构，包括一个Master和若干个Slave。Master上运行JobTracker，Slave上运行TaskTracker </li>
<li>Hadoop框架是用Java实现的，但是，MapReduce应用程序则不一定要用Java来写 </li>
</ul>
<h2 id="Map和Reduce函数"><a href="#Map和Reduce函数" class="headerlink" title="Map和Reduce函数"></a>Map和Reduce函数</h2><table>
<thead>
<tr>
<th>函数</th>
<th>输入</th>
<th>输出</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td>Map</td>
<td>&lt;k1,v1&gt;如：&lt;行号,”a b c”&gt;</td>
<td>List(&lt;k2,v2&gt;)如：&lt;“a”,1&gt;&lt;“b”,1&gt; &lt;“c”,1&gt;</td>
<td align="left">1.将小数据集进一步解析成一批&lt;key,value&gt;对，输入Map函数中进行处理 2.每一个输入的&lt;k1,v1&gt;会输出一批&lt;k2,v2&gt;。&lt;k2,v2&gt;是计算的中间结果</td>
</tr>
<tr>
<td>Reduce</td>
<td>&lt;k2,List(v2)&gt; 如：&lt;“a”,&lt;1,1,1&gt;&gt;</td>
<td>&lt;k3,v3&gt; &lt;“a”,3&gt;</td>
<td align="left">输入的中间结果&lt;k2,List(v2)&gt;中的List(v2)表示是一批属于同一个k2的value</td>
</tr>
</tbody></table>
<h2 id="MapReduce的体系结构"><a href="#MapReduce的体系结构" class="headerlink" title="MapReduce的体系结构"></a>MapReduce的体系结构</h2><p>MapReduce体系结构主要由四个部分组成，分别是：Client、JobTracker、TaskTracker以及Task<br><img src="https://i.loli.net/2019/08/14/N3suO6efTaCHiRJ.png" alt="MapReduce.png"></p>
<h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><ul>
<li>用户编写的MapReduce程序通过Client提交到JobTracker端</li>
<li>用户可通过Client提供的一些接口查看作业运行状态<h3 id="JobTracker"><a href="#JobTracker" class="headerlink" title="JobTracker"></a>JobTracker</h3></li>
<li>JobTracker负责资源监控和作业调度</li>
<li>JobTracker 监控所有TaskTracker与Job的健康状况，一旦发现失败，就将相应的任务转移到其他节点</li>
<li>JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源<h3 id="TaskTracker"><a href="#TaskTracker" class="headerlink" title="TaskTracker"></a>TaskTracker</h3></li>
<li>TaskTracker 会周期性地通过“心跳”将本节点上资源的使用情况和任务的运行进度汇报给JobTracker，同时接收JobTracker 发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）</li>
<li>TaskTracker 使用“slot”等量划分本节点上的资源量（CPU、内存等）。一个Task 获取到一个slot 后才有机会运行，而Hadoop调度器的作用就是将各个TaskTracker上的空闲slot分配给Task使用。slot 分为Map slot 和Reduce slot 两种，分别供MapTask 和Reduce Task 使用<h3 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h3></li>
<li>Task 分为Map Task 和Reduce Task 两种，均由TaskTracker 启动</li>
</ul>
<h2 id="MapReduce工作流程"><a href="#MapReduce工作流程" class="headerlink" title="MapReduce工作流程"></a>MapReduce工作流程</h2><h3 id="工作流程概述"><a href="#工作流程概述" class="headerlink" title="工作流程概述"></a>工作流程概述</h3><p><img src="https://i.loli.net/2019/08/14/6aMxLNtEWOicV5P.jpg" alt="MapReduce工作流程.jpg"></p>
<ul>
<li>不同的Map任务之间不会进行通信</li>
<li>不同的Reduce任务之间也不会发生任何信息交换</li>
<li>用户不能显式地从一台机器向另一台机器发送消息</li>
<li>所有的数据交换都是通过MapReduce框架自身去实现的<h3 id="MapReduce各个执行阶段"><a href="#MapReduce各个执行阶段" class="headerlink" title="MapReduce各个执行阶段"></a>MapReduce各个执行阶段</h3><img src="https://i.loli.net/2019/08/14/7GtfeaTjuilJyAC.jpg" alt="MapReduce各个阶段.jpg"><h4 id="关于Spilt（分片）"><a href="#关于Spilt（分片）" class="headerlink" title="关于Spilt（分片）"></a>关于Spilt（分片）</h4><img src="https://i.loli.net/2019/08/14/iBMRf2n7VOW5c9U.jpg" alt="Spilt分片.jpg"><br>HDFS 以固定大小的block 为基本单位存储数据，而对于MapReduce 而言，其处理单位是split。split 是一个逻辑概念，它只包含一些元数据信息，比如数据起始位置、数据长度、数据所在节点等。它的划分方法完全由用户自己决定。<h4 id="Map任务数量"><a href="#Map任务数量" class="headerlink" title="Map任务数量"></a>Map任务数量</h4></li>
<li>Hadoop为每个split创建一个Map任务，split 的多少决定了Map任务的数目。大多数情况下，理想的分片大小是一个HDFS块<h4 id="Reduce任务数量"><a href="#Reduce任务数量" class="headerlink" title="Reduce任务数量"></a>Reduce任务数量</h4></li>
<li>最优的Reduce任务个数取决于集群中可用的reduce任务槽(slot)的数目</li>
<li>通常设置比reduce任务槽数目稍微小一些的Reduce任务个数（这样可以预留一些系统资源处理可能发生的错误）<h3 id="Shuffle过程详解"><a href="#Shuffle过程详解" class="headerlink" title="Shuffle过程详解"></a>Shuffle过程详解</h3></li>
</ul>
<ol>
<li>Shuffle过程简介<br><img src="https://i.loli.net/2019/08/14/3NpMWh6L41Dz9IQ.jpg" alt="shuffle.jpg"></li>
<li>Map端的Shuffle过程<br><img src="https://i.loli.net/2019/08/14/5mnoagOvUxbYy19.jpg" alt="Map端shuffle.jpg"></li>
</ol>
<ul>
<li>每个Map任务分配一个缓存</li>
<li>MapReduce默认100MB缓存</li>
<li>设置溢写比例0.8</li>
<li>分区默认采用哈希函数</li>
<li>排序是默认的操作</li>
<li>排序后可以合并（Combine）</li>
<li>合并不能改变最终结果</li>
<li>在Map任务全部结束之前进行归并</li>
<li>归并得到一个大的文件，放在本地磁盘</li>
<li>文件归并时，如果溢写文件数量大于预定值（默认是3）则可以再次启动Combiner，少于3不需要</li>
<li>JobTracker会一直监测Map任务的执行，并通知Reduce任务来领取数据</li>
</ul>
<p>合并（Combine）和归并（Merge）的区别：<br>两个键值对&lt;“a”,1&gt;和&lt;“a”,1&gt;，如果合并，会得到&lt;“a”,2&gt;，如果归并，会得到&lt;“a”,&lt;1,1&gt;&gt;</p>
<ol start="3">
<li>Reduce端的shuffle过程</li>
</ol>
<ul>
<li>Reduce任务通过RPC向JobTracker询问Map任务是否已经完成，若完成，则领取数据</li>
<li>Reduce领取数据先放入缓存，来自不同Map机器，先归并，再合并，写入磁盘</li>
<li>多个溢写文件归并成一个或多个大文件，文件中的键值对是排序的</li>
<li>当数据很少时，不需要溢写到磁盘，直接在缓存中归并，然后输出给Reduce<br><img src="https://i.loli.net/2019/08/14/EkQv7xD5a9YtA4F.jpg" alt="Reduce端shuffle.jpg"><h3 id="MapReduce应用程序执行过程"><a href="#MapReduce应用程序执行过程" class="headerlink" title="MapReduce应用程序执行过程"></a>MapReduce应用程序执行过程</h3><img src="https://i.loli.net/2019/08/14/KUiuB7o6pzYZeLg.jpg" alt="MapReduce执行过程.jpg"></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/08/08/HDFS-分布式文件系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/08/HDFS-分布式文件系统/" itemprop="url">HDFS-分布式文件系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-08T18:55:50+08:00">
                2018-08-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Hadoop-分布式文件系统-HDFS"><a href="#Hadoop-分布式文件系统-HDFS" class="headerlink" title="Hadoop 分布式文件系统-HDFS"></a>Hadoop 分布式文件系统-HDFS</h1><p>分布式文件系统在物理结构上是由计算机集群中的多个节点构成的，这些节点分为两类，一类叫“主节点”(Master Node)或者也被称为“名称结点”(NameNode)，另一类叫“从节点”（Slave Node）或者也被称为“数据节点”(DataNode)<br><img src="https://i.loli.net/2019/08/13/tqh4cEsCudyDOPX.jpg" alt="图片1.jpg"></p>
<h2 id="HDFS要实现的目标如下："><a href="#HDFS要实现的目标如下：" class="headerlink" title="HDFS要实现的目标如下："></a>HDFS要实现的目标如下：</h2><ul>
<li>兼容廉价的硬件设备</li>
<li>流数据读写</li>
<li>大数据集</li>
<li>简单的文件模型</li>
<li>强大的跨平台兼容性<br>HDFS在实现以上特性同时，也使得自身有一些局限性，主要包括如下几个方面：</li>
<li>不适合低延迟数据访问</li>
<li>无法高效存储大量小文件</li>
<li>不支持多用户写入及任意修改文件</li>
</ul>
<h2 id="块"><a href="#块" class="headerlink" title="块"></a>块</h2><ul>
<li>HDFS默认一个块64MB，一个文件被分成多个块，以块作为存储单位块的大小远远大于普通文件系统，可以最小化寻址开销</li>
<li>HDFS采用抽象的块概念可以带来以下几个明显的好处：<ul>
<li>支持大规模文件存储：文件以块为单位进行存储，一个大规模文件可以被分拆成若干个文件块，不同的文件块可以被分发到不同的节点上，因此，一个文件的大小不会受到单个节点的存储容量的限制，可以远远大于网络中任意节点的存储容量</li>
<li>简化系统设计：首先，大大简化了存储管理，因为文件块大小是固定的，这样就可以很容易计算出一个节点可以存储多少文件块；其次，方便了元数据的管理，元数据不需要和文件块一起存储，可以由其他系统负责管理元数据</li>
<li>适合数据备份：每个文件块都可以冗余存储到多个节点上，大大提高了系统的容错性和可用性<h2 id="HDFS主要组件的功能"><a href="#HDFS主要组件的功能" class="headerlink" title="HDFS主要组件的功能"></a>HDFS主要组件的功能</h2></li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left"><strong>NameNode</strong></th>
<th align="left"><strong>DataNode</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">存储元数据</td>
<td align="left">存储文件内容</td>
</tr>
<tr>
<td align="left">元数据保存在内存中</td>
<td align="left">文件内容保存在磁盘上</td>
</tr>
<tr>
<td align="left">保存文件，block，datanode之间的映射关系</td>
<td align="left">维护了block id 到datanode本地文件的映射关系</td>
</tr>
</tbody></table>
<h3 id="NameNode-数据结构"><a href="#NameNode-数据结构" class="headerlink" title="NameNode 数据结构"></a>NameNode 数据结构</h3><ul>
<li>在HDFS中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构，即FsImage和EditLog<ul>
<li>FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据</li>
<li>操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作</li>
</ul>
</li>
<li>名称节点记录了每个文件中各个块所在的数据节点的位置信息<br><img src="https://i.loli.net/2019/08/13/m8GYhtLoaIpbq2d.jpg" alt="图片2.jpg"><h4 id="FsImage文件"><a href="#FsImage文件" class="headerlink" title="FsImage文件"></a>FsImage文件</h4><ul>
<li>FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据</li>
<li>FsImage文件没有记录文件包含哪些块以及每个块存储在哪个数据节点。而是由名称节点把这些映射信息保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的<h4 id="名称节点启动"><a href="#名称节点启动" class="headerlink" title="名称节点启动"></a>名称节点启动</h4></li>
<li>在名称节点启动的时候，它会将FsImage文件中的内容加载到内存中，之后再执行EditLog文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。</li>
<li>一旦在内存中成功建立文件系统元数据的映射，则创建一个新的FsImage文件和一个空的EditLog文件</li>
<li>名称节点起来之后，HDFS中的更新操作会重新写到EditLog文件中，因为FsImage文件一般都很大（GB级别的很常见），如果所有的更新操作都往FsImage文件中添加，这样会导致系统运行的十分缓慢，但是，如果往EditLog文件里面写就不会这样，因为EditLog 要小很多。每次执行写操作之后，且在向客户端发送成功代码之前，edits文件都需要同步更新<h4 id="名称节点运行期间EditLog不断变大问题"><a href="#名称节点运行期间EditLog不断变大问题" class="headerlink" title="名称节点运行期间EditLog不断变大问题"></a>名称节点运行期间EditLog不断变大问题</h4></li>
<li>在名称节点运行期间，HDFS的所有更新操作都是直接写到EditLog中，久而久之， EditLog文件将会变得很大</li>
<li>虽然这对名称节点运行时候是没有什么明显影响的，但是，当名称节点重启的时候，名称节点需要先将FsImage里面的所有内容映像到内存中，然后再一条一条地执行EditLog中的记录，当EditLog文件非常大的时候，会导致名称节点启动操作非常慢，而在这段时间内HDFS系统处于安全模式，一直无法对外提供写操作，影响了用户的使用</li>
</ul>
<strong>答案：SecondaryNameNode第二名称节点</strong><h4 id="Secondary-Namenode-工作情况"><a href="#Secondary-Namenode-工作情况" class="headerlink" title="Secondary Namenode 工作情况"></a>Secondary Namenode 工作情况</h4><img src="https://i.loli.net/2019/08/13/c8lQmqSNioyRFxM.png" alt="图片3.png"><ol>
<li>SecondaryNameNode会定期和NameNode通信，请求其停止使用EditLog文件，暂时将新的写操作写到一个新的文件edit.new上来，这个操作是瞬间完成，上层写日志的函数完全感觉不到差别；</li>
<li>SecondaryNameNode通过HTTP GET方式从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下；</li>
<li>SecondaryNameNode将下载下来的FsImage载入到内存，然后一条一条地执行EditLog文件中的各项更新操作，使得内存中的FsImage保持最新；这个过程就是EditLog和FsImage文件合并；</li>
<li>SecondaryNameNode执行完（3）操作之后，会通过post方式将新的FsImage文件发送到NameNode节点上</li>
<li>NameNode将从SecondaryNameNode接收到的新的FsImage替换旧的FsImage文件，同时将edit.new替换EditLog文件，通过这个过程EditLog就变小了<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3></li>
</ol>
<ul>
<li>数据节点是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客户端或者名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的快的列表</li>
<li>每个数据节点中的数据会被保存在各自节点的本地linux文件系统中<h2 id="FDHS体系结构"><a href="#FDHS体系结构" class="headerlink" title="FDHS体系结构"></a>FDHS体系结构</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3>HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群包括一个名称节点（NameNode）和若干个数据节点（DataNode）（如图3-4所示）。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。每个数据节点的数据实际上是保存在本地Linux文件系统中的<br><img src="https://i.loli.net/2019/08/13/WG3cMdAf8KLiSHe.jpg" alt="图片4.jpg"><h3 id="命名空间管理"><a href="#命名空间管理" class="headerlink" title="命名空间管理"></a>命名空间管理</h3></li>
<li>HDFS的命名空间包含目录、文件和块</li>
<li>在HDFS1.0体系架构中，在整个HDFS集群中只有一个命名空间，并且只有唯一一个名称节点，该节点负责这个命名空间进行管理</li>
<li>HDFS使用传统的分级文件系统，因此用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录间转移文件，重命名文件等<h3 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h3></li>
<li>HDFS是一个部署在集群上的分布式文件系统，因此，很多数据需要通过网络进行传输</li>
<li>所有的HDFS通信协议都是构建在TCP/IP协议基础之上的</li>
<li>客户端通过一个可配置的端口向名称节点主动发起TCP连接，并使用客户端协议与名称节点进行交互</li>
<li>名称节点和数据节点之间则使用数据节点协议进行交互</li>
<li>客户端与数据节点的交互是通过RPC（Remote Procedure Call）来实现的。在设计上，名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求<h3 id="client"><a href="#client" class="headerlink" title="client"></a>client</h3></li>
<li>客户端是用户操作HDFS最常用的方式，HDFS在部署时都提供了客户端</li>
<li>HDFS客户端是一个库，暴露了HDFS文件系统接口，这些接口隐藏了HDFS实现中的大部分复杂性</li>
<li>严格来说，客户端并不算是HDFS的一部分</li>
<li>客户端可以支持打开、读取、写入等常见的操作，并且提供了类似Shell的命令行方式来访问HDFS中的数据</li>
<li>此外，HDFS也提供了Java API，作为应用程序访问文件系统的客户端编程接口<h3 id="HDFS体系结构的局限性"><a href="#HDFS体系结构的局限性" class="headerlink" title="HDFS体系结构的局限性"></a>HDFS体系结构的局限性</h3></li>
</ul>
</li>
</ul>
<ol>
<li>命名空间的限制：名称节点是保存在内存中的，因此，名称节点能够容纳的对象（文件、块）的个数会受到内存空间大小的限制。</li>
<li>性能的瓶颈：整个分布式文件系统的吞吐量，受限于单个名称节点的吞吐量。</li>
<li>隔离问题：由于集群中只有一个名称节点，只有一个命名空间，因此，无法对不同应用程序进行隔离。</li>
<li>集群的可用性：一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用<h2 id="HDFS存储原理"><a href="#HDFS存储原理" class="headerlink" title="HDFS存储原理"></a>HDFS存储原理</h2><h3 id="冗余数据保存"><a href="#冗余数据保存" class="headerlink" title="冗余数据保存"></a>冗余数据保存</h3>作为一个分布式文件系统，为了保证系统的容错性和可用性，HDFS采用了多副本方式对数据进行冗余存储，通常一个数据块的多个副本会被分布到不同的数据节点上，如图所示，数据块1被分别存放到数据节点A和C上，数据块2被存放在数据节点A和B上。这种多副本方式具有以下几个优点：<br><img src="https://i.loli.net/2019/08/14/o2ztn561hLSlrKw.jpg" alt="数据块副本.jpg"><ol>
<li>加快数据传输速度</li>
<li>容易检查数据错误</li>
<li>保证数据可靠性<h3 id="数据存取策略"><a href="#数据存取策略" class="headerlink" title="数据存取策略"></a>数据存取策略</h3><h4 id="数据存放"><a href="#数据存放" class="headerlink" title="数据存放"></a>数据存放</h4><img src="https://i.loli.net/2019/08/14/aehmCizsqG9dM38.jpg" alt="数据副本放置策略.jpg"></li>
</ol>
<ul>
<li>第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点</li>
<li>第二个副本：放置在与第一个副本不同的机架的节点上</li>
<li>第三个副本：与第一个副本相同机架的其他节点上</li>
<li>更多副本：随机节点<h4 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h4></li>
<li>HDFS提供了一个API可以确定一个数据节点所属的机架ID，客户端也可以调用API获取自己所属的机架ID</li>
<li>当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含了副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID，当发现某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择该副本读取数据，如果没有发现，就随机选择一个副本读取数据<h3 id="数据错误与恢复"><a href="#数据错误与恢复" class="headerlink" title="数据错误与恢复"></a>数据错误与恢复</h3>HDFS具有较高的容错性，可以兼容廉价的硬件，它把硬件出错看作一种常态，而不是异常，并设计了相应的机制检测数据错误和进行自动恢复，主要包括以下几种情形：名称节点出错、数据节点出错和数据出错。<h4 id="名称节点出错"><a href="#名称节点出错" class="headerlink" title="名称节点出错"></a>名称节点出错</h4>名称节点保存了所有的元数据信息，其中，最核心的两大数据结构是FsImage和Editlog，如果这两个文件发生损坏，那么整个HDFS实例将失效。因此，HDFS设置了备份机制，把这些核心文件同步复制到备份服务器SecondaryNameNode上。当名称节点出错时，就可以根据备份服务器SecondaryNameNode中的FsImage和Editlog数据进行恢复。<h4 id="数据节点出错"><a href="#数据节点出错" class="headerlink" title="数据节点出错"></a>数据节点出错</h4></li>
<li>每个数据节点会定期向名称节点发送“心跳”信息，向名称节点报告自己的状态</li>
<li>当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节点的心跳信息，这时，这些数据节点就会被标记为“机”，节点上面的所有数据都会被标记为“不可读”，名称节点不会再给它们发送任何I/O请求</li>
<li>这时，有可能出现一种情形，即由于一些数据节点的不可用，会导致一些数据块的副本数量小于冗余因子</li>
<li>名称节点会定期检查这种情况，一旦发现某个数据块的副本数量小于冗余因子，就会启动数据冗余复制，为它生成新的副本</li>
<li><strong>HDFS和其它分布式文件系统的最大区别就是可以调整冗余数据的位置</strong><h4 id="数据出错"><a href="#数据出错" class="headerlink" title="数据出错"></a>数据出错</h4></li>
<li>网络传输和磁盘错误等因素，都会造成数据错误</li>
<li>客户端在读取到数据后，会采用md5和sha1对数据块进行校验，以确定读取到正确的数据</li>
<li>在文件被创建时，客户端就会对每一个文件块进行信息摘录，并把这些信息写入到同一个路径的隐藏文件里面</li>
<li>当客户端读取文件的时候，会先读取该信息文件，然后，利用该信息文件对每个读取的数据块进行校验，如果校验出错，客户端就会请求到另外一个数据节点读取该文件块，并且向名称节点报告这个文件块有错误，名称节点会定期检查并且重新复制这个块<h1 id="Hadoop-HDFS-2-0"><a href="#Hadoop-HDFS-2-0" class="headerlink" title="Hadoop HDFS 2.0"></a>Hadoop HDFS 2.0</h1></li>
</ul>
</li>
</ol>
<h2 id="Hadoop-1-0-局限与不足"><a href="#Hadoop-1-0-局限与不足" class="headerlink" title="Hadoop 1.0 局限与不足"></a>Hadoop 1.0 局限与不足</h2><p>Hadoop1.0的核心组件（仅指MapReduce和HDFS，不包括Hadoop生态系统内的Pig、Hive、HBase等其他组件），主要存在以下不足：</p>
<ul>
<li>抽象层次低，需人工编码</li>
<li>表达能力有限</li>
<li>开发者自己管理作业（Job）之间的依赖关系</li>
<li>难以看到程序整体逻辑</li>
<li>执行迭代操作效率低</li>
<li>资源浪费（Map和Reduce分两阶段执行）</li>
<li>实时性差（适合批处理，不支持实时交互式）</li>
</ul>
<h2 id="自身框架改进与提升"><a href="#自身框架改进与提升" class="headerlink" title="自身框架改进与提升"></a>自身框架改进与提升</h2><table>
<thead>
<tr>
<th>组件</th>
<th>Hadoop1.0的问题</th>
<th>Hadoop2.0的改进</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>单一名称节点，存在单点失效问题</td>
<td>设计了HDFS HA，提供名称节点热备机制</td>
</tr>
<tr>
<td>HDFS</td>
<td>单一命名空间，无法实现资源隔离</td>
<td>设计了HDFS Federation，管理多个命名空间</td>
</tr>
<tr>
<td>MapReduce</td>
<td>资源管理效率低</td>
<td>设计了新的资源管理框架YARN</td>
</tr>
</tbody></table>
<h2 id="HDFS2-0的新特性"><a href="#HDFS2-0的新特性" class="headerlink" title="HDFS2.0的新特性"></a>HDFS2.0的新特性</h2><h3 id="HDFS-HA"><a href="#HDFS-HA" class="headerlink" title="HDFS HA"></a>HDFS HA</h3><ul>
<li>第二名称节点（SecondaryNameNode）无法解决单点故障问题<ul>
<li>不是热备份</li>
<li>要是防止日志文件EditLog过大，导致名称节点失败恢复时消耗过多时间</li>
<li>附带起到冷备份功能</li>
</ul>
</li>
<li>HDFS HA（High Availability）是为了解决单点故障问题</li>
<li>HA集群设置两个名称节点，“活跃（Active）”和“待命（Standby）”</li>
<li>两种名称节点的状态同步，可以借助于一个<strong>共享存储系统</strong>来实现</li>
<li>一旦活跃名称节点出现故障，就可以立即切换到待命名称节点</li>
<li>Zookeeper确保一个名称节点在对外服务</li>
<li>名称节点维护映射信息，数据节点同时向两个名称节点汇报信息<br><img src="https://i.loli.net/2019/08/14/PAzmeqEVokFUHgG.jpg" alt="HDFS HA.jpg"></li>
</ul>
<h3 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h3><h4 id="HDFS1-0中存在的问题"><a href="#HDFS1-0中存在的问题" class="headerlink" title="HDFS1.0中存在的问题"></a>HDFS1.0中存在的问题</h4><ul>
<li>单点故障问题</li>
<li>不可以水平扩展（是否可以通过纵向扩展来解决？）</li>
<li>系统整体性能受限于单个名称节点的吞吐量</li>
<li>单个名称节点难以提供不同程序之间的隔离性</li>
<li>HDFS HA是热备份，提供高可用性，但是无法解决可扩展性、系统性能和隔离性<h4 id="HDFS-Federation-设计"><a href="#HDFS-Federation-设计" class="headerlink" title="HDFS Federation 设计"></a>HDFS Federation 设计</h4></li>
<li>在HDFS Federation中，设计了多个相互独立的名称节点，使得HDFS的命名服务能够水平扩展，这些名称节点分别进行各自命名空间和块的管理，相互之间是联盟（Federation）关系，不需要彼此协调。并且向后兼容</li>
<li>HDFS Federation中，所有名称节点会共享底层的数据节点存储资源，数据节点向所有名称节点汇报</li>
<li>属于同一个命名空间的块构成一个“块池”<br><img src="https://i.loli.net/2019/08/14/WsQN43FHywPftOu.jpg" alt="HDFS Federation架构.jpg"></li>
</ul>
<h4 id="HDFS-Federation访问方式"><a href="#HDFS-Federation访问方式" class="headerlink" title="HDFS Federation访问方式"></a>HDFS Federation访问方式</h4><ul>
<li>对于Federation中的多个命名空间，可以采用客户端挂载表（Client Side Mount Table）方式进行数据共享和访问</li>
<li>客户可以访问不同的挂载点来访问不同的子命名空间</li>
<li>把各个命名空间挂载到全局“挂载表”（mount-table）中，实现数据全局共享</li>
<li>同样的命名空间挂载到个人的挂载表中，就成为应用程序可见的命名空间<h4 id="HDFS-Federation相对于HDFS1-0的优势"><a href="#HDFS-Federation相对于HDFS1-0的优势" class="headerlink" title="HDFS Federation相对于HDFS1.0的优势"></a>HDFS Federation相对于HDFS1.0的优势</h4></li>
</ul>
<ol>
<li>HDFS集群扩展性。多个名称节点各自分管一部分目录，使得一个集群可以扩展到更多节点，不再像HDFS1.0中那样由于内存的限制制约文件存储数目</li>
<li>性能更高效。多个名称节点管理不同的数据，且同时对外提供服务，将为用户提供更高的读写吞吐率</li>
<li>良好的隔离性。用户可根据需要将不同业务数据交由不同名称节点管理，这样不同业务之间影响很小</li>
</ol>
<p>需要注意的，HDFS Federation并不能解决单点故障问题，也就是说，每个名称节点都存在在单点故障问题，需要为每个名称节点部署一个后备名称节点，以应对名称节点挂掉对业务产生的影响</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2018/08/03/大数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/03/大数据/" itemprop="url">大数据概述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-03T22:00:08+08:00">
                2018-08-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="大数据概述"><a href="#大数据概述" class="headerlink" title="大数据概述"></a>大数据概述</h1><p>大数据思维导图(点击链可以展开详细)<br><img src="https://i.loli.net/2019/08/13/n7zpOUBKujb4tr1.png" alt="大数据 (1).png"><br>(<a href="https://www.processon.com/view/link/5b9b6867e4b06fc64af4b823" target="_blank" rel="noopener">https://www.processon.com/view/link/5b9b6867e4b06fc64af4b823</a>)</p>
<ul>
<li>数据产生方式变革<ul>
<li>运营式阶段：数据库使得数据管理复杂度降低，数据往往伴随着一定的运营活动产生记录，生产方式是被动的</li>
<li>用户原创内容阶段：Web2.0时代，用户原创成为标志，智能手机加速内容产生，数据产生方式是主动的</li>
<li>感知式系统阶段：感知系统广泛使用</li>
</ul>
</li>
<li>大数据发展历程</li>
</ul>
<table>
<thead>
<tr>
<th><strong>阶段</strong></th>
<th><strong>时间</strong></th>
<th><strong>内容</strong></th>
</tr>
</thead>
<tbody><tr>
<td>第一阶段：萌芽期</td>
<td>上世纪90年代至本世纪初</td>
<td>随着数据挖掘理论和数据库技术的逐步成熟，一批商业智能工具和知识管理技术开始被应用，如数据仓库、专家系统、知识管理系统等。</td>
</tr>
<tr>
<td>第二阶段：成熟期</td>
<td>本世纪前十年</td>
<td>Web2.0应用迅猛发展，非结构化数据大量产生，传统处理方法难以应对，带动了大数据技术的快速突破，大数据解决方案逐渐走向成熟，形成了并行计算与分布式系统两大核心技术，谷歌的GFS和MapReduce等大数据技术受到追捧，Hadoop平台开始大行其道</td>
</tr>
<tr>
<td>第三阶段：大规模应用期</td>
<td>2010年以后</td>
<td>大数据应用渗透各行各业，数据驱动决策，信息社会智能化程度大幅提高</td>
</tr>
</tbody></table>
<ul>
<li>大数据概念<ul>
<li>大量化 Volume</li>
<li>快速化 Velocity （1秒定律）</li>
<li>多样化 Variety</li>
<li>价值化  Value  价值密度低，商业价值高</li>
</ul>
</li>
<li>大数据影响<ul>
<li>科学研究：先后经历了实验、理论、计算和数据四中范式<br><img src="https://i.loli.net/2019/08/13/aFXqhifzbmRLVGK.png" alt="图片1.png"></li>
<li>思维方面（摘自《大数据时代》）<ul>
<li>全样儿非抽样</li>
<li>效率而非精确</li>
<li>相关而非因果   </li>
</ul>
</li>
</ul>
</li>
<li>大数据应用<ul>
<li>智能医疗研发</li>
<li>监控身体情况</li>
<li>研发智能汽车</li>
<li>实时掌控交通情况，改善日常生活</li>
<li>金融交易</li>
<li>业务流程优化</li>
</ul>
</li>
<li>大数据关键技术</li>
</ul>
<table>
<thead>
<tr>
<th><strong>技术层面</strong></th>
<th align="left"><strong>功能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>数据采集</td>
<td align="left">利用ETL工具将分布的、异构数据源中的数据如关系数据、平面数据文件等，抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础；或者也可以把实时采集的数据作为流计算系统的输入，进行实时处理分析</td>
</tr>
<tr>
<td>数据存储和管理</td>
<td align="left">利用分布式文件系统、数据仓库、关系数据库、NoSQL数据库、云数据库等，实现对结构化、半结构化和非结构化海量数据的存储和管理</td>
</tr>
<tr>
<td>数据处理与分析</td>
<td align="left">利用分布式并行编程模型和计算框架，结合机器学习和数据挖掘算法，实现对海量数据的处理和分析；对分析结果进行可视化呈现，帮助人们更好地理解数据、分析数据</td>
</tr>
<tr>
<td>数据隐私和安全</td>
<td align="left">在从大数据中挖掘潜在的巨大商业价值和学术价值的同时，构建隐私数据保护体系和数据安全体系，有效保护个人隐私和数据安全</td>
</tr>
</tbody></table>
<ul>
<li><p>两大核心技术<br><img src="https://i.loli.net/2019/08/13/OYDRiAm1vBK2cjw.png" alt="图片2.png"></p>
</li>
<li><p>大数据计算模式</p>
</li>
</ul>
<table>
<thead>
<tr>
<th><strong>大数据计算模式</strong></th>
<th><strong>解决问题</strong></th>
<th><strong>代表产品</strong></th>
</tr>
</thead>
<tbody><tr>
<td>批处理计算</td>
<td>针对大规模数据的批量处理</td>
<td>MapReduce、Spark等</td>
</tr>
<tr>
<td>流计算</td>
<td>针对流数据的实时计算</td>
<td>Storm、S4、Flume、Streams、Puma、DStream、Super Mario、银河流数据处理平台等</td>
</tr>
<tr>
<td>图计算</td>
<td>针对大规模图结构数据的处理</td>
<td>Pregel、GraphX、Giraph、PowerGraph、Hama、GoldenOrb等</td>
</tr>
<tr>
<td>查询分析计算</td>
<td>大规模数据的存储管理和查询分析</td>
<td>Dremel、Hive、Cassandra、Impala等</td>
</tr>
</tbody></table>
<ul>
<li>大数据产业</li>
</ul>
<table>
<thead>
<tr>
<th align="center"><strong>产业链环节</strong></th>
<th><strong>包含内容</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">IT基础设施层</td>
<td>包括提供硬件、软件、网络等基础设施以及提供咨询、规划和系统集成服务的企业，比如，提供数据中心解决方案的IBM、惠普和戴尔等，提供存储解决方案的EMC，提供虚拟化管理软件的微软、思杰、SUN、Redhat等</td>
</tr>
<tr>
<td align="center">数据源层</td>
<td>大数据生态圈里的数据提供者，是生物大数据（生物信息学领域的各类研究机构）、交通大数据（交通主管部门）、医疗大数据（各大医院、体检机构）、政务大数据（政府部门）、电商大数据（淘宝、天猫、苏宁云商、京东等电商）、社交网络大数据（微博、微信、人人网等）、搜索引擎大数据（百度、谷歌等）等各种数据的来源</td>
</tr>
<tr>
<td align="center">数据管理层</td>
<td>包括数据抽取、转换、存储和管理等服务的各类企业或产品，比如分布式文件系统（如Hadoop的HDFS和谷歌的GFS）、ETL工具（Informatica、Datastage、Kettle等）、数据库和数据仓库（Oracle、MySQL、SQL Server、HBase、GreenPlum等）</td>
</tr>
<tr>
<td align="center">数据分析层</td>
<td>包括提供分布式计算、数据挖掘、统计分析等服务的各类企业或产品，比如，分布式计算框架MapReduce、统计分析软件SPSS和SAS、数据挖掘工具Weka、数据可视化工具Tableau、BI工具（MicroStrategy、Cognos、BO）等等</td>
</tr>
<tr>
<td align="center">数据平台层</td>
<td>包括提供数据分享平台、数据分析平台、数据租售平台等服务的企业或产品，比如阿里巴巴、谷歌、中国电信、百度等</td>
</tr>
<tr>
<td align="center">数据应用层</td>
<td>提供智能交通、智慧医疗、智能物流、智能电网等行业应用的企业、机构或政府部门，比如交通主管部门、各大医疗机构、菜鸟网络、国家电网等</td>
</tr>
</tbody></table>
<ul>
<li>大数据、云计算、物联网关系</li>
</ul>
<p><img src="https://i.loli.net/2019/08/13/LNPauHj28IFpZn6.jpg" alt="图片3.jpg"></p>
<h1 id="Hadoop-概述（Hadoop-2-0）"><a href="#Hadoop-概述（Hadoop-2-0）" class="headerlink" title="Hadoop 概述（Hadoop 2.0）"></a>Hadoop 概述（Hadoop 2.0）</h1><p> Hadoop 是 Apache 基金会下的一个开源分布式计算平台，以 <strong><font color="red">HDFS 分布式文件系统</font></strong> 和 <strong><font color="red">MapReduce</font></strong> 分布式计算框架为核心，为用户提供底层细节透明的分布式基础设施。目前，Hadoop 是分析海量数据的首选工具。Hadoop 是一个可以更容易开发和并行处理大规模数据的分布式计算平台，它的主要特点是扩展能力强、成本低、高效率和可靠。目前，Hadoop 的用户已经从传统的互联网公司，扩展到了各个行业，并且得到越来越广泛的应用。它的优势包括：</p>
<ol>
<li>方便：Hadoop 可以运行在商业机器集群上，或者Amazon EC2 等云计算服务商</li>
<li>弹性：Hadoop 可以方便增加和减少集群节点</li>
<li>健壮：Hadoop 可以从容处理常见的硬件失效情况</li>
<li>简单：Hadoop 允许用户快速高效编写并行分布代码<h2 id="Hadoop-项目结构"><a href="#Hadoop-项目结构" class="headerlink" title="Hadoop 项目结构"></a>Hadoop 项目结构</h2><img src="https://i.loli.net/2019/08/13/LEQbCB2q53mphVo.png" alt="hadoop项目结构.png"></li>
</ol>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>功能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>分布式文件系统</td>
</tr>
<tr>
<td>MapReduce</td>
<td>分布式并行编程模型</td>
</tr>
<tr>
<td>YARN</td>
<td>资源管理和调度器</td>
</tr>
<tr>
<td>Tez</td>
<td>运行在YARN之上的下一代Hadoop查询处理框架</td>
</tr>
<tr>
<td>Hive</td>
<td>Hadoop上的数据仓库</td>
</tr>
<tr>
<td>HBase</td>
<td>Hadoop上的非关系型的分布式数据库</td>
</tr>
<tr>
<td>Pig</td>
<td>一个基于Hadoop的大规模数据分析平台，提供类似SQL的查询语言Pig Latin</td>
</tr>
<tr>
<td>Sqoop</td>
<td>用于在Hadoop与传统数据库之间进行数据传递</td>
</tr>
<tr>
<td>Oozie</td>
<td>Hadoop上的工作流管理系统</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>提供分布式协调一致性服务</td>
</tr>
<tr>
<td>Storm</td>
<td>流计算框架</td>
</tr>
<tr>
<td>Flume</td>
<td>一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统</td>
</tr>
<tr>
<td>Ambari</td>
<td>Hadoop快速部署工具，支持Apache Hadoop集群的供应、管理和监控</td>
</tr>
<tr>
<td>Kafka</td>
<td>一种高吞吐量的分布式发布订阅消息系统，可以处理消费者规模的网站中的所有动作流数据</td>
</tr>
<tr>
<td>Spark</td>
<td>类似于Hadoop MapReduce的通用并行框架</td>
</tr>
</tbody></table>
<ul>
<li>HDFS有着高容错特点，并且设计用来部署在低廉的硬件之上，适合有着超量大数据集的应用程序</li>
<li>MapReduce：Hadoop编程模型，用于大规模数据及（大于1TB）的并行计算。MR是离线处理框架，由编程模型、运行时环境（JobTracker和TaskTracker）和数据处理引擎（MapTask和ReduceTask）三部分组成</li>
<li>HBase:基于列存储模型的分布式数据库，专用用于Hadoop档案系统上的资料库系统，采用Column-Oriented设计，不同于传统关系型数据库，没有资料表、Schema等规范，而是采用Key-Value形式的架构，采用多维度的对应关系建立类似于表格效果的资料架构。如此采用分布式存储方式，可以扩充到前台服务器，应付PB级资料处理</li>
<li>Hive：可用SQL语法存储Hadoop资料的工具。<ul>
<li>Hive是建置在HDFS上的一套分散式资料仓储系统，可让使用者以惯用的SQL语法，来存取Hadoop档案中的大型资料集，例如可以使用Join、Group by、Order by等，而这个语法称为Hive QL。Hive 提供完整的 SQL 查询功能，可以将 SQL 语句转换为 MR 任务进行运行。不过，Hive QL和SQL并非完全相同，例如Hive就不支援Store Procedure、Trigger等功能。</li>
<li>Hive会将使用者输入的Hive QL指令编译成Java程序，再来存取HDFS档案系统上的资料，所以，执行效率依指令复杂度和处理的资料量而异，可能有数秒鐘，甚至是数分鐘的延迟。和HBase相比，Hive容易使用且弹性高，但执行速度较慢。不少资料库系统，都是透过先连结到Hive，才能与Hadoop整合。例如微软就是透过Hive ODBC驱动程序，将SQL指令转换成Hive QL，让Excel可以存取Hadoop上的资料。</li>
<li>在同一个Hadoop集群中，Hive可以存取HBase上的资料，将HBase上的资料对应成Hive内的一个表格</li>
</ul>
</li>
<li>Pig：基于Hadoop分析组件，Pig 为复杂的海量数据并行计算提供一个简易的操作和编程接口。它提供了一个Script语言Pig Latin，语法简单，类似可读性高的高阶Basic语言，可用来撰写MapReduce程序。Pig会自动将这些脚本程序转换，成为能在Hadoop中执行的MapReduce Java程序。因此，使用者即使不懂Java也能撰写出MapReduce。<br>Zookeeper：是一个高效的可扩展的资源协调系统，存储和协调关键共享状态。它监控和协调 Hadoop 分散式运作的集中式服务，可提供各个服务器的配置和运作状态资讯，用於提供不同Hadoop系统角色之间的工作协调。<ul>
<li>以HBase资料库为例，其中有两种服务器角色：Region服务器角色和Master服务器角色，系统会自动透过ZooKeeper监看Master服务器的状态，一旦Master的运作资讯消失，代表当机或网路断线，HBase就会选出另一台Region服务器成为Mater角色来负责管理工作。<ul>
<li>可等同于etcd功能</li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">seven</p>
              <p class="site-description motion-element" itemprop="description">seven 的精神家园，学习笔记</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="1988xuegang@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">seven</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
