<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="kubernetes,">










<meta name="description" content="Kubernetes 架构 Kubernetes借鉴了Brog的设计理念，比如Pod、Service、Lables和单Pod单IP等。整体架构如下所示   etcd保存了集群的状态信息  kube-apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现机制  kube-controller-manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等">
<meta name="keywords" content="kubernetes">
<meta property="og:type" content="article">
<meta property="og:title" content="Kubernetes 架构">
<meta property="og:url" content="http://sevengarden.club/2019/08/12/Kubernetes-架构/index.html">
<meta property="og:site_name" content="岳阳北寒">
<meta property="og:description" content="Kubernetes 架构 Kubernetes借鉴了Brog的设计理念，比如Pod、Service、Lables和单Pod单IP等。整体架构如下所示   etcd保存了集群的状态信息  kube-apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现机制  kube-controller-manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://i.loli.net/2019/08/12/Wcv4PLCFgJ26imV.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/WyA6Jpo52BINwm8.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/xEBCcQ1YHAhqgP3.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/vmC7XRnEJpOoHzb.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/BXUHhx5ofuyJsL2.jpg">
<meta property="og:image" content="https://i.loli.net/2019/08/12/PO76KHBXYpUveaW.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/3TdApJyxroRDPg9.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/wlO8dfNvkq3r9sy.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/GzcCtOFyV7pnHBX.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/eg53NY8LvBa91q7.png">
<meta property="og:image" content="https://i.loli.net/2019/08/12/RyPTzkrf1qw5VKg.png">
<meta property="og:image" content="https://i.loli.net/2019/08/13/5GwXKSWfODuFaVt.png">
<meta property="og:image" content="https://i.loli.net/2019/08/13/FDv8ZWuRi3X5SCg.png">
<meta property="og:image" content="https://i.loli.net/2019/08/13/kV82oOjNUX6dQzC.png">
<meta property="og:updated_time" content="2019-08-26T11:28:53.541Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kubernetes 架构">
<meta name="twitter:description" content="Kubernetes 架构 Kubernetes借鉴了Brog的设计理念，比如Pod、Service、Lables和单Pod单IP等。整体架构如下所示   etcd保存了集群的状态信息  kube-apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现机制  kube-controller-manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等">
<meta name="twitter:image" content="https://i.loli.net/2019/08/12/Wcv4PLCFgJ26imV.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://sevengarden.club/2019/08/12/Kubernetes-架构/">





  <title>Kubernetes 架构 | 岳阳北寒</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">岳阳北寒</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">要有最朴素的生活和最遥远的梦想，即使明日天寒地冻，路远马亡.......</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-somrthing">
          <a href="/有料" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            somrthing
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sevengarden.club/2019/08/12/Kubernetes-架构/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="seven">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="岳阳北寒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Kubernetes 架构</h1>
        

        <div class="post-meta">
          
                    <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-12T18:51:51+08:00">
                2019-08-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/K8S/" itemprop="url" rel="index">
                    <span itemprop="name">K8S</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Kubernetes-架构"><a href="#Kubernetes-架构" class="headerlink" title="Kubernetes 架构"></a>Kubernetes 架构</h1><p> Kubernetes借鉴了Brog的设计理念，比如Pod、Service、Lables和单Pod单IP等。整体架构如下所示</p>
<p><img src="https://i.loli.net/2019/08/12/Wcv4PLCFgJ26imV.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6lf7UjRFyBsrhpw_components.png"></p>
<ul>
<li><p>etcd保存了集群的状态信息</p>
</li>
<li><p>kube-apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现机制</p>
</li>
<li><p>kube-controller-manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等</p>
</li>
<li><p>kube-scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上</p>
</li>
<li><p>kubelet 负责维持容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理</p>
</li>
<li><p>Container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI），默认的容器运行时为 Docker；</p>
</li>
<li><p>kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡</p>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/12/WyA6Jpo52BINwm8.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6ljrf3pM1bbtQ_0_core-packages.png"></p>
<p>除了核心组件，还有一些推荐的 Add-ons：</p>
<ul>
<li><p>kube-dns 负责为整个集群提供 DNS 服务</p>
</li>
<li><p>Ingress Controller 为服务提供外网入口</p>
</li>
<li><p>Heapster 提供资源监控</p>
</li>
<li><p>Dashboard 提供 GUI</p>
</li>
<li><p>Federation 提供跨可用区的集群</p>
</li>
<li><p>Fluentd-elasticsearch 提供集群日志采集、存储与查询</p>
</li>
</ul>
<h2 id="分层架构"><a href="#分层架构" class="headerlink" title="分层架构"></a>分层架构</h2><p><img src="https://i.loli.net/2019/08/12/xEBCcQ1YHAhqgP3.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6lnG-e8vfXmSbwl_core-ecosystem.png"></p>
<ul>
<li>核心层：Kubernetes 最核心的功能，对外提供 API 构建高层的应用，对内提供插件式应用执行环境</li>
<li>应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS 解析等）</li>
<li>管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态 Provision 等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy 等）</li>
<li>接口层：kubectl 命令行工具、客户端 SDK 以及集群联邦</li>
<li>生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴<ul>
<li>Kubernetes 外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS 应用、ChatOps 等</li>
<li>Kubernetes 内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等</li>
</ul>
</li>
</ul>
<h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><p><img src="https://i.loli.net/2019/08/12/vmC7XRnEJpOoHzb.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6llZfuE65sGzUkc_core-apis.png"></p>
<h2 id="核心API"><a href="#核心API" class="headerlink" title="核心API"></a>核心API</h2><p><img src="https://i.loli.net/2019/08/12/BXUHhx5ofuyJsL2.jpg" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6lhezSJ3ufUcmlH_14937095836427.jpg"></p>
<h2 id="生态系统"><a href="#生态系统" class="headerlink" title="生态系统"></a>生态系统</h2><p><img src="https://i.loli.net/2019/08/12/PO76KHBXYpUveaW.png" alt="assets_-LDAOok5ngY4pc1lEDes_-La8Wy3SQAP-8onLZ7uT_-La8X6ldNQWZNfl3OJ9M_architecture.png"></p>
<h1 id="设计理念"><a href="#设计理念" class="headerlink" title="设计理念"></a>设计理念</h1><h2 id="API设计原则"><a href="#API设计原则" class="headerlink" title="API设计原则"></a>API设计原则</h2><ol>
<li><p>所有API都是声明式</p>
</li>
<li><p>API对象比西湖不而且可组合</p>
</li>
<li><p>高层API以操作意图为基础设计</p>
</li>
<li><p>底层API更具高层API的控制需要设计</p>
</li>
<li><p>尽量避免简单封装，不要有外部API无法显式知道内部隐藏的机制</p>
</li>
<li><p>API操作复杂度与对象数量成正比</p>
</li>
<li><p>API对象状态不能依赖于网络连接状态</p>
</li>
<li><p>尽量避免让操作机制依赖于全局状态，分布式系统中要保证全局状态的同步是非常困难的</p>
<h2 id="控制设计原则"><a href="#控制设计原则" class="headerlink" title="控制设计原则"></a>控制设计原则</h2></li>
</ol>
<ul>
<li>控制逻辑只依赖于当前状态</li>
<li>假设任何错误的可能，并做容错助理</li>
<li>尽量避免复杂状态机制，控制逻辑不要依赖无法监控的内部状态</li>
<li>假设任何操作都可能被任何操作对象拒绝，甚至错误解析</li>
<li>每个模块都可以在出错之后自动恢复</li>
<li>每个模块都可以在必要时优雅地降级服务<h2 id="架构设计原则"><a href="#架构设计原则" class="headerlink" title="架构设计原则"></a>架构设计原则</h2></li>
<li>只有apiserver可以直接访问etcd存储，其他服务必须通过KubernetesAPI来访问集群状态</li>
<li>单点故障不影响集群状态</li>
<li>在没有新请求的情况下，所有组件应该在故障恢复后继续执行上次最后收到的请求（比如网络分区或服务重启等）</li>
<li>所有组件都应该在内存中保持所需要的状态，apiserver将状态写入etcd存储，而其他组件则通过apiserver更新并监听所有的变化</li>
<li>优先使用事件监听而不是轮询<h1 id="核心技术概念和API对象"><a href="#核心技术概念和API对象" class="headerlink" title="核心技术概念和API对象"></a>核心技术概念和API对象</h1></li>
</ul>
<p>API对象是K8s集群中的管理操作单元。K8s集群系统每支持一项新功能，引入一项新技术，一定会新引入对应的API对象，支持对该功能的管理操作。例如副本集Replica Set对应的API对象是RS。</p>
<p>每个API对象都有3大类属性：<font color="red"><strong>元数据metadata、规范spec和状态status</strong></font>。元数据是用来标识API对象的，每个对象都至少有3个元数据：namespace，name和uid；除此以外还有各种各样的标签labels用来标识和匹配不同的对象，例如用户可以用标签env来标识区分不同的服务部署环境，分别用env=dev、env=testing、env=production来标识开发、测试、生产的不同服务。规范描述了用户期望K8s集群中的分布式系统达到的理想状态（Desired State），例如用户可以通过复制控制器Replication Controller设置期望的Pod副本数为3；status描述了系统实际当前达到的状态（Status），例如系统当前实际的Pod副本数为2；那么复本控制器当前的程序逻辑就是自动启动新的Pod，争取达到副本数为3。</p>
<p>K8s中所有的配置都是通过API对象的spec去设置的，也就是用户通过配置系统的理想状态来改变系统，这是k8s重要设计理念之一，即所有的操作都是声明式（Declarative）的而不是命令式（Imperative）的。声明式操作在分布式系统中的好处是稳定，不怕丢操作或运行多次，例如设置副本数为3的操作运行多次也还是一个结果，而给副本数加1的操作就不是声明式的，运行多次结果就错了。</p>
<h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2><ul>
<li>Master是集群控制节点，每个K8S集群里需要Master负责整个集群的管理和控制，K8S所有控制命令都是发给它，由其负责具体执行和调度。</li>
<li>Master上运行的关键进程<ul>
<li>Kubernetes API Server（Kube-apiserver）,提供哦你了HTTP Rest接口的关键服务进程，是K8S里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程</li>
<li>Kubernetes Controller Manager（kube-controller-manager）,K8S里所有资源对象的自动化控制中心，资源对象的“大总管”</li>
<li>Kubernetes Scheduler（kube-scheduler）,负责资源调度（Pod调度）的进程，相当于“调度室；</li>
<li>etcd Server进程，K8S集群资源对象的数据全部保存在etcd中<h2 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h2></li>
</ul>
</li>
<li>Node节点是K8S集群中工作负载节点，每个Node都会被Master分配相应的工作负载</li>
<li>Node节点上运行的关键进程<ul>
<li>kubelet:负责Pod对应的容器创建、启停等任务，同时与Master节点密切协作，实现集群管理的基本功能</li>
<li>kube-proxy:实现K8S Service的通信与负载均衡机制的重要组件</li>
<li>Docker Engine: Docker引擎，负责容器的创建和管理工作<h2 id="POD"><a href="#POD" class="headerlink" title="POD"></a>POD</h2></li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/12/3TdApJyxroRDPg9.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_rqip-tinVoiFZE0I_-LM_sIwx4E3-69Ml-jNW_pod.png"></p>
<ul>
<li>Pod是在K8s集群中运行部署应用或服务的最小单元，它是可以支持多容器的。Pod的设计理念是支持多个容器在一个Pod中共享网络地址和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。Pod对多容器的支持是K8s最基础的设计理念。</li>
<li>Pod是K8s集群中所有业务类型的基础，可以看作运行在K8s集群中的小机器人，不同类型的业务就需要不同类型的小机器人去执行。</li>
<li>目前K8s中的业务主要可以分为长期伺服型（long-running）、批处理型（batch）、节点后台支撑型（node-daemon）和有状态应用型（stateful application）；分别对应的小机器人控制器为Deployment、Job、DaemonSet和StatefulSet。<h2 id="Replication-controller（RC）"><a href="#Replication-controller（RC）" class="headerlink" title="Replication controller（RC）"></a>Replication controller（RC）</h2></li>
<li>RC是K8S系统中核心概念之一，定义了一个期望的场景，即生命某种Pod的副本数量在任意时刻都符合某个预期值。通过监控运行中的Pod来保证集群中运行指定数目的Pod副本。</li>
<li>RC的都能够以包括如下<ul>
<li>Pod期待的副本数（replicas）</li>
<li>用于筛选目标Pod的Label Selector</li>
<li>当Pod的副本书两小于预期数量的时候，用于创建新Pod的Pod模板（template）</li>
</ul>
</li>
<li>RC是K8s较早期的技术概念，<font color="green"><strong>只适用于长期伺服型的业务类型</strong></font>，比如控制小机器人提供高可用的Web服务。<h2 id="Replica-Set（RS）"><a href="#Replica-Set（RS）" class="headerlink" title="Replica Set（RS）"></a>Replica Set（RS）</h2></li>
<li>RS 是新一代RC，提供同样的高可用能力，能够支持更多种类的匹配模式。RS对象一般不单独使用，而是作为Deployment的理想状态参数使用。<h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2></li>
<li>解决Pod的编排问题</li>
<li>部署是一个比RS应用模式更广的API对象，可以是创建一个服务，更新一个服务，或者滚动升级一个服务（滚动升级实际是创建新的RS，然后逐渐在新的RS中副本增加到理想状态，然后逐步将旧的RS中的副本减少到0）</li>
</ul>
<h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><p> <img src="https://i.loli.net/2019/08/12/wlO8dfNvkq3r9sy.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_rqip-tinVoiFZE0I_-LM_sIx5Qc9S275Z49_6_14731220608865.png"></p>
<ul>
<li>RC、RS和Deployment只是保证了支撑服务的微服务Pod的数量，但是没有解决如何访问这些服务的问题。一个Pod只是一个运行服务的实例，随时可能在一个节点上停止，在另一个节点以一个新的IP启动一个新的Pod，因此不能以确定的IP和端口号提供服务。</li>
<li>要稳定地提供服务需要服务发现和负载均衡能力。服务发现完成的工作，是针对客户端访问的服务，找到对应的后端服务实例。在K8S集群中，客户端需要访问的服务就是Service对象。</li>
<li><strong>每个Service会对应一个集群内部有效的虚拟IP，集群内部通过虚拟IP访问一个服务</strong></li>
<li>*<em>在K8S集中微服务的负载均衡是由Kube-proxy实现的 *</em></li>
<li>Kube-proxy是K8s集群内部的负载均衡器。它是一个分布式代理服务器，在K8s的每个节点上都有一个；这一设计体现了它的伸缩性优势，需要访问服务的节点越多，提供负载均衡能力的Kube-proxy就越多，高可用节点也随之增多<h2 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h2></li>
<li>Job是K8s用来控制批处理型任务的API对象。批处理业务与长期伺服业务的主要区别是批处理业务的运行有头有尾，而长期伺服业务在用户不停止的情况下永远运行。Job管理的Pod根据用户的设置把任务成功完成就自动退出了。成功完成的标志根据不同的spec.completions策略而不同：单Pod型任务有一个Pod成功就标志完成；定数成功型任务保证有N个任务全部成功；工作队列型任务根据应用确认的全局成功而标志成功。<h2 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h2></li>
<li>后台支撑型服务的核心关注点在K8s集群中的节点（物理机或虚拟机），要保证每个节点上都有一个此类Pod运行。节点可能是所有集群节点也可能是通过nodeSelector选定的一些特定节点。</li>
<li>典型的后台支撑型服务包括，存储，日志和监控等在每个节点上支撑K8s集群运行的服务<h2 id="StatefulSett"><a href="#StatefulSett" class="headerlink" title="StatefulSett"></a>StatefulSett</h2></li>
<li>RC和RS主要是控制提供无状态服务的，其所控制的Pod的名字是随机设置的，一个Pod出故障了就被丢弃掉，在另一个地方重启一个新的Pod，名字变了、名字和启动在哪儿都不重要，重要的只是Pod总数。</li>
<li>StatefulSet是用来控制有状态服务，StatefulSet中的每个Pod的名字都是事先确定的，不能更改</li>
<li>对于RC和RS中的Pod，一般不挂载存储或者挂载共享存储，保存的是所有Pod共享的状态，Pod像牲畜一样没有分别（这似乎也确实意味着失去了人性特征）</li>
<li>对于StatefulSet中的Pod，每个Pod挂载自己独立的存储，如果一个Pod出现故障，从其他节点启动一个同样名字的Pod，要挂载上原来Pod的存储继续以它的状态提供服务</li>
<li>适合于StatefulSet的业务包括数据库服务MySQL和PostgreSQL，集群化管理服务Zookeeper、etcd等有状态服务</li>
</ul>
<h2 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h2><ul>
<li>Pod中能够被多个容器访问的共享目录，与Pod生命周期相同，与容器生命周期不相关</li>
<li>类型：<ol>
<li>emptyDir ：初始内容为空，无需指定宿主机上对应目录文件，临时空间</li>
<li>hostpath ：Pod上挂载宿主机上的文件或目录</li>
<li>gcePersistentDisk:Pod上的内容会被永久保存，即使Pod删除（node节点在GCE环境）</li>
<li>awsElasticBlockStore:同上，AWS云环境</li>
<li>NFS</li>
<li>其他类型：iscsi、glusterfs、rbd、gitRepo、flocker、secret(加密)</li>
</ol>
</li>
</ul>
<h2 id="Persistent-Volume"><a href="#Persistent-Volume" class="headerlink" title="Persistent Volume"></a>Persistent Volume</h2><ul>
<li>PV只能是网络存储，不属于任何Node，但可以在每个Node上访问</li>
<li>PV并不定义在Pod上，而是独立于Pod之外定义</li>
<li>PV目前只有几种类型：GCE Persistent Disks、NFS、RBD、iSCSI、AWSEBS、GlusterFS等</li>
</ul>
<h2 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h2><ul>
<li>集群内部的资源对象”分配“到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源同时还能被分别管理</li>
</ul>
<h2 id="Label（标签）"><a href="#Label（标签）" class="headerlink" title="Label（标签）"></a>Label（标签）</h2><ul>
<li>Label是一个Key=value的键值对，key和value由用户自己定义。Label可以附加到各种资源对象上，例如Node、Pod、Service、RS等，一个资源对象可以定义任意数量的Label，同一label也可以被添加到任意数量的资源对象上，label可以在定义资源对象是创建，也可以创建后动态添加或删除</li>
<li>通过LabelSelector(标签选择器)查询和筛选，K8S通过这种方式实现类似SQL的简单又通用的对象查询机制</li>
</ul>
<h2 id="Horizontal-Pod-Autoscaler（HPA）"><a href="#Horizontal-Pod-Autoscaler（HPA）" class="headerlink" title="Horizontal Pod Autoscaler（HPA）"></a>Horizontal Pod Autoscaler（HPA）</h2><ul>
<li>Pod横向自动扩容，通过追踪分析RS控制的所有目标Pod的负载变化情况，确定是否需要针对性调整目标Pod的副本数</li>
<li>度量指标<ul>
<li>CPUUtilizationPercentage （需要部署安装Heapster）</li>
<li>应用程序自定义的度量指标，比如服务在每秒内的相应的请求数（TPS或QPS）</li>
</ul>
</li>
</ul>
<h2 id="RBAC访问授权"><a href="#RBAC访问授权" class="headerlink" title="RBAC访问授权"></a>RBAC访问授权</h2><ul>
<li>基于角色的访问控制（Role-based Access Control，RBAC）的授权模式</li>
</ul>
<h1 id="核心组件-1"><a href="#核心组件-1" class="headerlink" title="核心组件"></a>核心组件</h1><p> ##组件通信<br>   K8S多组件之间通信原理</p>
<p><img src="https://i.loli.net/2019/08/12/GzcCtOFyV7pnHBX.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_rqip-tinVoiFZE0I_-LM_sEq_NuMALezRGMtG_workflow.png"></p>
<ul>
<li>apiserver 负责etcd存储的所有操作，且只有apiserver才直接操作etcd集群</li>
<li>apiserver 对内（集群中的其他组件）和对外（用户）提供统一的REST API，其他组件均通过apiserver进行通信<ul>
<li>controller manager、scheduler、kube-proxy和kubelet等均通过apiserver watch API检测资源变化情况，并对资源作相应的操作</li>
<li>所有需要更新资源状态的操作均通过apiserver的REST API进行</li>
</ul>
</li>
<li>apiserver也会直接调用kubelet API（如logs,exec,attach等），默认不校验kubelet证书，看可以通过–kubelet-certificate-autprity开启开启（GKE通过SSH隧道保护他们之间通信）<br>比如典型的创建Podcast的流程为</li>
</ul>
<p><img src="https://i.loli.net/2019/08/12/eg53NY8LvBa91q7.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_rqip-tinVoiFZE0I_-LM_sEqUTx_-gUuaPyw1_components.png"></p>
<ol>
<li><p>用户通过REST API创建一个Pod </p>
</li>
<li><p>apiserver 将其写入etcd</p>
</li>
<li><p>scheduler检测到未绑定Node的Pod，开始调度并更新Pod的Node绑定</p>
</li>
<li><p>kubelet检测到有新的Podcast调度过来，通过container runtime运行该Pod</p>
</li>
<li><p>kubelet通过container runtime取到Pod状态，并更新到apiserver中</p>
<h2 id="端口号"><a href="#端口号" class="headerlink" title="端口号"></a>端口号</h2></li>
</ol>
<h3 id="Master-1"><a href="#Master-1" class="headerlink" title="Master"></a>Master</h3><table>
<thead>
<tr>
<th align="center"><strong>Protocol</strong></th>
<th align="center"><strong>Direction</strong></th>
<th align="center"><strong>PortRange</strong></th>
<th align="center"><strong>Purpose</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">6443*</td>
<td align="center">Kubernetes API server</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">8080</td>
<td align="center">Kubernetes API insecure server</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">2379-2380</td>
<td align="center">etcd server client API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10250</td>
<td align="center">Kubelet API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10251</td>
<td align="center">kube-scheduler healthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10252</td>
<td align="center">kube-controller-manager healthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10253</td>
<td align="center">cloud-controller-manager healthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10255</td>
<td align="center">Read-only Kubelet API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10256</td>
<td align="center">kube-proxy healthz</td>
</tr>
</tbody></table>
<h3 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h3><table>
<thead>
<tr>
<th align="center"><strong>Protocol</strong></th>
<th align="center"><strong>Direction</strong></th>
<th align="center"><strong>PortRange</strong></th>
<th align="center"><strong>Purpose</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">4194</td>
<td align="center">Kubelet cAdvisor</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10248</td>
<td align="center">Kubelethealthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10249</td>
<td align="center">kube-proxy metrics</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10250</td>
<td align="center">Kubelet API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10255</td>
<td align="center">Read-only Kubelet API</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">10256</td>
<td align="center">kube-proxy healthz</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">Inbound</td>
<td align="center">30000-32767</td>
<td align="center">NodePort Services**</td>
</tr>
</tbody></table>
<h2 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h2><p>Etcd 是 CoreOS 基于 Raft 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障（如数据库选主、分布式锁等）。</p>
<h2 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h2><p><img src="https://i.loli.net/2019/08/12/RyPTzkrf1qw5VKg.png" alt="assets_-LDAOok5ngY4pc1lEDes_-L_kZB_hPn0h_fskH43w_-L_kZGkSetdfkFl6OL6N_post-ccm-arch.png"></p>
<p>Controller Manager 由 kube-controller-manager 和 cloud-controller-manager 组成，是 Kubernetes 的大脑，它通过 apiserver 监控整个集群的状态，并确保集群处于预期的工作状态。<br>Kube-controller-manager 由一系列的控制器组成<br><img src="https://i.loli.net/2019/08/13/5GwXKSWfODuFaVt.png" alt="20170721232653797.png"></p>
<ul>
<li>Replication Controller</li>
<li>Node Controller</li>
<li>CronJob Controller</li>
<li>Daemon Controller</li>
<li>Deployment Controller</li>
<li>Endpoint Controller</li>
<li>Garbage Collector</li>
<li>Namespace Controller</li>
<li>Job Controller</li>
<li>Pod AutoScaler</li>
<li>RelicaSet</li>
<li>Service Controller</li>
<li>ServiceAccount Controller</li>
<li>StatefulSet Controller</li>
<li>Volume Controller</li>
<li>Resource quota Controller<br>cloud-controller-manager 在 Kubernetes 启用 Cloud Provider 的时候才需要，用来配合云服务提供商的控制，也包括一系列的控制器，如</li>
<li>Node Controller</li>
<li>Route Controller</li>
<li>Service Controller<h2 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h2>kube-scheduler 负责分配调度 Pod 到集群内的节点上，它监听 kube-apiserver，查询还未分配 Node 的 Pod，然后根据调度策略为这些 Pod 分配节点（更新 Pod 的 NodeName 字段）<br>调度器需要充分考虑诸多的因素：</li>
<li>公平调度</li>
<li>资源高效利用</li>
<li>QoS</li>
<li>affinity 和 anti-affinity</li>
<li>数据本地化（data locality）</li>
<li>内部负载干扰（inter-workload interference）</li>
<li>deadlines<br>有三种方式指定 Pod 只运行在指定的 Node 节点上</li>
<li>nodeSelector：只调度到匹配指定 label 的 Node 上</li>
<li>nodeAffinity：功能更丰富的 Node 选择器，比如支持集合操作</li>
<li>podAffinity：调度到满足条件的 Pod 所在的 Node 上<h2 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h2></li>
<li>提供集群管理的 REST API 接口，包括认证授权、数据校验以及集群状态变更等</li>
<li>提供其他模块之间的数据交互和通信的枢纽（其他模块通过 API Server 查询或修改数据，只有 API Server 才直接操作 etcd）<h2 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h2>每个节点上都运行一个 kubelet 服务进程，默认监听 10250 端口，接收并执行 master 发来的指令，管理 Pod 及 Pod 中的容器。每个 kubelet 进程会在 API Server 上注册节点自身信息，定期向 master 节点汇报节点的资源使用情况，并通过 cAdvisor 监控节点和容器的资源。<h3 id="节点管理"><a href="#节点管理" class="headerlink" title="节点管理"></a>节点管理</h3>节点管理主要是节点自注册和节点装填更新：<ul>
<li>Kubelet可以通过设置启动参数–register-node来确定是否向API Server注册</li>
<li>如果Kubelet没有选择自注册模式，则需要用户自己配置Node资源信息，同时需要告知Kubelet集群上的API Server的位置</li>
<li>Kubelet在启动时通过API Server注册节点信息，并定时向API Server发送节点新消息，API Server在接受到新消息后，将信息写入etcd<h3 id="Pod管理"><a href="#Pod管理" class="headerlink" title="Pod管理"></a>Pod管理</h3></li>
<li>Kubelet 以 PodSpec 的方式工作。PodSpec 是描述一个 Pod 的 YAML 或 JSON 对象。 kubelet 采用一组通过各种机制提供的 PodSpecs（主要通过 apiserver），并确保这些 PodSpecs 中描述的 Pod 正常健康运行<h3 id="Static-Pod"><a href="#Static-Pod" class="headerlink" title="Static Pod"></a>Static Pod</h3></li>
<li>静态Pod是由kubelet进行管理的仅存在于特定Node上的Pod。不能通过API Server进行管理，无法与RC、Deployment或者DaemonSet进行管理，并且kubelet无法对其进行健康检查。</li>
<li>静态Pod总是由kubelet进行创建，并且总是在kuelet所在的Node上运行</li>
<li>所有以非 API Server 方式创建的 Pod 都叫 Static Pod。Kubelet 将 Static Pod 的状态汇报给 API Server，API Server 为该 Static Pod 创建一个 Mirror Pod 和其相匹配。Mirror Pod 的状态将真实反映 Static Pod 的状态。当 Static Pod 被删除时，与之相对应的 Mirror Pod 也会被删除。</li>
<li><h3 id="容器健康检查"><a href="#容器健康检查" class="headerlink" title="容器健康检查"></a>容器健康检查</h3></li>
</ul>
</li>
</ul>
<ol>
<li>LivenessProbe 探针：用于判断容器是否健康，告诉 Kubelet 一个容器什么时候处于不健康的状态。如果 LivenessProbe 探针探测到容器不健康，则 Kubelet 将删除该容器，并根据容器的重启策略做相应的处理。如果一个容器不包含 LivenessProbe 探针，那么 Kubelet 认为该容器的 LivenessProbe 探针返回的值永远是 “Success”</li>
<li>ReadinessProbe：用于判断容器是否启动完成且准备接收请求。如果 ReadinessProbe 探针探测到失败，则 Pod 的状态将被修改。Endpoint Controller 将从 Service 的 Endpoint 中删除包含该容器所在 Pod 的 IP 地址的 Endpoint 条目。<br>livenessProbe 包含如下三种实现方式：</li>
</ol>
<ul>
<li><p>ExecAction：在容器内部执行一个命令，如果该命令的退出状态码为 0，则表明容器健康；</p>
</li>
<li><p>TCPSocketAction：通过容器的 IP 地址和端口号执行 TCP 检查，如果端口能被访问，则表明容器健康；</p>
</li>
<li><p>HTTPGetAction：通过容器的 IP 地址和端口号及路径调用 HTTP GET 方法，如果响应的状态码大于等于 200 且小于 400，则认为容器状态健康。</p>
<h3 id="cAdvisor-资源监控"><a href="#cAdvisor-资源监控" class="headerlink" title="cAdvisor 资源监控"></a>cAdvisor 资源监控</h3><p>Kubernetes集群中，应用程序的执行情况可以在不同的级别上检测到，包括：容器、Pod、Servvice和整个集群。Heapster项目为K8S提供了一个基本监控平台，它是集群级别的监控事件数据集成器（Aggregator）.Heapster以Pod的方式运行在集群中，Heapster通过Kubelet发现所有运行在集群中的节点，并查看这些节点的资源使用情况。Kubelet通过cAdvisor获取其所在节点及容器的数据。</p>
<ul>
<li>cAdvisor 是一个开源的分析容器资源使用率和性能特性的代理工具，已集成到 Kubernetes 代码中。</li>
<li>cAdvisor 自动查找所有在其所在节点上的容器，自动采集 CPU、内存、文件系统和网络使用的统计信息。</li>
<li>cAdvisor 通过它所在节点机的 Root 容器，采集并分析该节点机的全面使用情况。</li>
<li>cAdvisor 通过其所在节点机的 4194 端口暴露一个简单的 UI<h3 id="Container-Runtime"><a href="#Container-Runtime" class="headerlink" title="Container Runtime"></a>Container Runtime</h3>负责真正管理镜像和容器的生命周期。Kubelet通过Container Runtime Interface（CRI）与容器云形式交互，以管理镜像和容器。</li>
<li>拆分成Sandbox和Container的gPRC接口，并将镜像管理和容器管理分离到不同的服务</li>
</ul>
<p><img src="https://i.loli.net/2019/08/13/FDv8ZWuRi3X5SCg.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LOmrfw3UHfIY1g0xnLo_-LOmroTRjl0FBixIYL5x_cri.png"></p>
<h2 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h2></li>
</ul>
<ul>
<li>每台node上都运行一个kube-proxy服务，监听API server和endpoint的变化情况，并通过iptables等来为服务配置负载均衡（仅支持TCP和UDP）</li>
<li>kube-proxy可以直接运行在物理机上，也可以在static pod或者daemonset的方式运行</li>
<li>实现方式<ul>
<li>userspace:用户控件监听端口，所有服务通过iptables转发到这个端口，然后在其内部负载均衡到实际pod</li>
<li>iptables:完全以iptables规则的方式实现service负载均衡（服务多的时候，产生太多iptables规则）</li>
<li>ipvs：解决iptables模式性能问题，增量式更新，保证service更新期间连接不断开</li>
<li>应用层的转发机制通过services是无法实现的，需要借助Ingress将不同URL的访问请求转发到后端不同的service<h2 id="kube-dns"><a href="#kube-dns" class="headerlink" title="kube-dns"></a>kube-dns</h2></li>
</ul>
</li>
<li>目前推荐CoreDNS替代kube-dns(skydns)</li>
<li>DNS 格式<ul>
<li>Service <ul>
<li>A record (cluster IP 或Pod IP列表)</li>
<li>SRV record</li>
</ul>
</li>
<li>Pod<ul>
<li>A record:</li>
<li>指定hostname和subdomain</li>
</ul>
</li>
</ul>
</li>
<li>工作原理<ul>
<li>kube-dns：DNS 服务的核心组件，主要由 KubeDNS 和 SkyDNS 组成<ul>
<li>KubeDNS 负责监听 Service 和 Endpoint 的变化情况，并将相关的信息更新到 SkyDNS 中</li>
<li>SkyDNS 负责 DNS 解析，监听在 10053 端口 (tcp/udp)，同时也监听在 10055 端口提供 metrics</li>
<li>kube-dns 还监听了 8081 端口，以供健康检查使用</li>
</ul>
</li>
<li>dnsmasq-nanny：负责启动 dnsmasq，并在配置发生变化时重启 dnsmasq<ul>
<li>dnsmasq 的 upstream 为 SkyDNS，即集群内部的 DNS 解析由 SkyDNS 负责</li>
</ul>
</li>
<li>sidecar：负责健康检查和提供 DNS metrics（监听在 10054 端口）</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/13/kV82oOjNUX6dQzC.png" alt="assets_-LDAOok5ngY4pc1lEDes_-LM_tX5rWaCuzsx7xEcz_-LM_t_Oxw2Twn_BSf7GQ_kube-dns.png"></p>
<h1 id="资源管理对象"><a href="#资源管理对象" class="headerlink" title="资源管理对象"></a>资源管理对象</h1><h2 id="Node-1"><a href="#Node-1" class="headerlink" title="Node"></a>Node</h2><p>Node 是 Pod 真正运行的主机，可以是物理机，也可以是虚拟机。为了管理 Pod，每个 Node 节点上至少要运行 container runtime（比如 docker 或者 rkt）、kubelet 和 kube-proxy 服务。</p>
<h3 id="Node管理"><a href="#Node管理" class="headerlink" title="Node管理"></a>Node管理</h3><ul>
<li>不像其他的资源（如 Pod 和 Namespace），Node 本质上不是 Kubernetes 来创建的，Kubernetes 只是管理 Node 上的资源。虽然可以通过 Manifest 创建一个 Node 对象（如下 yaml 所示），但 Kubernetes 也只是去检查是否真的是有这么一个 Node，如果检查失败，也不会往上调度 Pod。</li>
<li>这个检查是由 Node Controller 来完成的。Node Controller 负责<ul>
<li>维护 Node 状态 </li>
<li>与 Cloud Provider 同步 Node</li>
<li>给 Node 分配容器 CIDR</li>
<li>删除带有 NoExecute taint 的 Node 上的 Pods<h3 id="Node状态"><a href="#Node状态" class="headerlink" title="Node状态"></a>Node状态</h3></li>
</ul>
</li>
<li>地址：包括 hostname、外网 IP 和内网 IP</li>
<li>条件（Condition）：包括 OutOfDisk、Ready、MemoryPressure 和 DiskPressure</li>
<li>容量（Capacity）：Node 上的可用资源，包括 CPU、内存和 Pod 总数</li>
<li>基本信息（Info）：包括内核版本、容器引擎版本、OS 类型等</li>
</ul>
<h2 id="PersistentVolume"><a href="#PersistentVolume" class="headerlink" title="PersistentVolume"></a>PersistentVolume</h2><p>PersistentVolume (PV) 和 PersistentVolumeClaim (PVC) 提供了方便的持久化卷：<strong>PV 提供网络存储资源，而 PVC 请求存储资源</strong>。这样，设置持久化的工作流包括配置底层文件系统或者云数据卷、创建持久性数据卷、最后创建 PVC 来将 Pod 跟数据卷关联起来。PV 和 PVC 可以将 pod 和数据卷解耦，pod 不需要知道确切的文件系统或者支持它的持久化引擎。</p>
<h3 id="Volume-生命周期"><a href="#Volume-生命周期" class="headerlink" title="Volume 生命周期"></a>Volume 生命周期</h3><p>Volume 的生命周期包括 5 个阶段</p>
<ol>
<li>Provisioning，即 PV 的创建，可以直接创建 PV（静态方式），也可以使用 StorageClass 动态创建</li>
<li>Binding，将 PV 分配给 PVC</li>
<li>Using，Pod 通过 PVC 使用该 Volume，并可以通过准入控制 StorageObjectInUseProtection（1.9 及以前版本为 PVCProtection）阻止删除正在使用的 PVC</li>
<li>Releasing，Pod 释放 Volume 并删除 PVC</li>
<li>Reclaiming，回收 PV，可以保留 PV 以便下次使用，也可以直接从云存储中删除</li>
<li>Deleting，删除 PV 并从云存储中删除后段存储<br>根据这 5 个阶段，Volume 的状态有以下 4 种</li>
</ol>
<ul>
<li>Available：可用</li>
<li>Bound：已经分配给 PVC</li>
<li>Released：PVC 解绑但还未执行回收策略</li>
<li>Failed：发生错误<h3 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h3>PersistentVolume（PV）是集群之中的一块网络存储。跟 Node 一样，也是集群的资源。PV 跟 Volume (卷) 类似，不过会有独立于 Pod 的生命周期。比如一个 NFS 的 PV 可以定义为<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv0003</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line">  nfs:</span><br><span class="line">    path: /tmp</span><br><span class="line">    server: 172.17.0.2</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>PV 的访问模式（accessModes）有三种：</p>
<ul>
<li>ReadWriteOnce（RWO）：是最基本的方式，可读可写，但只支持被单个节点挂载。</li>
<li>ReadOnlyMany（ROX）：可以以只读的方式被多个节点挂载。</li>
<li>ReadWriteMany（RWX）：这种存储可以以读写的方式被多个节点共享。不是每一种存储都支持这三种方式，像共享方式，目前支持的还比较少，比较常用的是 NFS。在 PVC 绑定 PV 时通常根据两个条件来绑定，一个是存储的大小，另一个就是访问模式。<br>PV 的回收策略（persistentVolumeReclaimPolicy，即 PVC 释放卷的时候 PV 该如何操作）也有三种</li>
<li>Retain，不清理, 保留 Volume（需要手动清理）</li>
<li>Recycle，删除数据，即 rm -rf /thevolume/*（只有 NFS 和 HostPath 支持）</li>
<li>Delete，删除存储资源，比如删除 AWS EBS 卷（只有 AWS EBS, GCE PD, Azure Disk 和 Cinder 支持）<h3 id="StorageClass"><a href="#StorageClass" class="headerlink" title="StorageClass"></a>StorageClass</h3>StorageClass 包括四个部分</li>
<li>provisioner：指定 Volume 插件的类型，包括内置插件（如 kubernetes.io/glusterfs）和外部插件（如 external-storage 提供的 ceph.com/cephfs）。</li>
<li>mountOptions：指定挂载选项，当 PV 不支持指定的选项时会直接失败。比如 NFS 支持 hard 和 nfsvers=4.1 等选项。</li>
<li>parameters：指定 provisioner 的选项，比如 kubernetes.io/aws-ebs 支持 type、zone、iopsPerGB 等参数。</li>
<li>reclaimPolicy：指定回收策略，同 PV 的回收策略。</li>
</ul>
<h3 id="PVC"><a href="#PVC" class="headerlink" title="PVC"></a>PVC</h3><p>PV 是存储资源，而 PersistentVolumeClaim (PVC) 是对 PV 的请求。PVC 跟 Pod 类似：Pod 消费 Node 资源，而 PVC 消费 PV 资源；Pod 能够请求 CPU 和内存资源，而 PVC 请求特定大小和访问模式的数据卷。</p>
<h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><p>Pod 是一组紧密关联的容器集合，它们共享 IPC、Network 和 UTS namespace，是 Kubernetes 调度的基本单位。Pod 的设计理念是支持多个容器在一个 Pod 中共享网络和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。</p>
<p>Pod 的特征</p>
<ul>
<li>包含多个共享 IPC、Network 和 UTC namespace 的容器，可直接通过 localhost 通信</li>
<li>所有 Pod 内容器都可以访问共享的 Volume，可以访问共享数据</li>
<li>无容错性：直接创建的 Pod 一旦被调度后就跟 Node 绑定，即使 Node 挂掉也不会被重新调度（而是被自动删除），因此推荐使用 Deployment、Daemonset 等控制器来容错</li>
<li>优雅终止：Pod 删除的时候先给其内的进程发送 SIGTERM，等待一段时间（grace period）后才强制停止依然还在运行的进程</li>
<li>特权容器（通过 SecurityContext 配置）具有改变系统配置的权限（在网络插件中大量应用）<h3 id="Pod-定义"><a href="#Pod-定义" class="headerlink" title="Pod 定义"></a>Pod 定义</h3>Pod 生命周期<br>Kubernetes 以 PodStatus.Phase 抽象 Pod 的状态（但并不直接反映所有容器的状态）。可能的 Phase 包括</li>
<li>Pending: Pod 已经在 apiserver 中创建，但还没有调度到 Node 上面</li>
<li>Running: Pod 已经调度到 Node 上面，所有容器都已经创建，并且至少有一个容器还在运行或者正在启动</li>
<li>Succeeded: Pod 调度到 Node 上面后成功运行结束，并且不会重启</li>
<li>Failed: Pod 调度到 Node 上面后至少有一个容器运行失败（即退出码不为 0 或者被系统终止）</li>
<li>Unknonwn: 状态未知，通常是由于 apiserver 无法与 kubelet 通信导致</li>
</ul>
<p>PodSpec 中的 restartPolicy 可以用来设置是否对退出的 Pod 重启，可选项包括 Always、OnFailure、以及 Never。</p>
<ul>
<li>Always：只要退出就重启</li>
<li>OnFailure：失败退出（exit code 不等于 0）时重启</li>
<li>Never：只要退出就不再重启</li>
</ul>
<h3 id="容器生命周期钩子"><a href="#容器生命周期钩子" class="headerlink" title="容器生命周期钩子"></a>容器生命周期钩子</h3><p>容器生命周期钩子（Container Lifecycle Hooks）监听容器生命周期的特定事件，并在事件发生时执行已注册的回调函数。支持两种钩子：</p>
<ul>
<li>postStart： 容器创建后立即执行，注意由于是异步执行，它无法保证一定在 ENTRYPOINT 之前运行。如果失败，容器会被杀死，并根据 RestartPolicy 决定是否重启</li>
<li>preStop：容器终止前执行，常用于资源清理。如果失败，容器同样也会被杀死<br>而钩子的回调函数支持两种方式：</li>
<li>exec：在容器内执行命令，如果命令的退出状态码是 0 表示执行成功，否则表示失败</li>
<li>httpGet：向指定 URL 发起 GET 请求，如果返回的 HTTP 状态码在 [200, 400) 之间表示请求成功，否则表示失败</li>
</ul>
<h2 id="ReplicaSet"><a href="#ReplicaSet" class="headerlink" title="ReplicaSet"></a>ReplicaSet</h2><ul>
<li>ReplicationController（也简称为 rc）用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代；而异常多出来的容器也会自动回收。ReplicationController 的典型应用场景包括确保健康 Pod 的数量、弹性伸缩、滚动升级以及应用多版本发布跟踪等。</li>
<li><ul>
<li>在新版本的 Kubernetes 中建议使用 ReplicaSet（也简称为 rs）来取代 ReplicationController。ReplicaSet 跟 ReplicationController 没有本质的不同，只是名字不一样，并且 ReplicaSet 支持集合式的 selector（ReplicationController 仅支持等式）。</li>
</ul>
</li>
<li><ul>
<li>虽然也 ReplicaSet 可以独立使用，但建议使用 Deployment 来自动管理 ReplicaSet，这样就无需担心跟其他机制的不兼容问题（比如 ReplicaSet 不支持 rolling-update 但 Deployment 支持），并且还支持版本记录、回滚、暂停升级等高级特</li>
</ul>
</li>
</ul>
<h2 id="Resource-Quota"><a href="#Resource-Quota" class="headerlink" title="Resource Quota"></a>Resource Quota</h2><p>资源配额（Resource Quotas）是用来限制用户资源用量的一种机制。<br>它的工作原理为</p>
<ul>
<li><strong>资源配额应用在 Namespace 上，并且每个 Namespace 最多只能有一个 ResourceQuota 对象</strong></li>
<li>开启计算资源配额后，创建容器时必须配置计算资源请求或限制（也可以用 LimitRange 设置默认值）</li>
<li>用户超额后禁止创建新的资源<h3 id="资源配额的类型"><a href="#资源配额的类型" class="headerlink" title="资源配额的类型"></a>资源配额的类型</h3></li>
<li>计算资源，包括 cpu 和 memory<ul>
<li>cpu, limits.cpu, requests.cpu</li>
<li>memory, limits.memory, requests.memory</li>
</ul>
</li>
<li>存储资源，包括存储资源的总量以及指定 storage class 的总量<ul>
<li>requests.storage：存储资源总量，如 500Gi</li>
<li>persistentvolumeclaims：pvc 的个数</li>
<li>.storageclass.storage.k8s.io/requests.storage</li>
<li>.storageclass.storage.k8s.io/persistentvolumeclaims</li>
<li>requests.ephemeral-storage 和 limits.ephemeral-storage （需要 v1.8+）</li>
</ul>
</li>
<li>对象数，即可创建的对象的个数<ul>
<li>pods, replicationcontrollers, configmaps, secrets</li>
<li>resourcequotas, persistentvolumeclaims</li>
<li>services, services.loadbalancers, services.nodeports<h3 id="LimitRange"><a href="#LimitRange" class="headerlink" title="LimitRange"></a>LimitRange</h3>默认情况下，Kubernetes 中所有容器都没有任何 CPU 和内存限制。LimitRange 用来给 Namespace 增加一个资源限制，包括最小、最大和默认资源。</li>
</ul>
</li>
</ul>
<h2 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h2><p>StatefulSet是为了解决有状态服务的问题（对应Deployments和ReplicaSets是为了无状态服务设计），其应用场景包括</p>
<ul>
<li>稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC实现</li>
<li>稳定的网络标识，即Pod重新调度后期PodName和HostName不变，基于Headless Service（即没有Cluster IP的service）来实现</li>
<li>有序部署，有序扩展，即Pod是由顺序的，在部署或者扩展的时候要依据定义的顺序依次次序进行（即从 0 到 N-1，在下一个 Pod 运行之前所有之前的 Pod 必须都是 Running 和 Ready 状态），基于init containers来实现</li>
<li>有序收缩，有序删除（即从 N-1 到 0）</li>
</ul>
<p>从上面的应用场景可以发现，StatefulSet 由以下几个部分组成：</p>
<ul>
<li>用于定义网络标志（DNS domain）的 Headless Service</li>
<li>用于创建 PersistentVolumes 的 volumeClaimTemplates</li>
<li>定义具体应用的 StatefulSet</li>
</ul>
<h2 id="Volume-1"><a href="#Volume-1" class="headerlink" title="Volume"></a>Volume</h2><blockquote>
<ul>
<li>默认情况下容器的数据都是非持久化的，在容器消亡以后数据也跟着丢失，所以 Docker 提供了 Volume 机制以便将数据持久化存储。类似的，Kubernetes 提供了更强大的 Volume 机制和丰富的插件，解决了容器数据持久化和容器间共享数据的问题。</li>
</ul>
</blockquote>
<p>与 Docker 不同，<strong>Kubernetes Volume 的生命周期与 Pod 绑定</strong></p>
<ul>
<li>容器挂掉后 Kubelet 再次重启容器时，Volume 的数据依然还在</li>
<li>而 Pod 删除时，Volume 才会清理。数据是否丢失取决于具体的 Volume 类型，比如 emptyDir 的数据会丢失，而 PV 的数据则不会丢<h3 id="Volume-类型"><a href="#Volume-类型" class="headerlink" title="Volume 类型"></a>Volume 类型</h3></li>
</ul>
<h4 id="emptyDir"><a href="#emptyDir" class="headerlink" title="emptyDir"></a>emptyDir</h4><p>如果 Pod 设置了 emptyDir 类型 Volume， Pod 被分配到 Node 上时候，会创建 emptyDir，只要 Pod 运行在 Node 上，emptyDir 都会存在（容器挂掉不会导致 emptyDir 丢失数据），但是如果 Pod 从 Node 上被删除（Pod 被删除，或者 Pod 发生迁移），emptyDir 也会被删除，并且永久丢失。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pd</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: gcr.io/google_containers/test-webserver</span><br><span class="line">    name: test-container</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /cache</span><br><span class="line">      name: cache-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: cache-volume</span><br><span class="line">    emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="hostPath"><a href="#hostPath" class="headerlink" title="hostPath"></a>hostPath</h4><p>hostPath 允许挂载 Node 上的文件系统到 Pod 里面去。如果 Pod 需要使用 Node 上的文件，可以使用 hostPath</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pd</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: gcr.io/google_containers/test-webserver</span><br><span class="line">    name: test-container</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pd</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    hostPath:</span><br><span class="line">      path: /data</span><br></pre></td></tr></table></figure>

<h4 id="gcePersistentDisk"><a href="#gcePersistentDisk" class="headerlink" title="gcePersistentDisk"></a>gcePersistentDisk</h4><p>gcePersistentDisk 可以挂载 GCE 上的永久磁盘到容器，需要 Kubernetes 运行在 GCE 的 VM 中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    # This GCE PD must already exist.</span><br><span class="line">    gcePersistentDisk:</span><br><span class="line">      pdName: my-data-disk</span><br><span class="line">      fsType: ext4</span><br></pre></td></tr></table></figure>

<h4 id="awsElasticBlockStore"><a href="#awsElasticBlockStore" class="headerlink" title="awsElasticBlockStore"></a>awsElasticBlockStore</h4><p>同gcePersistentDisk，环境为AWS</p>
<h4 id="nfs"><a href="#nfs" class="headerlink" title="nfs"></a>nfs</h4><p>NFS 是 Network File System 的缩写，即网络文件系统。Kubernetes 中通过简单地配置就可以挂载 NFS 到 Pod 中，而 NFS 中的数据是可以永久保存的，同时 NFS 支持同时写操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">volumes:</span><br><span class="line">- name: nfs</span><br><span class="line">  nfs:</span><br><span class="line">    # FIXME: use the right hostname</span><br><span class="line">    server: 10.254.234.223</span><br><span class="line">    path: &quot;/&quot;</span><br></pre></td></tr></table></figure>

<h4 id="gitRepo"><a href="#gitRepo" class="headerlink" title="gitRepo"></a>gitRepo</h4><p>gitRepo volume 将 git 代码下拉到指定的容器路径中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">volumes:</span><br><span class="line">- name: git-volume</span><br><span class="line">  gitRepo:</span><br><span class="line">    repository: &quot;git@somewhere:me/my-git-repository.git&quot;</span><br><span class="line">    revision: &quot;22f1d8406d464b0c0874075539c1f2e96c253775&quot;</span><br></pre></td></tr></table></figure>

<h4 id="使用subPath"><a href="#使用subPath" class="headerlink" title="使用subPath"></a>使用subPath</h4><p>Pod 的多个容器使用同一个 Volume 时，subPath 非常有用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: my-lamp-site</span><br><span class="line">spec:</span><br><span class="line">    containers:</span><br><span class="line">    - name: mysql</span><br><span class="line">      image: mysql</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - mountPath: /var/lib/mysql</span><br><span class="line">        name: site-data</span><br><span class="line">        subPath: mysql</span><br><span class="line">    - name: php</span><br><span class="line">      image: php</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - mountPath: /var/www/html</span><br><span class="line">        name: site-data</span><br><span class="line">        subPath: html</span><br><span class="line">    volumes:</span><br><span class="line">    - name: site-data</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: my-lamp-site-data</span><br></pre></td></tr></table></figure>


      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/kubernetes/" rel="tag"># kubernetes</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/08/11/AWS-Direct-Connect-Overview/" rel="next" title="AWS Direct Connect Overview">
                <i class="fa fa-chevron-left"></i> AWS Direct Connect Overview
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/08/17/CDN技术详解/" rel="prev" title="CDN技术详解">
                CDN技术详解 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">seven</p>
              <p class="site-description motion-element" itemprop="description">seven 的精神家园，学习笔记</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="1988xuegang@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Kubernetes-架构"><span class="nav-number">1.</span> <span class="nav-text">Kubernetes 架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#分层架构"><span class="nav-number">1.1.</span> <span class="nav-text">分层架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#核心组件"><span class="nav-number">1.2.</span> <span class="nav-text">核心组件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#核心API"><span class="nav-number">1.3.</span> <span class="nav-text">核心API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生态系统"><span class="nav-number">1.4.</span> <span class="nav-text">生态系统</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#设计理念"><span class="nav-number">2.</span> <span class="nav-text">设计理念</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#API设计原则"><span class="nav-number">2.1.</span> <span class="nav-text">API设计原则</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#控制设计原则"><span class="nav-number">2.2.</span> <span class="nav-text">控制设计原则</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#架构设计原则"><span class="nav-number">2.3.</span> <span class="nav-text">架构设计原则</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#核心技术概念和API对象"><span class="nav-number">3.</span> <span class="nav-text">核心技术概念和API对象</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Master"><span class="nav-number">3.1.</span> <span class="nav-text">Master</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Node"><span class="nav-number">3.2.</span> <span class="nav-text">Node</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#POD"><span class="nav-number">3.3.</span> <span class="nav-text">POD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Replication-controller（RC）"><span class="nav-number">3.4.</span> <span class="nav-text">Replication controller（RC）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Replica-Set（RS）"><span class="nav-number">3.5.</span> <span class="nav-text">Replica Set（RS）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deployment"><span class="nav-number">3.6.</span> <span class="nav-text">Deployment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Service"><span class="nav-number">3.7.</span> <span class="nav-text">Service</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Job"><span class="nav-number">3.8.</span> <span class="nav-text">Job</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DaemonSet"><span class="nav-number">3.9.</span> <span class="nav-text">DaemonSet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#StatefulSett"><span class="nav-number">3.10.</span> <span class="nav-text">StatefulSett</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Volume"><span class="nav-number">3.11.</span> <span class="nav-text">Volume</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Persistent-Volume"><span class="nav-number">3.12.</span> <span class="nav-text">Persistent Volume</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Namespace"><span class="nav-number">3.13.</span> <span class="nav-text">Namespace</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Label（标签）"><span class="nav-number">3.14.</span> <span class="nav-text">Label（标签）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Horizontal-Pod-Autoscaler（HPA）"><span class="nav-number">3.15.</span> <span class="nav-text">Horizontal Pod Autoscaler（HPA）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RBAC访问授权"><span class="nav-number">3.16.</span> <span class="nav-text">RBAC访问授权</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#核心组件-1"><span class="nav-number">4.</span> <span class="nav-text">核心组件</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#端口号"><span class="nav-number">4.1.</span> <span class="nav-text">端口号</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Master-1"><span class="nav-number">4.1.1.</span> <span class="nav-text">Master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Worker"><span class="nav-number">4.1.2.</span> <span class="nav-text">Worker</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#etcd"><span class="nav-number">4.2.</span> <span class="nav-text">etcd</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kube-controller-manager"><span class="nav-number">4.3.</span> <span class="nav-text">kube-controller-manager</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kube-scheduler"><span class="nav-number">4.4.</span> <span class="nav-text">kube-scheduler</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kube-apiserver"><span class="nav-number">4.5.</span> <span class="nav-text">kube-apiserver</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kubelet"><span class="nav-number">4.6.</span> <span class="nav-text">kubelet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#节点管理"><span class="nav-number">4.6.1.</span> <span class="nav-text">节点管理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pod管理"><span class="nav-number">4.6.2.</span> <span class="nav-text">Pod管理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Static-Pod"><span class="nav-number">4.6.3.</span> <span class="nav-text">Static Pod</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#容器健康检查"><span class="nav-number">4.6.4.</span> <span class="nav-text">容器健康检查</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cAdvisor-资源监控"><span class="nav-number">4.6.5.</span> <span class="nav-text">cAdvisor 资源监控</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Container-Runtime"><span class="nav-number">4.6.6.</span> <span class="nav-text">Container Runtime</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kube-proxy"><span class="nav-number">4.7.</span> <span class="nav-text">kube-proxy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kube-dns"><span class="nav-number">4.8.</span> <span class="nav-text">kube-dns</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#资源管理对象"><span class="nav-number">5.</span> <span class="nav-text">资源管理对象</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Node-1"><span class="nav-number">5.1.</span> <span class="nav-text">Node</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Node管理"><span class="nav-number">5.1.1.</span> <span class="nav-text">Node管理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Node状态"><span class="nav-number">5.1.2.</span> <span class="nav-text">Node状态</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PersistentVolume"><span class="nav-number">5.2.</span> <span class="nav-text">PersistentVolume</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Volume-生命周期"><span class="nav-number">5.2.1.</span> <span class="nav-text">Volume 生命周期</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PV"><span class="nav-number">5.2.2.</span> <span class="nav-text">PV</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#StorageClass"><span class="nav-number">5.2.3.</span> <span class="nav-text">StorageClass</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PVC"><span class="nav-number">5.2.4.</span> <span class="nav-text">PVC</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pod"><span class="nav-number">5.3.</span> <span class="nav-text">Pod</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pod-定义"><span class="nav-number">5.3.1.</span> <span class="nav-text">Pod 定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#容器生命周期钩子"><span class="nav-number">5.3.2.</span> <span class="nav-text">容器生命周期钩子</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ReplicaSet"><span class="nav-number">5.4.</span> <span class="nav-text">ReplicaSet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Resource-Quota"><span class="nav-number">5.5.</span> <span class="nav-text">Resource Quota</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#资源配额的类型"><span class="nav-number">5.5.1.</span> <span class="nav-text">资源配额的类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LimitRange"><span class="nav-number">5.5.2.</span> <span class="nav-text">LimitRange</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#StatefulSet"><span class="nav-number">5.6.</span> <span class="nav-text">StatefulSet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Volume-1"><span class="nav-number">5.7.</span> <span class="nav-text">Volume</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Volume-类型"><span class="nav-number">5.7.1.</span> <span class="nav-text">Volume 类型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#emptyDir"><span class="nav-number">5.7.1.1.</span> <span class="nav-text">emptyDir</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hostPath"><span class="nav-number">5.7.1.2.</span> <span class="nav-text">hostPath</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gcePersistentDisk"><span class="nav-number">5.7.1.3.</span> <span class="nav-text">gcePersistentDisk</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#awsElasticBlockStore"><span class="nav-number">5.7.1.4.</span> <span class="nav-text">awsElasticBlockStore</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#nfs"><span class="nav-number">5.7.1.5.</span> <span class="nav-text">nfs</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gitRepo"><span class="nav-number">5.7.1.6.</span> <span class="nav-text">gitRepo</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用subPath"><span class="nav-number">5.7.1.7.</span> <span class="nav-text">使用subPath</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">seven</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




<!-- 新增访客统计代码 -->

<div class="busuanzi-count">
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="site-uv">
      <i class="fa fa-user"></i>
      访问用户： <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 人
    </span>
    <div class="powered-by"></div>
    <span class="site-uv">
      <i class="fa fa-eye"></i>
      访问次数： <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次
    </span>
    <!-- 博客字数统计 -->
    <span class="site-pv">
      <i class="fa fa-pencil"></i>
      博客全站共： <span class="post-count"></span> 字
    </span>
</div>
<!-- 新增访客统计代码 END-->


<!-- 在网页底部添加网站运行时间 -->
<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("07/21/2018 00:00:00");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "Run for "+dnum+" Days ";
        document.getElementById("times").innerHTML = hnum + " Hours " + mnum + " m " + snum + " s";
    }
setInterval("createtime()",250);
</script>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
